{"id": "ptjmq2", "title": "Real-World Cryptography, the book, is done and shipping!", "url": "https://www.reddit.com/r/crypto/comments/ptjmq2/realworld_cryptography_the_book_is_done_and/", "Created (UTC)": "2021-09-22 17:30:34", "body": "Hey folks! My book Real-World Cryptography was just released last week and is now shipping. I've been working on this thing for the last two years and a half, and the goal was to give a good overview of everything that can be classified as \"real-world\" about crypto. You'll find all the basics in the first half of the book, and the second half contains chapters on TLS, noise, PAKEs, post-quantum cryptography, zero-knowledge proofs, MPC, cryptocurrencies, FHE, etc. So it's a good pick if you're learning, but also if you've been in the field for a while and want an intro to some subfield you're interested in. It's not a reference book, and is written in a light style. Also has some art and lots of diagrams. Talks about good practices and how you should use Libsodium and Tink. Things like that :) Anyway, [here's the link](https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&a_bid=ad500e09)", "post URL info": ["https://www.manning.com/books/real-world-cryptography?a_aid=Realworldcrypto&a_bid=ad500e09)"], "author": "davidw_-", "ups": "124", "downs": "0", "number of comments": "78", "comments": ["Congrats David!!!", "Congrats!", "I was just skimming through some of it. This is a very minor quibble, but Figure 5.1 makes it look like Bob transmits his private key.", "The visible on-the-fly decryption of the book as you scroll is a nice touch. :)", "Congrats! The preview looks amazing!\n\nAnd it's the first book that I know of covering non-interactive ZKPs! Great job ;)", "Looks fantastic", "Congrats! Can't wait to read it.", "[deleted]", "I pre ordered it on Amazon, why doesn't it come out until October 19?\n\nI'm not in any rush but that's almost like a full month away.", "Congrats Man! I got your point!", "Congrats on the book. Is it me or can the book be read on the site?", "Great! I just bought it. Looking forward to read it.", "Congrats for the book :) I am waiting for the physical copy; dont want spoilers with the ebook :P", "Just grabbed a copy after stumbling across this sub, looking forward to it's arrival in Australia.", "Link is down  :-(", "The -45% deal is really only today, or its just a marketing trick? \ud83d\ude00", "Amazing pal! congratulations!!", "Congrats for the book pal!!", "hi u/davidw_- i'm looking for a crypto book that has exercises / solutions.. does yours? thanks", "Hopefully, having the hardcopy within arm's reach will motivate me to actually buckle down and get through it. It looked like just the perfect resource to quickly bring me up to speed when I first found it.\nCongratulations on the release!", "> but Figure 5.1 makes it look like Bob transmits his private key.\n\nThat's the most real world thing ever!", "That\u2019s how Manning does previews for other books as well :)", "It lightly covers pairing, and the scheme explained is pretty much groth16 (chapter 15)", "Not sure, maybe Manning is keeping the exclusivity for a month to get more sales?", "are you sure? It works on my end, even in incognito mode :o", "There\u2019s discounts all the time on Manning I realized. If you\u2019re on a budget and want to buy a book there just wait until there\u2019s a sale. It happens several times a year.", "it has a very few number of exercises. Maybe check [cryptohack](https://cryptohack.org/), [cryptopals](https://cryptopals.com/) or [blockbreakers](https://davidwong.fr/blockbreakers/)?", "[removed]", "Yeah, quite likely I guess. If I really wanted it urgently I would have purchased it direct from them.\n\nHowever I like to keep everything in the kindle app on my ipad and PC so I'll wait.", "Thank you for those links!\n\nAre you aware of any (text)books with practical (as opposed to theoretical) problems that require code to solve? I'm trying to wrap my head around using cryptography in applications from scratch and it's rather difficult to get going.", "Your attempts to copy-paste to blend in are still failing.", "Not sure no!", "u/B-Con please let me post this question in this sub!", "Can you link to the post?", "submissions are restricted", "Sorry for the delay, I accidentally messed up my notifications, you've been approved."]}
{"id": "ptfqf8", "title": "[2015] How to manipulate standards - Daniel J. Bernstein", "url": "https://www.youtube.com/watch?v=Cj3PN5-n108", "Created (UTC)": "2021-09-22 13:07:40", "body": "", "post URL info": [], "author": "Zamicol", "ups": "14", "downs": "0", "number of comments": "23", "comments": []}
{"id": "prs8qf", "title": "Bandersnatch: a fast elliptic curve built over the BLS12-381 scalar field", "url": "https://eprint.iacr.org/2021/1152.pdf", "Created (UTC)": "2021-09-20 03:42:35", "body": "", "post URL info": [], "author": "minbunny", "ups": "43", "downs": "0", "number of comments": "43", "comments": ["Introducing Bandersnatch, a new elliptic curve built over the BLS12-381 scalar field in a paper co-written by Simon Masson, a zero-knowledge cryptography researcher from the team building [Anoma](https://anoma.network/). BLS12-381 is a pairing-friendly curve, universally used for digital signatures and zero-knowledge proofs by many projects, one being Anoma.\n\nIn comparison to the Jubjub curve introduced by Zcash which is also not pairing friendly, the Bandersnatch curve has a small discriminant, a lower multiplication cost, and defined over the same scalar field.\n\nLet us know if you have any questions on our [Twitter](https://twitter.com/anomanetwork).", "You should probably make the hyperlinks stand out a little more.", "> Jubjub curve introduced by Zcash which is not pairing friendly\n\nBandersnatch is not pairing-friendly either, no?", "You're right, that was confusing wording. I've edited it :)"]}
{"id": "pq8erj", "title": "I'm writing a communication protocol standard for LoRa and want to include cryptography at the transport layer.. I have questions", "url": "https://www.reddit.com/r/crypto/comments/pq8erj/im_writing_a_communication_protocol_standard_for/", "Created (UTC)": "2021-09-17 13:46:00", "body": "LoRa is \"Long Range\" radio.  For the purpose of this post just think of it as WiFi but much longer ranges (realistic shots can go further than 10 km) and typically less-than dial-up speeds.  If you want to read more, have at it: [https://en.wikipedia.org/wiki/LoRa](https://en.wikipedia.org/wiki/LoRa)\n\nThis project is primarily a learning exercise for me.  I'm writing a python library that acts as an API between the radio hardware itself (communicating via serial interface) and any python program I could ever want to transmit data out of.  I have hopes of expanding it further to add more capability as I go. **Again, this is all a learning exercise for me.** I'm potentially reinventing a wheel here just so I can learn how the wheel was invented.  I completed phase 1 of my proof of concept yesterday with a successful field test.\n\nThe problem I'm running into is packet size.  I have UP TO 240 bytes (characters) to play with and that includes packet metadata such as the \"to\" and \"from\" fields.  It seems like a lot to play with but I'm finding that encrypting my data payloads adds a tremendous amount of overhead after the considerable overhead from the metadata.\n\nI already have Diffie Hellman Key Exchange operational between two radios.  With a full DH exchange coupled with encryption via a simple substitution cypher (for now) then fragmenting the encrypted payload I'm able to transfer \\~120 bytes of data with \\~1200 bytes of transmission in \\~18 seconds.  I have a decent amount of room to reduce my metadata overhead and overhead from how I encode the encrypted data payload and will implement the majority of those optimizations in my next round of development.\n\nSome additional considerations/challenges:\n\n1. I have to assume the radio net is not secure.  Anyone could be monitoring it.  Data payload must be encrypted.\n2. The key exchange must occur over the radio net.\n3. I'm not focused on authentication right now but I have no idea how to best authenticate the identity of the receiver yet.  I'm open to suggestions.  I may leave that up to the application layer as I'm more focused on data assurance at the transport layer by providing the application a standardized API to send data to the destination using a transport layer secured \"channel\" with confirmation the data reached its intended destination intact.\n4. Data transmission may require relays between the sender and receiver.  These relays should not be able to realistically decrypt the data.\n5. 240 byte packet length is not always guaranteed.  That's the most it could be.  If the radio band gets busy or there is interference this could drop to as low as 32 bytes and possibly lower.  I'll write my protocol to try to transmit data as long as there is enough space left over after the metadata overhead.  Remember: 1 character = 1 byte (in this case).\n\nSo I guess after all that my questions for the group are:\n\n1. Given a DH exchange what would be the best course of action to encrypt the data payload?\n2. Is DH exchange of any implementation the best option for this project?\n\nI guess I'm looking for a crypto algorithm/method which won't fail to frequency analysis but also is lightweight enough in that it doesn't add a tremendous amount of overhead to the byte-size of the data.  If DH is ideal then a crypto algorithm that can work with the full key generated by the DH key exchange might be ideal whether symmetric using just the full key or possibly asymmetric using the partial and the full key.  I'm not really sure - encryption/cryptography isn't my area of expertise.\n\nI'm open to suggestions.. books/articles to read, other code to review, etc.  FWIW, communication protocols, how they work and how they are manipulated are what I work with on a daily basis.", "post URL info": ["https://en.wikipedia.org/wiki/LoRa](https://en.wikipedia.org/wiki/LoRa)"], "author": "YukaTLG", "ups": "33", "downs": "0", "number of comments": "79", "comments": ["The initial suggestions I have are\n\n1) find a reduced-size key exchange mechanism to reduce the overhead of establishing a secure channel.\n\n2) A symmetric encryption algorithm such as AES doesn't change the data size. Use the shared key from the key exchange as the symmetric key.", "Have anyone examined the techniques they already use?", "Naked Diffe Hellman is subject to man in the middle attacks. The fix for this tends to involve some sort of cryptographic signature.\n\nWhy can't you just use some sort of symmetrical encryption scheme?", "Classic DH or elliptic curve DH (ECDH)? The latter is much more compact.\n\nFor a stream cipher keyed by ECDH, you can encrypt arbitrary message lengths down to one data bit. But note that you need to add message authentication too, which adds an authentication tag of some given size.", "I'd suggest taking a look at the [Noise Protocol](https://noiseprotocol.org/noise.html). It's extremely flexible, supporting all sorts of use cases.\n\nAssuming you want something connectionless, you might take a look at [WireGuard](https://www.wireguard.com/protocol/) for specific protocol decisions and packet framing.\n\nRegarding the overhead of the D-H exchange, note that Noise supports a \"0RTT\" mode which is capable of carrying data with the initial handshake packet, with some tradeoffs (e.g. replayability)", "Hey OP, this sound very cool. Do you know about LoRa Chat?\n\nThere some other things I can\u2019t think of things second to share but I will update my comment or make another comment. Also I\u2019d love to hear more about your project because I\u2019ve recently become quite obsessed with LoRa tech\n\nHere some links you might find helpful (not that you don\u2019t know them anything covered here)\n\n[white paper ](https://lora-alliance.org/wp-content/uploads/2020/11/lorawan_security_whitepaper.pdf)\n\n[research paper](https://link.springer.com/article/10.1007/s42452-021-04377-y)\n\n[key management paper](https://mdpi-res.com/d_attachment/sensors/sensors-21-02962/article_deploy/sensors-21-02962-v3.pdf)", "More on the protocol side you may want to create a scheme that uses the whole 240 byte packet to create a stream.\n\nAlso, what is the reliability like? Does it have built in ECCs? If not you may need to make room for syndromes. \n\nAll in all, sequencing messages into arbitrary sized blocks or messages may help with a lot of this on the cryptography side.", "[deleted]", "There are a bunch of standards that may help here.  \n\nDTLS is a twist on standard TCP-based TLS that works with datagrams.  But it may be a squeeze for the 240 bytes available.\n\nIETF have been defining COSE, a security extension for CBOR.  May be applicable to handle some of the wrapping of crypto primitives.  Again, may be a squeeze for your payload sizes.\n\nBoth these have implementations, and can wrap the lower-level cryptographic messaging, including key exchange, certificate validation and payload encryption.\n\nThe comments from others re. establishing trust and avoiding MITM are very pertinent.", "Are you aware that Lora itself integrates encryption?  Have you examined the techniques they already use?\n\nNot saying that what is there is any good.  I haven't looked at it myself, but, as the 400 MHz Lora frequencies are smack dab in the middle of an amateur radio band in the US, and that encryption is not allowed on the amateur bands, it is something I am very much cognizant of.\n\nSo basically the only legal way to use 400MHz in the US is to get an amateur license, and then use an encryption key that is \"obvious\", or perhaps better, publish the details of how you are using Lora on the internet.", "this's  what I might be looking for", "I'll take a look at implementing AES.  Seems like what I might be looking for.\n\nThe issue with DH in my implementation isn't packet size.. it's the 3-way handshake. This handshake requires air time and a very large percentage of each packet isn't payload so it is tying up the radio and the net for \\~3 seconds (I haven't exactly measured the time but that's about what it feels like).  Those \\~3 seconds drastically reduce my effective average throughput.  Not a huge deal overall.\n\nI'm sure I'm preaching to the choir but here's how I've implemented DH exchange.  I think it is the most efficient but I'm open to suggestions.\n\nRadio A wants to talk to B:\n\nPacket 1 - A->B: Radio A picks a private prime and public prime and sends the public to Radio B.\n\nPacket 2 - B-> A: Radio B receives, picks a public prime and private prime and computes its partial and transmits its partial and public to Radio A.\n\nPacket 3 - A->B: Radio A receives Radio B's public key, computes its partial key and transmits its partial key to Radio B.\n\nRadio A and B both compute the full key with no more transmissions.  All further payloads are encrypted.\n\nMy overhead is going to be drastically reduced by more efficient packet header formatting with my next phase of proof of concept but I can't get around this 3-way handshake in anyway that I'm aware of.\n\nI can, however, reduce the rate at which two radios need to conduct a key exchange by prioritizing the order in which data is sent if Radio A needs to send data to both Radio B and C.  I believe that is beyond the scope of this sub-reddit but can be summed up as \"While I have you on the phone I also have this I need to talk to you about\".", "i have the same question.. does anyone knows?>", "i haven't but still amazing  to know what you have", "MITM is my primary concern here.  I need to read up on cryptographic signatures and their implementation.  How would it work in a situation where Radio A and B have never communicated with each other previously?\n\n*Down the rabbit hole I go...*\n\nWhat's interesting about LoRa is there may be a scenario where radio C is evil and trying to perform MiTM but Radio A and B can reach each other directly so when responding to each other they also see radio C mimicking the other.. which affords an opportunity for my protocol to identify that and both A & B blacklist radio C.\n\n*Further down the rabbit hole...*\n\nIn the above scenario how do the radios know which one is the legitimate far station and which one is the evil imposter?  I guess that leads me back to cryptographic signatures.\n\nFurther if there are other radios which A & B can mutually reach and use for relay they could bounce messages off of all the potential relays to see if their DH responses differ... the MiTM would expose itself.  This wouldn't work if all the potential relays are also MiTM.\n\nSo without public key infrastructure to act as a known-good 3rd party what's the best way to go about implementing signatures for the DH key exchange?\n\nNow I have a lot to think about/read about.  Thanks haha.", "Thanks.  I'll dive into ECDH.  From my initial wikipedia read it seems like it would be a better choice for the hardware I'm prototyping on.. calculating prime numbers is not easy on the hardware (one of my remote stations is a raspberry pi zero) and I had to resort to precalculation of prime numbers and caching them to disk and verifying that the randomly selected number is actually prime before using it.", "I've seen a lot of various LoRa applications but I write a lot of solutions for my professional life and my own curiosity.  I've found I keep reinventing the wheel with LoRa.. writing the bare minimum protocol for my solution to work.  I decided to end that insanity this week.\n\nI'm basically writing a python library that sits between the LoRa radio \"driver\" and expects certain APIs into the radio provided by that driver. In turn this python library provides an API for any applications that might want to send/receive data via an onboard LoRa radio.  The library handles the transmission of data to the intended destination in a standardized manner.  It is not intended to give LoRa nets a connection to the Internet.\n\nThe library aims to be the transport layer. In concept it'll manage the local radio net, communicate with other stations running the same library and generally be a good steward of the ILM band. It will automatically build out relays as needed. \n\nI'm going to build out a method for a signalling channel where all radios will idle to monitor for connection requests, reachability notices (I'm looking for radio D, has any seen D? Hey  it's E last I saw D was talking to A on 23) and provide net health reports (Hey all this address is in use by external radios).. radio A will try to hail B when it needs to send data to B.. they quickly decide on another address to use for their conversation, switch to it, establish encryption (if requested/required) and say what they have to say and get back to the signalling channel.\n\nRelaying and net mapping will be a part of it.. radios will try to figure out who their neighbors are and what kind of minimum output power they need to reach their neighbors.\n\nThere's a lot more to it. I'm documenting it as I go and actually started working on a PowerPoint presentation to help me mind map how I'm handling things.", "I'm building the layer 2 net management features now and testing reliability and such.  I'm trying to figure out the best ways to handle packet routing and delivery in a way that will make a best effort while not taking up a lot of airtime.  It's a challenge but I'm hooked on it.\n\nWhat I'm finding is the radios are somewhat reliable. The longer the shot or more interference the higher chance of receiving a malformed packet can be. To mitigate this I can reduce packet size and/or reduce bitrate. I'm trying to find a methodology for predicting what reductions are required based on observed network conditions.  Problem is a missed bit is a missed bit.\n\nThere is no ECC on the chip. I have to write it.  That's nice because I'll know how it works under the hood but it's also a lot of work.\n\nOn the key exchange implementation and making the protocol MITM resistant I'm thinking of a few approaches:\n\nMultiple routes: same is packet  is duplicated and hops along multiple parallel relays.  This has drawbacks but could work in a way to expose evil relays which are manipulating data.\n\nWhite knight monitoring: A and B can't reach each other but both C and D are within range to be relays between A and B.  A relays through evil C which performs the MITM. D sees the packet C receives from A and sees a different packet sent from C to B. D alerts the network that C is doing some evil stuff.  Still have a trust issue because what if D is evil and C is not.. and D tells the net that C is evil when C is not to force traffic over D.  This would be more difficult to do as the percentage of evil radios on the net becomes more and more of a priority.. kind of like a 51% attack.\n\n\"Good idea\" fairy shower thought follows..is probably total trash and is a real-time brainstorm as I type:\n\nI'm trying to also think of a way to hash the messages for a key exchange which a node intends to send.. send them via relay before the actual key exchange method. I don't think this would work though.. but with certain methods it could make it incredibly resource intensive for an attacker to effectively MiTM.  \n\nHash the packet before sending it.. send the hash first, wait for ack, and then the packet. The MiTM wouldn't know what's going to be in the packet and won't be able to send an accurate hash of what it intends to send if it is trying to manipulate data in real time. Problem is a MiTM could still monitor encrypted traffic AND it could also get ahead of this by sending the ack and not pushing the hash to B... Waiting for A to then send the packet, peaking into the packet, and then sending the hash to B, waiting for an ack, and then sending the packet.\n\nThing is.. A and B can't hear what either transmit to C but A can hear everything C transmits and so can B. So if A sends something to C to relay to B.. and C changes it.. A will hear that and can recognize that C is evil.", "There is a 33 hour delay fetching comments.\n\nI will be messaging you in 7 days on [**2021-09-24 22:34:31 UTC**](http://www.wolframalpha.com/input/?i=2021-09-24%2022:34:31%20UTC%20To%20Local%20Time) to remind you of [**this link**](https://www.reddit.com/r/crypto/comments/pq8erj/im_writing_a_communication_protocol_standard_for/hd9i0dp/?context=3)\n\n[**CLICK THIS LINK**](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5Bhttps%3A%2F%2Fwww.reddit.com%2Fr%2Fcrypto%2Fcomments%2Fpq8erj%2Fim_writing_a_communication_protocol_standard_for%2Fhd9i0dp%2F%5D%0A%0ARemindMe%21%202021-09-24%2022%3A34%3A31%20UTC) to send a PM to also be reminded and to reduce spam.\n\n^(Parent commenter can ) [^(delete this message to hide from others.)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Delete%20Comment&message=Delete%21%20pq8erj)\n\n*****\n\n|[^(Info)](https://www.reddit.com/r/RemindMeBot/comments/e1bko7/remindmebot_info_v21/)|[^(Custom)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=Reminder&message=%5BLink%20or%20message%20inside%20square%20brackets%5D%0A%0ARemindMe%21%20Time%20period%20here)|[^(Your Reminders)](https://www.reddit.com/message/compose/?to=RemindMeBot&subject=List%20Of%20Reminders&message=MyReminders%21)|[^(Feedback)](https://www.reddit.com/message/compose/?to=Watchful1&subject=RemindMeBot%20Feedback)|\n|-|-|-|-|", "I'm using the 915 MHz ILM license free band.  The 433 MHz LoRa radios are for use in Europe, Africa, and Asia and the 470 MHz LoRa radios are for use in China.\n\nAs far as I've seen the radios themselves have zero encryption built in. In my testing, without implementing encryption I'm able to observe 100% plain text on a 3rd radio.  Are you sure you aren't talking about LoRaWAN?", "But don't you have to send multiple packets for key exchange packet if you only get 32 bytes? A more efficient key exchange will reduce packet transmission time. There is also the computation time of the private key. Look into FourQ for a microcontroller-friendly key exchange mechanism.\n\nLook also into \"multi-party key exchange\" for ideas on your second question.\n\nI think normally, diffie hellman messages are unique to the sender/receiver pair, so I don't think you can send a single key-exchange message to multiple receivers.", "Look up broadcast encryption as well, FYI. There's a wide variety of schemes, some of which are designed to be bandwidth efficient while broadcasting while selectively making data accessible to some but not other recipients.\n\nFor key exchange, you could address multiple nodes in the initial broadcast, with A sharing their public ECDH value and requesting that B and C respond. Note that you can do this with only one round-trip, since once B or C has responded with their own public ECDH values then A can instantly derive session keys with ECDH for each and use it to encrypt data in the next message replying back. In the third packet you don't need to send anything more related to the key exchange, it's done, just acknowledge it and start encrypting.", "[removed]", "If A and B has never communicated before then you have the bootstrap problem. Either you go with TOFU (trust on first use) and hope for the best (only works if there's a high chance the initial communication is NOT intercepted), or you go with PKI (public key infrastructure) and let A and B present signed certificates to each other from some trusted entity who is attestating to who they are.\n\nYou can not necessarily identify a radio C if they choose to not send identifiable information, and they may also jam other radio signals.\n\nFor your question with multiple radio stations, an adversary can attempt a Sybil attack (simply present a greater number of nodes).", "You may even want to try using ECC with this curve, optimized for embedded devices - Curve9767 \n\nhttps://eprint.iacr.org/2020/009\n\nhttps://research.nccgroup.com/2020/04/28/curve9767-and-fast-signature-verification/amp/\n\nYour method for managing primes sounds like a recipe for disaster, to be honest. Definitely a good thing you're here to ask, ECC is much more robust in that regards because you can just collect some entropy on the device and hash it to produce a completely valid key.", "Wow just wow seems amazing and can\u2019t wait to see what you create!", "> Are you sure you aren't talking about LoRaWAN?\n\nYeah that may be.", "Default DH implementations (ECDH included) only uses each session's key exchange material once, but this is not strictly required. It's recommended to not reuse for robustness (forward secrecy, etc), but it's possible.\n\nIn fact, that's what web servers using classic DH all used to do, keeping each DH session keypair for a full day and using it for all clients, instead of only a few seconds for ECDH keys nowadays.", "this is something I am very much cognizant of.", "It's absolutely a recipe for disaster and is merely a placeholder. As I'm reading into ECDH implementation should be as simple as referencing the EC function I need to write instead of the existing prime function.\n\nAnd I came here to pick some minds that are better than mine.  I really appreciate all the great info I've received. Thank you all for your time, knowledge, and insight.", "This. You don't need a new key exchange for every payload. Than you only need it e.g. once a day or once per hour", "You're right, of course.\n\n(In standard DH) The initial message, when the private keys are a and b, includes public prime (p), public small integer (g), and (g^a % p). The response from each individual is  (g^b % p). So if the same private key is used in the source, then then initial payload to all recipients is the same. Of course with standard DH, generating a suitable prime on a small microcontroller is time consuming.\n\nThank you for the correction."]}
{"id": "pqbi3p", "title": "Why does RNGCryptoServiceProvider fail the NIST test for randomness", "url": "https://www.reddit.com/r/crypto/comments/pqbi3p/why_does_rngcryptoserviceprovider_fail_the_nist/", "Created (UTC)": "2021-09-17 16:40:46", "body": "I use RNGCryptoServiceProvider to return sequences of random data (text or binary) in an app I wrote called RESIZER.EXE.\n\nResizer lets you increase or decrease the size of a file with random text or binary values. \n\nI started with a file of one character ('a') and resized it up by 100 bytes of random numeric data using RNGCryptoServiceProvider. I have another app, IsRandom.exe, largely copied from Microsoft, at \n\nhttps://docs.microsoft.com/en-us/archive/msdn-magazine/2013/government-special-issue/test-run-implementing-the-national-institute-of-standards-and-technology-tests-of-randomness-using-csharp\n\nto see if the generated data is random.  IsRandom said it passed the NIST test.\n\nThen I upsized it by 1000 bytes of random numeric data and IsRandom reported it failed the Gamma Test, key is not random enough. I'm confused by this report as the data has no key that I'm aware of. So why do 100 bytes of \"random\" data pass the NIST test but 1000 do not?\n\nI've tried this with a few files. Mostly they pass the NIST test, but a few do not.\n\n(apologies if this post is inappropriate as I've not posted here before)", "post URL info": ["https://docs.microsoft.com/en-us/archive/msdn-magazine/2013/government-special-issue/test-run-implementing-the-national-institute-of-standards-and-technology-tests-of-randomness-using-csharp"], "author": "DeadWorkerBee", "ups": "19", "downs": "0", "number of comments": "49", "comments": ["Without looking at any of your code, it's impossible to give you an answer.", "What percentage are passing? Could just be false positives. If you're using the recommended significance level then you can expect a false positive 5 % of the time.  The dieharder tests use a significance level of less than 0.000001 if memory serves. 0.05 seems high.", "I am not that familiar with C# but it does not look like you are checking for any errors at all, you are just assuming things are working properly. Have you actually opened up these files in a Hex Editor to see if it's outputting the proper data? NIST tests also require lengthy inputs, I believe the minimum was 1MB from memory. HxD Hex Editor is free and has a frequency test built in which can help you see if it's outputting random bytes that are at least distributed evenly.\n\n100/1000 bytes are way too small for the NIST test, I am surprised it did not give you an error for that.", "I generated a 10MB file of random data via Powershell:\n\n$path = \"T:\"\n$bytes = 10MB\n\n[System.Security.Cryptography.RNGCryptoServiceProvider] $rng = New-Object System.Security.Cryptography.RNGCryptoServiceProvider\n$rndbytes = New-Object byte[] $bytes\n$rng.GetBytes($rndbytes)\n[System.IO.File]::WriteAllBytes(\"$($path)\\test.txt\", $rndbytes)\n\nAnd looked at it from the statistics section of HxD. \n\nThe output from mine looks like the others. Can I post images here?", "I didn't know about false positives or the recommended significance level. I'll check that out. THANKS!", "I did download and use HxD. Excellent hex editor. I ran it against one of my files but I don't see how I can upload here. The result \"looks\" random-ish but I'm not sure at all.", "Now that you do, would you care to share your statistics? As someone else mentioned, these tests are usually run over 10^6 bits.  You are using two orders of magnitude less than that.", "I can run it on files in the 10^6 byte range. But I will need a reference about gathering the proper statistics. If someone can run C# code they can run the Resizer app I have here. But I can also produce binary code encrypted data from my app as well.", "Reading from and writing to files is slow.  To reduce this to a problem we can help you with, find a way to pass simple arrays to your NIST methods, for example, through arrays: byte[] randomByteArray = new byte[1024 * 1024], etc.  Fill those bytes with RNGCryptoServiceProvider, and reuse the array for every test, while reporting what percentage failed.  The trick is to reduce the problem to as few methods as possible.\n\nEdit: see https://docs.microsoft.com/en-us/dotnet/api/system.security.cryptography.rngcryptoserviceprovider.getbytes?view=net-5.0#System_Security_Cryptography_RNGCryptoServiceProvider_GetBytes_System_Byte___"]}
{"id": "pq0m42", "title": "A little help with Montgomery ladder implementation", "url": "https://www.reddit.com/r/crypto/comments/pq0m42/a_little_help_with_montgomery_ladder/", "Created (UTC)": "2021-09-17 06:55:11", "body": "Hi folks,\n\nI'm trying to implement Montgomery ladder, just for learning/fun.\n\nI using Swift, as it's a simple language.\n\nBased on the Cryptohack guidance it should be:\n\nInput: P in E(Fp) and an l-bit integer k = \u03a3 2i ki where kl-1 = 1\nOutput: [k]P in E(Fp)\n\n1. Set (R0, R1) to (P, [2]P) \n2. for i = l - 2 down to 0 do\n3.   If ki = 0 then\n4.      Set (R0, R1) to ([2]R0, R0 + R1)\n5.   Else:\n6.      Set (R0, R1) to (R0 + R1, [2]R1)\n7. Return R0\n\n\nSo as a basic pseudocode I did:\n\n    func montgomeryLadder(point p: Point, scalar k: (Int)) -> Point {\n        var r0 = p\n        var r1 = Point(p.x*2,p.y*2)\n        var k0 = k\n        while(k0 > 1) {\n            k0=k0/4\n            if(k0==0){\n                r0 = (r0.x*2, r0.y*2) //should be double\n                r1 = (r0.x+r1.x, r0.y+r1.y) //should be add\n            } else {\n                r0 = (r0.x+r1.x, r0.y+r1.y) //should be add\n                r1 = (r1.x*2, r1.y*2) //should be double\n            }\n        }\n        return r0\n    }\n\n    func pointAddition(point1 p1: Point, point2 p2: Point) -> Point {\n        var a = (p2.y - p1.y)/(p2.x - p1.x) % P // <-- like this, mod per line?\n        //x3 = B\u03b12 - A - x1 - x2 % P\n        //y3 = \u03b1(x1 - x3) - y1 % P\n        return (thePoint)  \n    }\n\nSo the questions I have are:\n\n1. Am I doing this loop right? I'm interpreting it as \"take 2 bits from the number on each loop\", which is why I divide by 4.\n\n2. When I do the add implementation, I am supposed to do all calculations mod the prime P, so does that look something like the above in ```func pointAddition```?\n\n3. Is the \"B\" value in the above add implementation supposed to be the \"B\" co-efficient from the curve equation?\n\n\n\nThank you for your time and sharing your knowledge!", "post URL info": [], "author": "anonXMR", "ups": "11", "downs": "0", "number of comments": "61", "comments": ["Few quick comments \n\nYour point addition will fail when P = Q (essentially when doubling) you will need to modify your point addition to do this, and also for it work for when P or Q is the point at infinity.\n\nYes, when doing point addition everything is computed modulo p. Remember this means you take the modular inverse, you can\u2019t divide like you\u2019re doing in `a`\n\nYou do not divide by 4. You are performing the ladder for every bit of the scalar multiple. Not sure why you\u2019d be dividing by 4? You should look at the binary expansion of k and iterate through all the bits. \n\nHard to be precise by mobile. But I suggest going through the earlier CryptoHack challenges on ECC to make sure you understand regular point addition. \n\nSource: I wrote the CryptoHack challenges for ECC", "> Am I doing this loop right? I'm interpreting it as \"take 2 bits from the number on each loop\", which is why I divide by 4.\n\nWhere did you read that it works like that?\nIf I ask the question it's because I don't have a clue where you found that.", "I'm sorry.. i just had a headache analyzing and trying to answer the question.. :(", "> Your point addition will fail when P = Q (essentially when doubling) you will need to modify your point addition to do this, and also for it work for when P or Q is the point at infinity\n\nThis case can never happen in Montgomery ladder.\nThe two points R0 and R1 in the algorithme always satisfy *R1-R0 = P* where P is the input point of the scalar multiplication.", "> Input: P in E(Fp) and an l-bit integer k = \u03a3 2i ki where kl-1 = 1 Output: [k]P in E(Fp)\n> Set (R0, R1) to (P, [2]P)\n> for i = l - 2 down to 0 do\n\nSo this is the instruction on the crypto hack website, it's this part:\n\n```for i = l - 2 down to 0 do```\n\nso wouldn't that be (taking a 128-bit example), ```128 126 124...```\n\nand since each bit is doubling, each 2-bit subtraction would be div by 4?\n\nThanks for taking a look, and I love cryptohack.", "hey dude, I got a lot further and I think I'm nearly there with point addition, looking at this (based on a library that's doing the heavy lifting (BigInt for Swift), see anything off? I'm still not getting the same as Sagemath:\n\n\n    func pointAddition(point1 p1: Point, point2 p2: Point) -> Point {\n        var p3:Point = (0,0)\n        let a = ((p2.y - p1.y)/(p2.x - p1.x)).inverse(f)\n        p3.x = ((a!^2)-(-486662-p1.x-p2.x))%f\n        p3.y = ((a!*(p1.x-p3.x))-p1.y)%f\n        return (p3.x,p3.y)\n    }\n\n```f``` is defined as ```2^255 - 19```", "> Input: P in E(Fp) and an l-bit integer k = \u03a3 2i ki where kl-1 = 1 Output: [k]P in E(Fp)\n> Set (R0, R1) to (P, [2]P)\n> for i = l - 2 down to 0 do\n\nSo this is the instruction on the crypto hack website, it's this part:\n\n```for i = l - 2 down to 0 do```\n\nso wouldn't that be (taking a 128-bit example), ```128 126 124...```\n\nand since each bit is doubling, each 2-bit subtraction would be div by 4?", "You need both P + Q and P + P in the algorithm. The original code has only code for P + Q. That was my main concern. The other comment was just to work well with a function named \u201cpoint addition\u201d as it\u2019s defined as a function outside of the ladder.", "It just means for every bit in (l-2)", "You\u2019re still not taking into account when you do P + P\n\nHave you done the earlier cryptohack challenge for point addition?", "the line `for i = l - 2 down to 0 do` means that `i` starts from `l-2` and goes down to `0` and by default it generally means the step is `1`.", "You are right, if a single function is used for the group operation then the point doubling should be included.\n\nI didn't look exactly at the proposed code, and there are serious issues at this as it does not look like anything related to an elliptic curve point addition :\n\n    r0 = (r0.x*2, r0.y*2) //should be double\n    r1 = (r0.x+r1.x, r0.y+r1.y) //should be add", "Thanks! Why do we take 2 bits off the scalar?", "yep I've nearly completed ECC, but I did most of it with Sage.\n\nNow I'm trying to implement this for learning and fun with Swift and a BigInt lib.\n\nJust so I can learn, I understand my current implementation is naive (doesn't work for P+P) but it looks correct following this:\n\n    \u03b1 = (y2 - y1) / (x2 - x1 )\n    x3 = B\u03b12 - A - x1 - x2\n    y3 = \u03b1(x1 - x3) - y1 \n\nyet I'm getting totally different points to sage...\n\ne.g.\n\n    Elliptic Curve defined by y^2 = x^3 + 486662*x^2 + x over Finite Field of size 57896044618658097711785492504343953926634992332820282019728792003956564819949\n    sage: a=ec.random_point()\n    sage: b=ec.random_point()\n    sage: a+b\n\n\n    a:(12296486695298768074514340592232185416532989162510434686758991230227901651811 : 13494232587050892934200633015316951090986989709980022136586333594325203872082 : 1)\n\n    b:(11689173278986200479282758195104014802073073363882580268536386220610680032039 : 12025264456401860637091033760780241464179671283833245299980985218556906994932 : 1)\n\n\n    a+b:(30815291228927927632886026054635177532770945458582910157782802841072594073738 : 574307423591002239029635671404707172273485304585061717413615887533038244219 : 1)\n\n\nMy code:\n    a+b:\n    \n    (x: 4962362335044080302095647464835776744711433640017126054569018551139700239461, y: 48068874211734548663794206052725207171558780384086914199237444749175461654042)\n\n\n\nps thank you kindly for even taking a look. <3", "Ah!! Why start at -2?\n\nif a scalar is 256bits why start at 254?", "Because of step 1 and our initial assumptions.", "The first mistake I can see is you have -(-A-x1-x2). This should be +(-A-x1-x2)\n\nAlso, every question you\u2019ve asked, including that operations are done mod p, are in the challenge description.", "It has to do with the numbering of the bits of the scalar\nAs an example we take a scalar *k* of 256 bits. It can be written as\n\n`k = k_255*2^255 + k_254*2^254 + ... + k_2*2^2 + k_1*2 + k_0`\n\nAs you can see its lowest bit is `k_0`, then the second lowest is `k_2`, etc, and its top bit is `k_255`.\nThey are numbered from 0 to 255, so it is 256 bits overall.\nWe suppose that `k_255 = 1`.\n\nThe algorithm as described initialized the points `R_0` and `R_1` as `P` and `2P`, meaning that the top bit is already processed (reread the requirement on the input of the algorithm).\nSo the loop start the processed at the second top bit of the scalar, which is in our example the bit `k_254`.", "thanks! and yep I've read the challenge description many times...\n\nStill not giving results like sage, but I'm learning :)\n\n\n    func pointAddition(point1 p1: Point, point2 p2: Point) -> Point {\n        var p3:Point = (0,0)\n        var a = ((p2.y - p1.y)/(p2.x - p1.x)).inverse(f)\n        p3.x = ((a!^2)+(-486662-p1.x-p2.x))%f\n        p3.y = ((a!*(p1.x-p3.x))-p1.y)%f\n        return (p3.x,p3.y)\n    }\nthe change to + didn't fix it unfortunately. I'll continue to debug!", "Perfect. Totally understand thank you!", "Your inverse is being applied to all of a. You should be doing ((y2-y1) * (x2 - x1).inverse(f)) % f", "thanks finally got their in the end.\n\nproblems:\n\n1) ^ in swift is XOR, not power!\n\n2) % in swift isn't a pure mod, it instead computes the remainder of integer division"]}
{"id": "pppu37", "title": "Promoting Misuse-Resistance in PASETO Libraries", "url": "https://paragonie.com/blog/2021/09/promoting-misuse-resistance-in-paseto-libraries", "Created (UTC)": "2021-09-16 17:43:51", "body": "", "post URL info": [], "author": "sarciszewski", "ups": "11", "downs": "0", "number of comments": "24", "comments": []}
{"id": "pppak6", "title": "Best approach for requiring two keys to compute a symmetric key?", "url": "https://www.reddit.com/r/crypto/comments/pppak6/best_approach_for_requiring_two_keys_to_compute_a/", "Created (UTC)": "2021-09-16 17:09:27", "body": "I need to build an app that contains data that is encrypted (with AES, but that's irrelevant). The data will be decrypted inside a web browser requiring a combination of two keys:\n\n1. A key that is only known to the user, such as a passphrase (let's call it `Ku`)\n2. A key that is stored inside a server and is provided to the browser only after having verified certain credentials (`Ks`)\n\nThe problem I'm trying to solve is that no party (user or server) should be able to decrypt the data with only one of the two keys. Only the browser should be allowed to decrypt the key after the user typed a passphrase (which is not sent to the server) and has received the half of the key from the server (after having authenticated themselves).\n\n`Ku` is a passphrase that is user-defined; this is hopefully strong enough (with enough entropy). `Ks` can be generated randomly, and for example be a long-enough string (such as 32 random bytes, possibly encoded as base64).\n\nThere are two ideas I am considering and would like your thoughts on them:\n\n1. Use a key that is `KDF(Ku || Ks)`, that is: concatenate the two keys (as simple strings) and then use a KDF to derive a symmetric key. (`Ks` in this case could be base64-encoded - it would still be 256 bit of entropy)\n2. Use a (static) ECDH to perform a key agreement. In this case, `Ks` would be the server's private key. `Ku` is the user's private key that is wrapped using a passphrase (that is: the user's passphrase is converted to a key with a KDF, then we use AES-KW as per RFC-3394 to wrap the private EC key).\n\nThoughts on the above? Or, is there a better option?\n\n(As for KDF, that will likely be Argon2id, but any strong KDF should work)", "post URL info": [], "author": "fromYYZtoSEA", "ups": "10", "downs": "0", "number of comments": "38", "comments": ["Xor the two keys together. Knowledge of one key gives no information about the composite key.\n\nMore generally: https://en.m.wikipedia.org/wiki/Secret_sharing", "I don't see any discussion yet regarding how to support a user changing their password, and I think most professionals would agree that a system that doesn't permit key rotation isn't a secure system.\n\nThe general approach is to generate a random symmetric key (DEK) on the client, and another symmetric key (KEK) using a PBKDF.  The DEK is then encrypted with the KEK and sent to the server for storage and later retrieval.\n\nOn subsequent startups, the app retrieves the encrypted DEK from the server and prompts the user for the passphrase in order to regenerate the KEK.  Decrypt the DEK, and it can be used for subsequent cryptographic operations.\n\nYou can rotate the passphrase at any time by generating a new KEK from a new passphrase, encrypting the DEK, and sending that to the server.\n\nA good place to start would be understanding how mature systems of this type work.  I'd suggest reading LastPass' technical whitepaper:\n\nhttps://www.lastpass.com/-/media/88a42919fbc646e6966f64c37fbd29ee.pdf", "I think what you are looking for is https://en.m.wikipedia.org/wiki/Shamir%27s_Secret_Sharing", "I would use a static, randomly generated symmetric key for the data encryption. That key would be stored alongside the data, after being encrypted with the user and server secrets.   \n\nUsing both the user and server secret, set up two stream cipher instances like AES-OFB and then XOR the two resulting keystreams with each other and the symmetric encryption key to either encrypt (or decrypt) the symmetric key. That way there is no inner/outer wrapping where one secret is enough for first stage partial decryption.  \n\nThe user secret would be a passphrase, then use a KDF to compute the key for the user's AES-OFB part.  \n\nThe server secret could be both a public and private EC key from different key pairs (since servers are good at storing files). With these keys, you can compute ECDH and pass the result through a KDF for whitening, then set up the server instance of AES-OFB with the resulting key.", "I am currently working on design of\r  \n\"Secure Anonymous Authentication and Key Agreement Protocol\"\r  \n(for Telecare medical information system)\r  \nwhere can I find more introductory resources or articles for reference ?", "That\u2019s a good idea. Thanks!", "Just to be clear, you\u2019re suggesting to do:\n\n`KDF(user passphrase) XOR Ks`\n\nRight? Assuming the server\u2019s key is already a 256-bit random key, there shouldn\u2019t be any need to pass it through a KDF.\n\nThe difference with my approach #1 is just that it makes it harder for someone with knowledge of Ks to compute the full key (assuming that the user\u2019s passphrase isn\u2019t already having 256 bits of entropy)", "Changing the pass phrase will be possible\n\nI was trying to think why using a wrapped key would not work, but you\u2019re right, it should be ok.\n\nPS: PBKDF is not an appropriate KDF: it\u2019s too fast and it\u2019s not resistant to GPU attacks. We\u2019ll use Argon2id", "Oh data IS encrypted with a random key for each file. The key I\u2019m talking about here is the key encryption key.", "This should probably be its own post (you may need to request posting permission first).\n\nAnonymous how? There anonymous credentials schemes, if you mean anonymous as in letting a user prove some trusted entity has issued them some credential without identifying themselves. But you're also talking about key agreement, so it's probably a very different context.", "As a practical matter the first solution is probably fine. The xor approach is simpler, with information theoretic security as a nice bonus. I'm assuming you mean a PBKDF, which is different than a KDF.\n\nIf the client can store data locally, it would be better to generate a full strength encryption key, use that in the key share with the server, and then wrap the client key share with the password and store the wrapped key locally. Then the server wouldn't be able to do a bruteforce attack on the password. (By the way, if the user authenticates to the server using a password, you can bet your bottom dollar that many users will choose the same or very similar passwords for their decryption key, which is a problem if you want to keep it secret from the server...)\n\nRegardless of whether it not that specific improvement is an option, I'll add that your question assumes half the solution to the actual problem you're trying to solve, and that some better solutions might exist if you back up a few steps from using key sharing and ask about the original problem instead.", "I know you're planning to use Argon2id... I'm referring to password-based KDFs, generally.", "No the client can\u2019t store data locally. \n\n\nAs for KDF, I meant a generic key derivation function. In practice we\u2019ll use Argon2id which should be slow enough to stretch even weaker passphrases and protect against GPU attacks.\n\nThe server never sees the client\u2019s key so there\u2019s no need to wrap that."]}
{"id": "pp0tc6", "title": "Automatic cipher suite ordering in crypto/tls", "url": "https://go.dev/blog/tls-cipher-suites", "Created (UTC)": "2021-09-15 15:43:48", "body": "", "post URL info": [], "author": "knotdjb", "ups": "20", "downs": "0", "number of comments": "35", "comments": ["I'm torn on this. Misconfiguration is a problem.\n\nBut when there is eventually a weakness in a TLS 1.3 suite, I have to wait for the GO developers to acknowledge and fix it. If this trend catches on, then I'll be waiting for every individual developer to enact these fixes, because I can't be trusted with a config file.\n\nAside from perceived strength, might there be other performance, legal, compliance, or industry-based reasons to prefer a suite?"]}
{"id": "pop3ay", "title": "If you copied any of these popular StackOverflow encryption code snippets, then you coded it wrong", "url": "https://littlemaninmyhead.wordpress.com/2021/09/15/if-you-copied-any-of-these-popular-stackoverflow-encryption-code-snippets-then-you-did-it-wrong/", "Created (UTC)": "2021-09-15 05:25:00", "body": "", "post URL info": [], "author": "ScottContini", "ups": "95", "downs": "0", "number of comments": "62", "comments": ["Nice writeup. Some thoughts:\n\n1. I cringe at how many answers confuse cryptographic keys with human generated passwords.\n2. One time pads need to die. They have a very specific use case, and it's not software.\n3. It may be my 44 year old eyeballs, but on my mobile phone, the light text against the white background is difficult to read.", "* From my experience this is a fair representation of common mistakes\n* I was wondering whether I'd see a case where the key is also used as IV\n* Saying that the iteration count for rfc2898DeriveBytes is too low is nice, but it would be useful to give a better value especially since neither the Microsoft example nor the selected SO one use a proper iteration count\n* You cite as a reason for these mistakes the design of crypto APIs that rely on developpers knowing what they're doing. I think that's fair but that another point is how difficult it is to test that cryptography is properly implemented. Maybe we need more efforts toward cryptography testing frameworks. I think developpers would be inclined to find correct implementations if they had a way to know that their current one isn't correct. Maybe something based on test vectors?\n\nThat's getting a bit out of hand, but what about a service implementing several methods, proper or not. As a user of this service you are given a random string to encrypt with your freshly baked encryption code, then post the result on the service. If you are using something common and properly implemented (like AES-GCM or AES-CBC) then the service tells you that your implementation is OK and provides additional remarks if possible (\"You're using AES-CBC, note that this does not guarantee data integrity, consider upgrading to AES-GCM or implementing HMAC-SHA256 to authenticate your message\"). If the implementation cannot be identified it is assumed to be bad and a page showcasing proper implementations for your language is shown. Sure that would still require some implication of the developpers, and things like pkdf rounds will be hard to take into account, but with a nice API this could lead to automated testing for cryptographic code which would probably be better than what most use today. Just a thought.", "Great write-up.", "There was a talk about insecure code on Stackoverflow presented at Real World Crypto 2019 doing a a machine learning analysis of insecure code and proposing good code as well. Though if I recall correctly it was some sort of research project and not something expected to see deployment at the time\n\nY\u2019all may find it interesting https://youtu.be/Int1ekT3iA0", "> [...] Especially when someone responds with \u201cIt\u2019s okay \u2014 we will put the IV in the vault,\u201d my frustration level sky-rockets. No, it\u2019s not okay: IVs are not intended to be secret, and even if they are hidden, it does not fix the security problem. Quit rolling your own crypto! Unfortunately so many do not understand that they are rolling their own crypto.\n\nWhen did \"rolling your own crypto\" mean incorrectly using an encryption API? Shouldn't rolling your own crypto be reserved for people actually coming up with their own algorithms.", "I was just talking to our vendor who produces the cryptographic platform that we use and inquiring about support for encrypting Cloudera databases. We eventually ended up discussing [Ranger KMS](https://docs.informatica.com/big-data-management/big-data-management/10-1/big-data-management-security-guide/introduction-to-big-data-management-security/apache-ranger-kms.html). In much nicer words, the vendor told us that it was one of the more poorly written cryptographic implementations that they've seen. Some of the things they pointed out are [using immutable strings for keys](https://github.com/apache/ranger/blob/53c98116850f90810c0bb85d651a64fe01ef865d/kms/src/main/java/org/apache/hadoop/crypto/key/RangerKMSMKI.java#L24), poor use of the Java keystore interface to limit integrations to particular HSMs, and [exporting keys from the HSM](https://github.com/apache/ranger/blob/53c98116850f90810c0bb85d651a64fe01ef865d/kms/src/main/java/org/apache/hadoop/crypto/key/RangerHSM.java#L126) instead of using a standard KEK/DEK approach where the KEK remains non-exportable in the HSM. \n\nI looked at the code myself and saw other bad practices like [poor choice of default cryptographic primitives](https://github.com/apache/ranger/blob/53c98116850f90810c0bb85d651a64fe01ef865d/kms/src/main/java/org/apache/hadoop/crypto/key/RangerMasterKey.java#L59), logging but not handling exceptions, [using platform default charter encodings](https://github.com/apache/ranger/blob/53c98116850f90810c0bb85d651a64fe01ef865d/kms/src/main/java/org/apache/hadoop/crypto/key/RangerMasterKey.java#L426), and more. It's hard to believe that this code was written by someone experienced in cryptography or that it has been properly code reviewed.", "As for the KDF difficulty level question, a common reply is to benchmark it and set it to a level acceptable to you. So then it would be useful to have a benchmarking guide which explains both how to benchmark and configure it, and *why* it should be done (covering relevant trade-offs for cost effective security measures).\n\nAlso a suggestion for how to implement methods for raising KDF difficulty incrementally as time goes on, without breaking things.", "They have a very specific use case, since neither the Microsoft example nor the selected SO one use a proper iteration count.", "1. Agree!!!\n2. Agree!!!\n3. Noted.  I\u2019ll see if I can change the mobile view, but I am not great at this stuff.\nThanks for your feedback.", "I made a change to the font -- does it help?", "On the last point, yeah, failure modes are different for cryptography than for most other things. Bugs in cryptography are often silent, everything looks like it's working despite failing to protect you, while a typical bug is visible and prevents something from working correctly. Developers are more used to the latter kind, and to work on a bug until they get an output which looks right.", "> was wondering whether I'd see a case where the key is also used as IV.\n\nI have not seen it on StackOverflow, but I have seen it a few times in real code review.  [Crypto101](https://www.crypto101.io/Crypto101.pdf) has a great section on how to break that, which I point the developers to.  Of course they don't read it, but that's usually enough to get them to change it.\n\n> Saying that the iteration count for rfc2898DeriveBytes is too low is nice, but it would be useful to give a better value especially since neither the Microsoft example nor the selected SO one use a proper iteration count\n\nYou are 100% correct.  I am going to add this.  This is a tricky one, but I think I know how to deal with it (give answers from 3 different sources!)\n\n> another point is how difficult it is to test that cryptography is properly implemented. Maybe we need more efforts toward cryptography testing frameworks. I think developpers would be inclined to find correct implementations if they had a way to know that their current one isn't correct. Maybe something based on test vectors?\n\nThis is a really good idea.  I'm not going to tackle that one, but hopefully somebody else does.\n\nThank you for your hugely helpful feedback.", "Just wanted to let you know that I added an Addendum to the blog to acknowledge your very helpful feedback.  Thanks again.", "I'm not sure I agree with the practicality of that. Even if you've weakened your security through key/iv mismanagement, it's still going to be a herculean computational effort to prove it from any kind of black box analysis. A knowledgeable human doing a code review is still going to be far more practical.\n\nEdit: unless you are saying just tell it your key/iv and what function you are using, but at that point you might as well just print out a checklist of best practices, since that's effectively all it could tell you without seeing the full picture.", "Github is already deploying their automated code suggestion tool, which already has been demonstrated to occasionally propose insecure use of encryption...", "What level of abstraction are you thinking of regarding API:s? An API for a collection of cipher modes and parameters? For a scheme implementing misuse resistant authenticated encryption? For a full cryptographic protocol like TLS?\n\nMost developers probably shouldn't be dealing even with cipher modes directly, something which transparently handles all the choices which needs cryptographic expertise to make is what developers should be using.\n\nEven Sony couldn't ensure that a number used once would only be used once. When you ask every single developer to make security critical choices, some will fail, and that's what \"don't roll your own\" is meant to address. Let an expert make the choices.", "Maybe it could be a stretch, but from my viewpoint they are essentially coming up with a new mode of operation that involves secret but constant IV.  This is very easily seen to be insecure. \n\n I\u2019ve had the argument it too many times.  I tell them they are doing it incorrectly but they insist the secrecy of the IV makes it safe.  No, no, no!", "So, I'm going to ignore the choice of wording until the very end, then come back around to it.\n\nIt's not just that people shouldn't be coming up with their own encryption algorithms, or that they shouldn't be writing their own implementation of those algorithms, they also shouldn't be picking algorithms not recently vetted by people who know the current state of things, nor should they be _configuring_ those algorithms.\n\nJust having your sysadmin be in charge of correctly configuring which TLS algorithms to enable, in which order, for your apache configuration is going to almost guarantee that they get it wrong.\n\nEven if it was _right_ when it was put together, it's probably wrong by now.\n\n[Go 1.17 introduced changes around this exact subject.](https://go.dev/blog/tls-cipher-suites)\n\nIn the case of the write up, you have people writing encryption _tools_ using libraries that don't even try to make sane choices for the developers.  Once upon a time that _seemed_ like a smart choice, but we have learned just how bad of an idea that is in practice.\n\nThese days, nobody should be using anything except a tool that does everything necessary unless they have a _really_ good reason.\n\nIf they are interacting with OpenSSL, it's a mistake.  Not because OpenSSL is bad at what it does, but because what it does is a horrible idea for 95% of people who might use it to implement encryption.  And the same can be said for pretty much every single other library or tool set from a similar era, because to my knowledge, they all made the same mistakes.\n\n'We implemented encryption!' should be a huge warning sign all by itself.  'We turned on the flag for our tool set that says that we want encryption' might sound trivial and boring...  But that's _exactly_ what you want.  As soon as you have to do much more than that, there's _far_ too high of a chance that developers are going to get it wrong.\n\nAnd _not_ because they are bad at their job, but because their job isn't to understand the nuances of encryption and to keep up to date on the latest changes to understanding on those nuances.\n\nWith that in mind, these days, calling even using a low level crypto library 'rolling your own' isn't all that far off the mark.  It's nearly just as stupidly dangerous as coming up with your own algorithm.", "Yeah. A bunch. Thanks!", "I don't think a test framework is expected to be bulletproof. But even just a crypto linter that parses the code and outputs warnings like \"your IV is a string\" would do a world of good.", "The idea is not to rely on code parsing at all. The service doesn't see the code you're using. Instead it relies on pre-computed test vectors to identify, from a given input, what function you implemented.\n\nLet's say you want to implement encryption. You're probably going to choose AES-CBC or AES-GCM, and maybe something else but let's stick to that for the example. I know that you're likely to choose one of those two, and there's essentially one proper way to implement each of them (given keysize/padding... not a huge difference). So what I can do as the server is give you some random string and password. As a developper you take the encryption function you implemented and use it to encrypt my message. I can then obtain the IV from it and encrypt the message as well using all the encryption methods I know. I am then able to compare my results to yours. If your result matches mine for AES-GCM then I know what algorithm you choose and I know that you implemented it properly. I may even implement some bad encryptions  to help identify common mistakes. If none of my implementations gives your result then I inform you that you probably messed something up and give you a good implementation reference.\n\nThe goal is to help people that just copy-paste and may not even know how what they implemented is called. This method doesn't rely on parsing code, just comparing encryption outputs for arbitrary messages. It allows checking some properties of IVs and padding.\n\nIt's not perfect, but neither are humans doing a code review. They're costly and may not be available when you need them. I see great potential in automated services and it seems to me that the main hurdle with this one is that there are lots of cases to implement, but once the base is there implementing new ones can be tackled through the community.", "Interestingly enough, looks like StackOverflow is rolling out a feature so sort by votes instead of accepted, which may help to fix this at least somewhat over time.\nhttps://meta.stackoverflow.com/questions/411352/outdated-answers-accepted-answer-is-now-unpinned-on-stack-overflow\n\nI think at least some of the time, the secure solution has more upvotes but it came later than the \"accepted answer\", so it wasn't the first one people see\n\nOne can hope", "Perhaps poor choice of words when I said API. I kind of just meant using the encryption scheme, but presented as a Java API or whatever.\n\n> Even Sony couldn't ensure that a number used once would only be used once. When you ask every single developer to make security critical choices, some will fail, and that's what \"don't roll your own\" is meant to address. Let an expert make the choices.\n\nI guess, I think there's a distinction between \"consult a cryptographer/expert\" and \"don't roll your own\". Sony used a signature scheme incorrectly but they didn't \"roll their own\". I just find the phrase confusing and I think it is misapplied.", "There's also stuff like languages with type safety which allows for defining rules which could prevent a string from even being passed as an IV", "One idea for a project in Rust would be to have a `Password` type which can *only* be constructed from reading it from user input (And it would be a `String` that allocates itself in RAM that's protected from reading when not in use and all that).\n\nThen you hash it to make a `Key`, which is then used for encryption/decryption. Maybe bundle in a serialisation/deserialisation framework so you can have `fn encrypt<T>(key: &Key, item: T) -> Result<Vec<u8>, Error>` and `fn decrypt<T>(key: &Key, bytes: &[u8]) -> Result<T, Error>`.\n\nSince currently in Rust anyways, the answer to \"I have some data structure I want to save to disk in an encrypted way\" is \"uhhh.... libsodium has bindings\"\n\nThough even libsodium isn't great since it can't prevent you from using a shit key (i.e. using user input directly as a key, which I've seen before), and for some reason it forces you to manage the nonce yourself?"]}
{"id": "pnxqgo", "title": "How does /dev/urandom work?", "url": "https://www.reddit.com/r/crypto/comments/pnxqgo/how_does_devurandom_work/", "Created (UTC)": "2021-09-13 23:58:39", "body": "I understand the entropy pool \u201cseeds\u201d the device and effectively there is an encryption function like ChaCha uses this seed as a key, but what is it encrypting with that key to make the pseudorandom numbers?", "post URL info": [], "author": "anonXMR", "ups": "25", "downs": "0", "number of comments": "58", "comments": ["It doesn't encrypt. It just runs ChaCha and outputs the \"key stream\" itself as the random numbers being generated. \n\nChaCha is a stream cipher, which has an internal state which may be based on for example a number (counter value) or some other value which it iterates on. This state plus the key produces the output values (the key stream), using the cryptographic algorithm which it is based on.\n\nIn normal operation with encryption using ChaCha you'd XOR the key stream with the plaintext, but when used as an RNG you just use the key stream output itself.", "I think you are talking in the context of Linux. This will be a simplified answer.\n\nIf you want to read the actual code it is available at:\n\n[https://github.com/torvalds/linux/blob/master/drivers/char/random.c](https://github.com/torvalds/linux/blob/master/drivers/char/random.c)\n\nThe algorithm is based on what is called a \"twisted GFSR\", which uses those \"seeds\" to iterate though a list of unending numbers (in practice it will wrap around after a very long period).\n\nThe basic operation is very similar to walking though a round robin list, however each read causes the current element to be modified. And that modification, if done correctly will give us a very long periods on those lists.\n\nThe algorithm is described in several papers, a relevant would be: [http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/ARTICLES/tgfsr3.pdf](http://www.math.sci.hiroshima-u.ac.jp/m-mat/MT/ARTICLES/tgfsr3.pdf)\n\nNow, how does the entropy factor in these calculations?\n\n[https://github.com/torvalds/linux/blob/d0ee23f9d78be5531c4b055ea424ed0b489dfe9b/drivers/char/random.c#L536](https://github.com/torvalds/linux/blob/d0ee23f9d78be5531c4b055ea424ed0b489dfe9b/drivers/char/random.c#L536)\n\nThe extra bits are used to mutate the pool to prevent predicting the random sequence.", "its like encrypting a stream of numerous zeroes", " It took me some days to find it, but here's an excellent video that answers exactly your questions in a really clear way: https://media.ccc.de/v/32c3-7441-the_plain_simple_reality_of_entropy", "[NIST SP 800-90A Rev 1](https://csrc.nist.gov/publications/detail/sp/800-90a/rev-1/final) explains most of the ideas you'll need for a seeded DRBG.", "[removed]", "[deleted]", "> It doesn't encrypt. It just runs ChaCha and outputs the \"key stream\" itself as the random numbers being generated. \n\nEssentially can be thought of as encrypting a continuous stream of zeroes.", "[removed]", "> but when used as an RNG you just use the key stream output itself.\n\nDoesn't it still XOR it with RDRAND? IIRC the Linux kernel used that somewhat questionable design choice for /dev/random and urandom.", "Thank you!", "It\u2019s a scam. Like you.", "macOS, Linux - real operating systems", "Not since [2013](https://github.com/torvalds/linux/commit/85a1f77716cf546d9b9c42e2848b5712f51ba1ee).", "Oh geez I feel old now."]}
{"id": "pn56s2", "title": "Some thoughts on 2021 OWASP Top 10's Cryptographic Failures Section", "url": "https://www.reddit.com/r/crypto/comments/pn56s2/some_thoughts_on_2021_owasp_top_10s_cryptographic/", "Created (UTC)": "2021-09-12 18:04:00", "body": "What this post is about: OWASP has [drafted their 2021 list](https://owasp.org/Top10/), and the number 2 ranking entry is [Cryptographic Failures](https://owasp.org/Top10/A02_2021-Cryptographic_Failures/).  They are asking for feedback.  Here, I don't want to get into their methodology or the ranking of the issue or why they are grouping things together, instead I have a serious issue with what is written here.\n\nSpecifically, look at what is written in the description, particularly the bullet points.  My concern is that they are missing so many common cryptographic issues that I see nearly every day in my job.  And I mean it: nearly every day I run into somebody simply implementing crypto incorrectly: they hard code an IV, or they treat passwords like keys without running them through a password base key derivation function, or they use unauthenticated encryption when they really only need a MAC, and so on.  These problems, which I have posted in [my blog](https://littlemaninmyhead.wordpress.com/2017/04/22/top-10-developer-crypto-mistakes/) years ago, are still very frequent and never seeming to go away, and yet OWASP has not mentioned a single one of them in their description.\n\nSo, I thought I should give them a hand.  I opened up [an issue](https://github.com/OWASP/Top10/issues/540) on their GitHub page about what is lacking.  And I'm seriously thinking about contributing to OWASP to help improve this, figuring that that is the best way to try to make progress on improving these common problems.\n\nWhy am I posting right here, right now?  Because I want your thoughts on what I have written and what is lacking or needs improvement: https://github.com/OWASP/Top10/issues/540 .  I'm not looking for comments like \"use libsodium for everything\", instead I want to focus on the common problems independent of what library they are using.  I appreciate in advance any thoughts you have that can help point OWASP in the right direction.\n\n**EDIT**: I have submitted a pull request to address my concerns [here](https://github.com/OWASP/Top10/pull/563/files).  **If you have any concerns about this, speak up now.**", "post URL info": ["https://owasp.org/Top10/),", "https://owasp.org/Top10/A02_2021-Cryptographic_Failures/).", "https://littlemaninmyhead.wordpress.com/2017/04/22/top-10-developer-crypto-mistakes/)", "https://github.com/OWASP/Top10/issues/540)", "https://github.com/OWASP/Top10/issues/540", "https://github.com/OWASP/Top10/pull/563/files)."], "author": "ScottContini", "ups": "44", "downs": "0", "number of comments": "47", "comments": ["I think you may be extrapolating your own bubble to represent a much larger part of the industry than it does\u2026 most companies use encryption in three places:\n\n-\tTLS\n-\tFull disk encryption\n-\tProvider-managed (like AWS) encryption\n\nNone of those require you to pick an IV or think about MAC. The choices have pretty much all been made for you.\n\nI think the easiest place for most companies to trip up is with user passwords and session management.\n\nIf you are commonly seeing issues in industry related to the building blocks of higher level encryption, then I feel like that\u2019s a very special sector of the industry.\n\nFrom my point of view, the OWASP recommendation seems focused on the right area. Your mileage may vary. I often think of this story: [If You\u2019re Typing The Letters A-E-S Into Your Code, You\u2019re Doing It Wrong](https://people.eecs.berkeley.edu/~daw/teaching/cs261-f12/misc/if.html)", "You seem to be comparing personal anecdotes to OWASP's metrics.\n\nThey are mapping vulnerability classes from the Common Weaknesses Enumeration (CWE) and taking a metrics-based approach to how often they occur in vulnerabilities reported as CVEs.\n\nThis really sounds like you don't like the CWE enumeration, but even then some of the vulnerabilities you mention are there...\n\n> they hard code an IV\n\nCWE-323 Reusing a Nonce, Key Pair in Encryption\n\n> they treat passwords like keys without running them through a password base key derivation function\n\nPossibly CWE-325 Missing Required Cryptographic Step", "Thank you for opening this up!\nI put my 2\u00a2 to WSTG in the past. OWASP guys are open to feedback.\nThat would be great if you got in touch with the draft's authors and suggested an updated version.\nI like your blog on crypto mistakes. It fits my experience as well. (I am running a pentest company)", "[removed]", "> I think you may be extrapolating your own bubble to represent a much larger part of the industry than it does\n\nI was previously a web security consultant.  I consulted to banks, telecommunication companies, insurance companies, and a number of small companies developing unique web applications.  I've also worked in retail and with logistic companies.  I've reviewed several hundred code bases.  I've found cryptography everywhere -- and most of the time it is wrong.\n\nAlso have a look at all the highly up-voted stack overflow questions about cryptography.  There are lots, and many of them are just wrong.  I have a blog about this coming soon.\n\nAlso, you can look for key words on GitHub and find hundreds and thousands/millions of results.  For example, Java's [IVParameterSpec](https://github.com/search?l=Java&q=IVParameterSpec&type=Code), or Java's [MessageDigest](https://github.com/search?q=MessageDigest&type=code) ,or .Net's deprecated [RinjdaelManaged](https://github.com/search?q=RijndaelManaged&type=code), or .Net's [deprecated PasswordDeriveBytes](https://github.com/search?q=PasswordDeriveBytes&type=code), or Node's [createCipheriv](https://github.com/search?q=createCipheriv&type=code)  (or the deprecated variant of [createCipher](https://github.com/search?q=createCipher&type=code) ).  And honestly, this is only a small sample of what's out there.\n\nSo, I am very confident that I am not misrepresenting the reality.  My \"bubble\" covers a very large group of applications you use day-to-day.", "All companies have secrets.\n\nI see secret PDFs, Excels, emails or part of the database that should be kept secret.\n\nWhen a company grows large enough, they inevitably need encryption if only for all legal matters.", ">  but even then some of the vulnerabilities you mention are there...\n\nI'm not sure you got my point.  The CWEs are there, but they give no examples of those in the **Description** or bullet points or the **How to Prevent** bullet points.  In other words, the description and how to prevent ignore the vast majority of CWEs they list under Cryptographic Failures.  My proposed change to the standard is that they include those CWEs in the Description and Prevention section.  That was the entire point of raising the issue that I linked to: https://github.com/OWASP/Top10/issues/540", "Thanks.  I have submitted a pull request to address this [here](https://github.com/OWASP/Top10/pull/563/files).", "This subreddit is about cryptography, not cryptocurrency", "OWASP is \u201cOpen Web Application Security Project\u201d.\n\nI don\u2019t see why they should be writing recommendations around PDFs, excel spreadsheets, or emails? (Outside of web apps that specialize in parsing and manipulating that kind of content\u2026 but that\u2019s too application specific for OWASP to care about, I think)\n\nIn a broader context, sure\u2026 but this topic is about OWASP\u2019s recommendations.\n\nRegardless, do people often pick bad IVs for their encrypted PDFs? I think that\u2019s handled by the software, and isn\u2019t something people often make mistakes about\u2026 which was the point that the OP was trying to make.\n\nIf your lawyers are mis-encrypting stuff.. that\u2019s unfortunate, but not relevant to OWASP recommendations", "OWASP has grown out of being simply about web years ago, they've even published guides on mobile applications and foster several projects like SAMM: a security maturity assessment framework.\n\nI do agree that companies that don't do development don't get into these crypto hurdles, but companies that do develop often end up writting some cryptographic code and that involves manipulating IVs and modes. Any mobile application that thinks \"I'll encrypt things on the phone, it'll be safer\" ends up copying some AES encyrption code from stackoverflow, it comes fast."]}
{"id": "pmz56t", "title": "Random bytes generator for generating private keys?", "url": "https://www.reddit.com/r/crypto/comments/pmz56t/random_bytes_generator_for_generating_private_keys/", "Created (UTC)": "2021-09-12 12:18:53", "body": "[https://gist.github.com/z-ninja/acaaa70ff6469faf5c62145696087ab1#file-random\\_generator-cpp](https://gist.github.com/z-ninja/acaaa70ff6469faf5c62145696087ab1#file-random_generator-cpp)\n\nI'm trying to make  a random generator, but I need opinion of experienced observer and advice on what testing techniques should be apply to random generator for testing its strength and conclusion if satisfying terms to be used as random generator for generating cryptographic private keys.", "post URL info": ["https://gist.github.com/z-ninja/acaaa70ff6469faf5c62145696087ab1#file-random\\_generator-cpp](https://gist.github.com/z-ninja/acaaa70ff6469faf5c62145696087ab1#file-random_generator-cpp)"], "author": "zninja-bg", "ups": "0", "downs": "0", "number of comments": "62", "comments": ["Don't do this.\n\nYou want to just ask the operating system for actual randomness (read from `/dev/urandom` on linux, for example).\n\nThe current time is *not* suitable for cryptographically secure randomness.", "* [CPU Time Jitter Based Non-Physical True Random Number Generator](http://www.chronox.de/jent/doc/CPU-Jitter-NPTRNG.html)\n* [The maxwell(8) random number generator](https://www.kernel.org/doc/ols/2014/ols2014-harris.pdf)\n\nThis is very difficult to get right, and it's only something to do as a\nlast resort.", "If you're gonna do it, do it right.\n\nhttps://www.nist.gov/publications/statistical-test-suite-random-and-pseudorandom-number-generators-cryptographic", "timing based trngs (like haveged) have an inherent problem: they're combining entropy collection with mixing. we do know that if the cpu is truly deterministic, they're deterministic too. so the so called \"jitter\" is nothing else then accumulated randomness coming from other hardware. but it gets mixed in a chaotic manner even before it affects timing, which is then mixed further by the algorithm.\n\ntherefore it is not possible to actually measure the entropy content. theoretically assessing it is also essentially impossible. in a hardware rich high end system, like a pc, they probably work fine. however, in such an environment, everything works fine. simple embedded systems are the problematic ones, and jitter might fail you in exactly those systems.", "[removed]", "Cannot stress the above enough. There are zero reasons to be writing your own and three zillion reasons not to. Whatever you\u2019re trying to do here, the best answer is to *just not*.\n\nThere are no tests you can write to prove that your PRNG is secure.", "[deleted]", "On Windows, either use a library, or read up on [BCryptGenRandom](https://docs.microsoft.com/en-us/windows/win32/api/bcrypt/nf-bcrypt-bcryptgenrandom)", "You have post a links to very interested documents. It will be a pleasure to read.\n\nThank you.", "Note that passing that test suite (or any other physically realizable test suite in this universe) doesn't mean the generator is safe for cryptographic use, but failing such a test suite means it's NOT safe.", "You can't even format the spam posts right, lol", ">There are no tests you can write to prove that your PRNG is secure.\n\nhttps://dilbert.com/strip/2001-10-25", "there is one reason for: fun. pretty strong reason too.", "In the newest kernels /dev/random and /dev/urandom both behaves similar to getrandom()", "\u201cI need an experienced observer to tell me if it\u2019s strong enough to generate cryptographic keys\u201d does not sound like it\u2019s for fun or educational purposes.\n\nIt\u2019s really not necessary to jump in to literally every discussion about this and helpfully remind everyone that it\u2019s fine to play around with crypto for learning purposes. We know. We get it. We all did it ourselves. Nobody cares about people trying to have fun, but we care about stopping people from shooting themselves in the foot.", "[deleted]", "While baby is learning to walk, baby will fall on the floor several times.\n\nBut as many times she fell, that many times will rise up until eventually learn how to walk normally.\n\nFor baby is fun to learn to walk.  \nI think that is what u/pint was trying to point out.\n\nWhile you have taken role of parent, the one it does:  \nDo not try to walk, you will fall again.\n\nOr: Do not make self a dinner, I will do it for you.\n\nLike you will be able whole life to do things instead of child.\n\nWe are learning from mistakes.\n\nSo, stopping people from shooting themselves into foot should be approach only if someone could die if you do not interrupt the person for doing what is doing.\nIn this thread example, your approach was like:\nChild: Daddy, I would like to become a scientist.\nDaddy: No, you can not become a scientist.\nThere are already enough scientists, they already do what you imagined to do.", "not fun for you. fun for the implementor. have you ever wrote software just for your own entertainment?", "[As of Linux 5.6, /dev/random only blocks until the RNG is initialized ](https://www.phoronix.com/scan.php?page=news_item&px=Linux-5.6-Random-Rework). It behaves the same as /dev/urandom after that.", "Oh gee gosh you caught me, no that\u2019s never happened.\n\nSerious question. Do you genuinely think these posts are helpful or insightful? Or is there at least some self-awareness that these posts are just a vehicle for you to feel smug?", "okay, if you can't take a hint: i'm a little bit fed up with the \"dryoc\" comments. these things don't pose any real danger to anyone. i'm not the one being smug here.", "See, me, I\u2019m tired of coming in and cleaning up the mess after some well-meaning but unqualified developer wrote some security-related code that \u201cdidn\u2019t pose any real danger to anyone\u201d until it actually did.\n\nAnd oddly despite all the concern about \u201cdryoc\u201d comments I thankfully don\u2019t see a drop in the number of people playing around with and learning crypto for fun and educational purposes. Astonishingly it seems as if people are actually capable of understanding the context of those comments.", "they don't pose any danger. perhaps to the implementor himself, but why would you care so much? it is perfectly enough to tell them that it is not or probably not secure, and call it a day. however, do that as a part of a meaningful reply, not instead of it. just saying to people: you are not worthy of cryptograpy, is just the very smug thing you accuse me of.", "\"don't deploy your own crypto\" is perhaps a better way of saying it. Lots of people have no clue how to implement it securely.", ">\tthey don't pose any danger. perhaps to the implementor himself, but why would you care so much?\n\nBecause\u2014and I genuinely don\u2019t know how to be any clearer about this\u2014*I\u2019m tired of having to come in and cleaning up the mess afterward*.\n\n>\thowever, do that as a part of a meaningful reply, not instead of it\n\nYou have been more than free to add this sort of additional information to the conversation. Instead you\u2019ve chosen to bicker about whether or not we should warn people when they\u2019re potentially going down a misguided path that many of us have personally seen end badly.\n\nIf this was so important to you, why haven\u2019t *you* done it instead of demanding it from others?", "my version is: don't trust untrustworthy software with your secrets.", "well i did. and i also posted a remark on your unfriendly and useless behavior after.", "Too many people don't understand risk well enough to judge that on their own", "Unfriendly is a subjective spin you\u2019re choosing to put on things. But at least you did do *both*, I\u2019ll give you that.", "that will not be fixed by shouting dryoc to implementors"]}
{"id": "pmfqaz", "title": "How to check for adiantum cipher support on Linux?", "url": "https://www.reddit.com/r/crypto/comments/pmfqaz/how_to_check_for_adiantum_cipher_support_on_linux/", "Created (UTC)": "2021-09-11 14:23:45", "body": "I wanted to know if my distribution supports the adiantum cipher so I checked \\`/proc/crypto\\` but there is no entry on aes-adiantum. Does it mean that my kernel has no support for adiantum? Am I missing something?", "post URL info": [], "author": "australis_heringer", "ups": "15", "downs": "0", "number of comments": "38", "comments": ["You can test run a benchmark to see if it's available and working (you may need to enable it first in kernel config) \n\nhttps://www.reddit.com/r/crypto/comments/b3we04/_/ej32sjf\n\nCtrl+F in link below for using it to encrypt\n\nhttps://www.kernel.org/doc/html/v5.8/filesystems/fscrypt.html", "So, the benchmark do works, but why isn't it shown on /proc/crypto?"]}
{"id": "plobsm", "title": "Security of End-To-End Encrypted Backups: Whatsapp Whitepaper [pdf]", "url": "https://scontent.whatsapp.net/v/t39.8562-34/241394876_546674233234181_8907137889500301879_n.pdf/WhatsApp_Security_Encrypted_Backups_Whitepaper.pdf?ccb=1-5&_nc_sid=2fbf2a&_nc_ohc=XhVTjVGfRagAX8rykfP&_nc_ht=scontent.whatsapp.net&oh=09b54601888e3da5a9387aa77ce2b260&oe=6140577C", "Created (UTC)": "2021-09-10 09:21:47", "body": "", "post URL info": [], "author": "espadrine", "ups": "39", "downs": "0", "number of comments": "37", "comments": ["I just read the white paper from Facebook and wanted to ask the question here too. Glad someone posted it here too.\n\nPerhaps someone can explain why they really need the hardware module to store the backup key? As I understand, the backup key is encrypted on the client device using a user password based key encryption key KEK. So, there should be no way for WhatsApp or Facebook to access the plaintext backup key. The only benefit is probably that part about tamper resistant against repeated attack and automatically destroy the key. However, if the backup key is already encrypted with a reasonably strong encryption and password KEK, then there should not even be worry about the encrypted backup key being leaked in the first place? \n\nAll those cloud based password manager such as lastpass or bitwarden is also based on client side KEK to ensure the security of the passwords being stored in the cloud. But they also don't need such elaborate hardware module to keep the cloud storage safe?", "I'm unable to access the link, I get an error saying that the signature on the URL expired. I assume [this](https://www.whatsapp.com/security/WhatsApp_Security_Encrypted_Backups_Whitepaper.pdf) is the same content?", "From what I understand, this protects against low-ish entropy user passwords being brute-forced through an attack, either online or with access to the Facebook internal private network.\n\nIt reminds me a bit of [Signal SVR](https://signal.org/blog/secure-value-recovery/), in that part of the protection is server-side temper-proof hardware (SGX, in the case of SVR).", "Yes! I didn\u2019t know the link was on a timer. That isn\u2019t great.", "That's how google encrypted backup works too. Since it verifies a PIN, which is low entropy, it has to verify it within an HSM.", ">\tFrom what I understand, this protects against low-ish entropy user passwords being brute-forced through an attack, either online or with access to the Facebook internal private network.\n\nYes, the \u201cprivileged backend\u201d. Apple uses HSMs for a similar purpose, since some things are protected with a key wrapped with a 6 digit passcode, which is low-entropy.", "Oh thanks. Interesting to see the length they have go thru just to protect against weak user passwords. On most sites, they will just say if your password is weak and account is being compromised, that's just users' responsibility."]}
{"id": "plo2iw", "title": "Running Numpy programs homomoprhically | FHE.org meetup", "url": "https://www.reddit.com/r/crypto/comments/plo2iw/running_numpy_programs_homomoprhically_fheorg/", "Created (UTC)": "2021-09-10 09:08:30", "body": "The next FHE.org meetup will be on Sept 30th at 6pm Paris time\n\nThe team at [Zama](https://zama.ai) will present a homomorphic Numpy compiler, and do a live demo of a homomorphic RNN.\n\nTo attend: https://www.meetup.com/fhe-org/events/280689265/ \n\nSee you there!", "post URL info": ["https://zama.ai)", "https://www.meetup.com/fhe-org/events/280689265/"], "author": "randhindi", "ups": "6", "downs": "0", "number of comments": "27", "comments": []}
{"id": "plnruq", "title": "Do you think that a bachelor's degree in physics is worth attaining for post-quantum crypto?", "url": "https://www.reddit.com/r/crypto/comments/plnruq/do_you_think_that_a_bachelors_degree_in_physics/", "Created (UTC)": "2021-09-10 08:54:00", "body": "I'm particularly curious about the answer to this question because I'm approaching a time in my life where I can choose to do a physics double major on top of math. On one hand, four years of study seems a little excessive but on the other hand how is it possible to do post quantum crypto research without knowing any quantum theory? How do people usually go about this and how does it compare to doing a double major in computer science? Would doing a double major in computer science still be more favorable if you wanted to do pq-crypto research?", "post URL info": [], "author": "None", "ups": "6", "downs": "0", "number of comments": "30", "comments": ["The useful thing would be to find a class on quantum information or quantum computing, which could be taught in a physics, CS, or an EE department.  You do not need a physics degree to work in post-quantum crypto research. There is likely a small benefit for understanding if you take a quantum mechanics class from a physics department, but that's just giving you context for quantum computing.  It would be like a CS student taking an EE class to understand how a computer works; it's nice and cute and all, but not necessary.\n\nThe majority of people who work on post-quantum cryptography do not work on quantum attacks or otherwise use quantum information in their papers. Look through the Simons Institute workshop on lattice tools (which was focused on post-quantum crypto) to see if you believe me:\n\nhttps://simons.berkeley.edu/programs/lattices2020", "I think its not a requirement to cryptography in itself, but might be for an expert in hardware security or for space technology.\n\nMyself I enjoy understanding the physical context of electronics (I did advanced science, electronics and programming), which gives me a deeper understanding of the whole stack, but, does it make my paycheck bigger? Nope. \n\nAnd its not necessary (unless you want to understand driver and kernel programming). I would assume the same scenario for quantum computing in the future. (Except maybe that programmers will need to understand both systems; electronic and quantum)\n\nPersonally, I don't understand the fuss around quantum circuitry. Its not \"ready\" yet. You can compare it to iron ferrule memory cards that were made by knitting ladies in the 50s for space missions. Circuits that require resetting after reading... hihihi... So yeah, plenty of discoveries left to be made on the physical side of the quantum equation, but perhaps quantum computers won't make it into mainstream, like protein-chips... I wouldn't divert too much time on it, programming and algorithms are much more important. And those can be applied to whatever physical system afterwards.\n\nQuantum applications right now are still bound by their physical properties and discoveries. Look at quantum annealing for example.\n\nPost-quantum crypto is still a moving target as far as I understand it. The only application is currently making algorithms quantum-resistant, which is, bit of a paradox without proper *public* quantum experimentation. Newer hardware will always accelerate crypto-cracking efforts drastically, that's computer-history-101. And mathematicians will always fail to see the future exploit on their algorithms. Nature of things.\n\nSo I would not detour on it too long myself.  Except for a basic understanding. But I'm biased. :D", "A physics degree is not necessary. You can study quantum information theory / quantum computing without touching any physics, and this is how it's taught in computer science courses.\n\nTo get a feel for what its all about I'd suggest watching some lectures by Ryan O'Donnell or Scott Aaronson.", "Honestly, I took a QM class and then a pqcrypto class, and the QM was basically irrelevant in the latter. Some QM is necessary if you want to learn how the attacks that make pqcrypto necessary work, but that was only a small part of my actual pqcrypto course. Even then you don't need to know most of QM for it, just the discrete parts (bra-ket notation, superposition/entanglement, but not stuff like time evolution or even the schr\u00f6dinger equation).\n\nDoing a full *degree* in physics is definitely overkill.", "It is very easy to do PQ research with no knowledge of quantum computing. Roughly cryptography research separates itself into a few \"levels\", such as:\n\n1. Underlying hardness assumptions\n2. Direct constructions of primitives\n3. Securely combining several primitives together for some purpose\n\nYou only need quantum computing to work on (parts of) the first point. Its important some people work in this area, but you could always focus on either of the other areas.", "> The majority of people who work on post-quantum cryptography do not work on quantum attacks or otherwise use quantum information in their papers.\n\nThis is totally true, and yet really should not be true. We need more people working in post-quantum cryptography who are knowledgeable in quantum attacks. If you don't know how to perform the attacks, then you are unlikely to know how to design schemes that are safe from attack. In lattice cryptography in particular, there are vast gaps in our knowledge of attacks, especially in the post-quantum context.\n\nYou definitely don't need knowledge of quantum mechanics to work in post-quantum cryptography. A class on quantum computing is enough. (I don't even have that, and I still have some papers on quantum attacks.)"]}
{"id": "plfauj", "title": "Understanding the Linear multipermutations in IDEA NXT", "url": "https://www.reddit.com/r/crypto/comments/plfauj/understanding_the_linear_multipermutations_in/", "Created (UTC)": "2021-09-09 23:06:45", "body": "Was looking into other AES finalist earlier and started with IDEA NXT from this pdf refered in wiki.\n\n[https://web.archive.org/web/20070928014200/http://www.mediacrypt.com/\\_pdf/NXT\\_Technical\\_Description\\_0406.pdf](https://web.archive.org/web/20070928014200/http://www.mediacrypt.com/_pdf/NXT_Technical_Description_0406.pdf)\n\nwas unable to understand what  linear multipermutations is . tried to find some simple explanations online . unable to find anything. Need some help", "post URL info": ["https://web.archive.org/web/20070928014200/http://www.mediacrypt.com/\\_pdf/NXT\\_Technical\\_Description\\_0406.pdf](https://web.archive.org/web/20070928014200/http://www.mediacrypt.com/_pdf/NXT_Technical_Description_0406.pdf)"], "author": "None", "ups": "12", "downs": "0", "number of comments": "24", "comments": ["If you want the precise definitions of mu4/mu8, you can find them in the original FOX proposal (the previous name of IDEA NXT) : https://crypto.junod.info//fox_spec_v1.2.pdf\n\nAbout multipermutations, I didn't know the term before but was able to find this : https://eprint.iacr.org/2014/085.pdf\n\nThe first page gives the definition of a multipermutation, and I guess the operations mu4/mu8 respect this definition, in addition to being linear.", "OH thanks ... earlier i thought it was some variant of permutation dependent on key --- but looks its diffrent ---- thanks for that second PDF"]}
{"id": "plb7nl", "title": "High school student interested in cryptography", "url": "https://www.reddit.com/r/crypto/comments/plb7nl/high_school_student_interested_in_cryptography/", "Created (UTC)": "2021-09-09 18:30:14", "body": "Hello,\n\nI am a Junior in a U.S. High School. I stumbled upon cryptography as a field that I would be very interested in, but my knowledge of it is zero. I have a few questions.\n\nObviously, I'm not planning on self-learning the entirety of cryptography, as that would be impossible. However, I would like to get myself a head start self-learning on some things, especially programming and computer science before college. What kind of things (online courses/**programming languages**/books/videos) would you recommend a high schooler learn or work on? Maybe some things that I could possibly put on a college application or resume? I will of course focus hard in my math classes.\n\nAs a side question, I do not particularly want to work for someone my whole life, and was wondering of what the startup/**entrepreneurship** environment is like in the cryptography sphere. I know that may be a silly inquiry, but nevertheless it is something I consider important at the moment.\n\nThere is not a large and formal \"learn cryptography\" community online, so any help will of course be appreciated. Thank you.", "post URL info": [], "author": "None", "ups": "22", "downs": "0", "number of comments": "43", "comments": ["The biggest thing a cryptographer is going to do freelance is probably consulting, e.g. validating software for banks and things along those lines.   \n\n\nFor programming, learn Python to start, and implement some simple algorithms, e.g. rot13 and a XOR cipher.  \n\n\nUse things like hackerrank and leetcode to boost your programming skills. Cryptography can be heavy on the math and algorithms side of things.", "You might enjoy the book \"Cracking Codes With Python: An Introduction To Building And Breaking Ciphers\" as a Introduction to programming in python and basic crypto concepts.", "I'm going to take a different approach. Let me introduce you to the world of CTFs. They are hacking competitions, and one of the categories in them is Crypto. There you can find broken implementations of different cryptographic algorithms and concepts, and you'll be tasked with breaking them. You can find everything from classic cryptography to RSA, Block Ciphers, ECC, etc.   \n\n\nYou can (and should) start with Python if you haven't already. After that, you can practice with sites like [cryptopals](https://cryptopals.com/) and [cryptohack](https://cryptohack.org/). There you can find the chance to learn the math essential to crypto, like XOR and some number theory. If anything cryptohack has a discord server you can join. And you can find competitions weekly on [ctftime](https://ctftime.org/). CTFs are a great way to have a path of what to learn while also gamifying the process. I'd say it's a nice chance to explore something new, and find out if you like the security side of cryptography more than the pure cryptography one. At any case, have fun :)", "On the entrepreneur side: I'm freelance in the infosec field with a good experience in cryptography, even if I'm not academically trained. I sell this as an area of expertise that I can use on penetration testing, so I'm more often being given crypto-heavy projects to work on. Basing your career on crypto would, in my opinion, require to have an academic background (e.g. PhD) and/or having contributed a major product/concept in the security landscape (think Moxie with Signal). Last I checked, being good with cryptography alone wasn't sufficient to bootstrap a freelance career.", "Crypto is just maths. If you are interested in the maths behind it all, reading up on discrete maths is a good start, and definitely something a high schooler can grasp. RSA is a simple algorithm that is foundational for the internet, and a good first algorithm to learn.\n\nA good first language to learn is Python. But for actually implementing cryptographic algorithms it's too slow, you need a low level language like C for that, so view Python as a starting point rather than the destination. I learned Python [10 years ago using this series of lectures from google](https://www.youtube.com/watch?v=tKTZoB2Vjuk), but there is probably something more up to date now.\n\nProgramming and computer science is a separate field of study. Someone that designs cryptographic algorithms will rarely be competent enough to implement it in code, and vice versa. I imagine from your last question that you might be more into learning how to implement and use cryptographic primitives to build cool things, rather than designing new primitives, so I would concentrate on learning how to program if I were you. You will get to learn the math in college.", "This is a good one for them all, and I believe they'll all get to learn a few things", "[removed]", "This would be better suited for /r/learnprogramming.", "[deleted]", "Many people have recommended to practice C as it is better from an implementation standpoint in a business environment. What is your take?", "Your account seems to be shadowbanned, FYI. Only moderators can see your comments, nobody else can unless us mods approve it first. You have to talk to the reddit admins if you want to fix it (us mods can not fix it).\n\nAlso, a reminder we tend give to a lot of the people who are new here, this subreddit is about cryptography, not cryptocurrency.", "This subreddit is about cryptography (encryption, etc), not cryptocurrency", "That's pretty intense. What problems did you actually need those for? I ended up getting so interested in this stuff during my first go at PE problems (a couple years ago) that I wrote a toy library of modular arithmetic / number theory / factorization stuff, but I never actually needed a Pollard-Rho / quadratic sieve / etc. level of heavy artillery for PE. And I'm nearly at level 5 now.", "Not recommended for security nowadays, in particular due to the high frequency of memory management related exploits in code programmed in C.", "Thanks a lot", "[deleted]", "The role of C depends very much on where you are in the cryptography spectrum. If you're working with low-level primitives, then I think C is the dominant implementation language for efficiency reasons. For example most (in fact, all?) of the [NIST PQCrypto candidates](https://www.nist.gov/pqcrypto) use C for their provided implementations.", "I mean, yeah, I know that\u2014it's not like I'm brute-forcing my way through PE\u2014so I'm wondering if there were any notable problems that really required that level of algorithm to produce a result in a reasonable time?", "[deleted]", ">you only need high school maths at most to solve them \n\nI dunno about that\u2014last I checked, modular arithmetic, combinatorics, and linear algebra weren't high school math."]}
{"id": "pkdfve", "title": "What are the most overrated cryptographic schemes, protocols, conferences, etc.?", "url": "https://www.reddit.com/r/crypto/comments/pkdfve/what_are_the_most_overrated_cryptographic_schemes/", "Created (UTC)": "2021-09-08 09:03:35", "body": "So?", "post URL info": [], "author": "davidw_-", "ups": "17", "downs": "0", "number of comments": "97", "comments": ["QKD -- not just overrated, outright rubbish.\n\nhttps://twitter.com/SmartCryptology/status/1432645860245000197", "I would say Homomorphic Encryption for the time being. While there have been a lot of promising developments the past years, it's still nowhere near productive use.", "MD5 (outside of our circles)", "Clipper Chip https://en.wikipedia.org/wiki/Clipper_chip", "[deleted]", "Quantum computers (not quantum cryptography).", "OPAQUE, people blindly believe it to be the best. Adding an OPRF to most aPAKEs makes a better aPAKE than OPAQUE. This might be due to IBM pushing this hard. A reason they're pushing OPAQUE is to get people to look at their patented AKE. We can add OPAQUE to IBM's cryptographic \"successes\" like DES and LM hash. And yes I have said \"OPAQUE is the LM hash of PAKEs\".\n\nAnyway, if they weren't trying to push their patented AKE then they would have made a better aPAKE \"OPAQUE-No-AEAD-Noise-KN\". Note this isn't actually a valid OPAQUE because of \"No-AEAD\".", "[removed]", "Signatures.", "Does this sub believe quantum computers will never exist?", "Rogaway had some not nice things to say about FHE in his paper on ethics. It always seemed like an interesting solution, but these days I\u2019m more impressed with what zero knowledge proofs can do.", "If you want privacy, you do not use FHE, that enables them to *compute* over your *private* data.\n\nFacebook et al. will market FHE as a solution to your privacy, yet data mine your *encrypted* data.\n\nIf you can *compute* over it, it is not *private*. The point of encryption is to not reveal anything.", "Cryptomeanscryptographyrant", "Despite bitcoin being called a \"cryptocurrency\" the cryptography is only a small part. Coins are protected with digital signatures and distributed consensus is established using a one-way function (in the case of bitcoin it's SHA256 applied twice). But that's already it in regards to cryptography. There are other electronic cash systems like Monero which are very crypto-intensive.", "I\u2019d say specifically, proof of work is overrated.", "The point of Bitcoin is absolutely not just to store data. The point of Bitcoin is the ability to securely transfer ownership of digital tokens to anybody in the world without having to use a trusted third party intermediary.\n\nThe reason people dont understand why this is so revolutionary is because they have absolutely no idea how the banking system actually transfers money around.\n\nBanks transfer money between customers using a trust model. Banks need to have trust between themselves in order to transact on behalf of their customers. The fact that the entire system is built on trust makes it incredibly fragile, vulnerable, and slow. Ask youself why bank transfers between countries take days to settle? Its a huge clusterfuck, and there is absolutely no question that blockchain tech, or something very similar, will replace it", "Which better ones?", "I'd say even Quantum Cryptography, specifically Quantum Key Distribution. It requires entangled quanta linking the ends directly. That means it needs a fully connected mesh network of such links to work for more than two parties. The length limits are extremely low, the expense enormous, and all it gets you is a symmetric key exchange. So while that's \"perfectly\" secure, you're still bounded by the security of the symmetric algorithm you use to actually communicate.", "The amount of FUD there is interesting, but the amount of cool crypto that came out of that is interesting as well :) mixed feelings.", "This subreddit is about cryptography, not cryptocurrency", "Quantum Key Distribution (QKD) has nothing really to do with quantum computers. It's a way to use quantum entanglement thingys (technical term) to securely create a shared key between two parties, that is resistent to eavesdropping. This key is then used for symmetric classic encryption to send actual data.\n\nThere's a lot of problems with this, limiting it's usefulness. The biggest one probably being that you have no protection against MITM-attacks, so to combat this you first need to have a shared key between the parties (which begs the question of why you bother with this in the first place...).\n\nOther problems include that connections need to be point-to-point - making it easy to interrupt the key exchange, repeaters of the connection are essentially \"trusted\" MITM breaking the whole system etc.\n\nFun to play with in the lab, and interesting mechanisms behind it, but not really useful for anything as far as I can tell.", "QKD has nothing to do with quantum **computers**\n\nI also do believe that CRQC (new abbreviation, apparently \"Cryptographically Relevant Quantum Computers\") will never exist but that is a belief, not hard fact.\n\nQKD's problems are much more objective.", "Oh I would be interested in this, do you have a link on his paper?", "It's not that simple; it depends on who controls the keys. If I have the FHE secret key, then you can perform arbitrary computation on a ciphertext, but you won't learn any information about the underlying plaintext.", "If I need to protect confidential company data but want to leverage the benefits of cloud computing, HE sounds like the way to go but at the moment it's far from this. HE at the moment only allows addition and multiplication, no text comparison, no branching.", "I don't know why you say this, most schemes are based on RLWE, that is demonstrated to be hard.", "Any POW you think are better?", "When you involve already trusted parties, you don't need a blockchain.", "thanks bud\n\ninitials state crypto, hence the confusion", "Brb downvoting myself", "[https://web.cs.ucdavis.edu/\\~rogaway/papers/moral-fn.pdf](https://web.cs.ucdavis.edu/~rogaway/papers/moral-fn.pdf)\n\ngrep for FHE", "And you really think Facebook et al. are not going to have a key. Their entire business model is based around data mining you.\n\nFHE is marketed and sold as allowing companies to mine your encrypted data.\n\nThey will be computing to the extreme to reveal as much and profile you as much as they can. The more they can compute the more they can profile the more it reveals.\n\nIf you don't want to reveal anything you don't use FHE.", "There are FHE implementations more capable than that, however they all tend to be horribly inefficient", "Sure, but, in the context of messaging and privacy, they want to use it there, which imo is inappropriate if you want privacy.", "Congratulations, you can now transact with almost nobody. \n\nThe whole point of blockchain tech is that you dont have to exclude people who cant prove they are trustworthy, which is the majority of the third world, and those who are poor in the first world.\n\nAnyone can transact with anyone with blockchain tech because the system isnt so fragile that it is vulnerable to untrustworthy users.\n\nBlockchain is the future of finance because it lets you do things that people want to do that cannot be done in any other way.\n\nEthereum alone settled over 1.5 Trillion dollars worth of transactions in Q1 2021 and is one pace to settle around a total of $8 trillion this year. Most people do not know how large it has become, and it continues to grow.", "Thank you", "I agree that plenty of companies use fancy cryptography to \"privacy-wash\" their products, but that doesn't mean the cryptography itself is \"overrated\".\n\nEDIT: Also, if FB is going to keep the key, then there's no point to using FHE; it just imposes massive overhead.", "FB may *lie* and not use FHE at all while claiming to -- I wouldn't put it past them\n\nbut don't knock the math in FHE.  It's solid.  Slow, very slow (make that very very slow!), but solid.", ">And you really think Facebook et al. are not going to have a key\n\nThis sounds like \"AES is overrated, because Facebook can just override it with a copy of the key\". It's not at all a criticism of the underlying math.", "How do they avoid being oracles and leaking plain text information through computation?", "True, but with all kinds of metadata available already it doesn't really change much anyway if you do E2EE or HE", "Big banks don't need it though.\n\nAlso, this subreddit is about cryptography, not cryptocurrency.", "You can compute whatever function you want on them and will just get back a ciphertext containing the output. You still need the key to learn anything about what is under the ciphertext.\n\nWhen someone computes on your data then tells you \"hey I computes F on your data x, can you decrypt it for me please\", making sure you are actually decrypting F(x) is an entirely different problem (especially if F is also a function of *their* input)", "I think they mostly rely on constant time algorithms for that (not completely sure honestly).", "Not only that. You must also handle differential privacy attacks.", "No true.. Few people are aware of the clusterfuck that Big Banks have to go through to transfer money amongst themselves. Blockchain solves a fundamental problem, and most large banks are already implementing blockchain solutions", "So far so good, but you have to *do* something with the results of those calculations, e.g. write to other tables, dispatch emails/push notifications, etc. \n\nIt just feels like you're adding so many metadata sidechannels that it's just not practical to maintain perfect obfuscation, you'll still have to trust your cloud vendor at the end of the day.", "Differential privacy is more about the function being computed (ex learning a dataset) than how you do the computation without revealing anything other than the output (MPC, which can use FHE)", "As long as you're working with a set of parties all known in advance, there's no point in adding blockchains.", "The point is that FHE isn't the problem. Its what you're doing with the data that is the problem.", "The server can't accidentally leak, nor can see what's inside because they are encrypted. At the end of the day, you are the only one who can decrypt the result and do something useful with it. The whole thing assumes untrustworthy server.", "Not true at all.. you clearly have absolutely no idea how banks send transactions between them, and the absurd way that this is currently implemented. \n\nDistributed consensus problems are currently best solved by various flavors of blockchain, including private blockchains. This is why nearly every bank is researching blockchain tech, and governments are researching central bank digital currencies built on private blockchains", "Which loops back to FHE being overrated, since it doesn't really solve anything in practice.", "I think you misunderstand. I know plenty about how it's working now - but working badly now isn't magically a justification for implementing precisely the solution which you have in mind. There are other solutions that are better than both.\n\nAnd there's not really a distributed concensus problem when all entities involved are known and all transactions are following strictly defined rules with auditing. At this point it's just a coordination problem, which blockchains don't add any value to.", "This is 100% a distributed consensus problem. Clearly you have absolutely zero experience with distributed systems. If you did then you would immediately realize that even in systems with perfectly defined deterministic protocols, disagreements will ALWAYS arise (even from phenomena as exotic as Cosmic rays), and these disagreements have to be resolved in a distributed way. Furthermore, it is not the case that all banks in the banking system have full and perfect trust of eachother, or even deal with eachother directly. This isnt a fully connected graph. Sending money to many foreign banks will require multiple indirect hops because not all banks deal with all other banks directly, or even trust them.\n\nI dont really care what you think. You are free to believe in your silly version of reality. For my part, Im making a shit ton of money because the world is still filled with complete idiots who have no idea what the future holds and are still clinging to the past.\n\nBlockchain is the future simply because it allows people to do things that they want to do that no other technology will permit them to do, and it does it far more effectively than anything else. Its that simple. Entire new financial instruments are now possible that people didnt even dream of, like distributed autonomous organizations (DAO), decentralized lending and borrowing (DeFi), Non fungile tokens (NFTs), Decentralized exchanges (DEX), Smart contracts, decentralized oracle networks, Stable coins which have values that are pegged to fiat currencies, etc etc.\n\nWhat we are seeing is the distributed automation of key parts of both the legal system and the financial system. Removing trusted third parties, middle men, and systemic risk from all of it. You can deny its happening and get left behind, or you can hop on board.", "Literally none of what you're talking about need blockchains to fix, just basic error correction algorithms and atomic databases and deterministic and formally verified protocols for carrying out the transactions between banks.\n\nDisagreement between two *banks* around a transaction between them which they agreed on will *never ever* be resolved in a distributed way. Very centralized legal systems will be getting involved. \n\nYes, I know banks use intermediates. And? They can still do multi-hop atomic transactions across atomic databases. They still deal with the legal system, just potentially now across a few more jurisdictions. \n\nAnd how exactly are you making all that money? Daytrading cryptocurrency? Volatility will screw you over eventually if that's the case. \n\nI am perfectly aware that blockchains add new capabilities. The problem is that you don't recognize when and where they are appropriate to apply. They can be useful when you *do not* start with a fixed set of vetted and well known entities like banks, for example, and need to make certain types of transactions. This is not that. \n\nDecentralized exchanges are still consistently failing. NFT:s are merely digital trading cards. DAO:s keep getting hacked and keep being not useful. DeFi is full of scams (you should see our spam log). Decentralized oracle networks are just centralized oracles with extra steps. Stable coins keep failing too. \n\nSo basically, only smart contacts remains from that list. It's the only one both with a threat model that isn't insane and a usecase that isn't nonsense. \n\nI've been following Bitcoin since around 2011. I know a thing or two."]}
{"id": "pk5bw6", "title": "RFC 9106: Argon2 Memory-Hard Function for Password Hashing and Proof-of-Work Applications", "url": "https://www.rfc-editor.org/rfc/rfc9106.html", "Created (UTC)": "2021-09-07 23:50:18", "body": "", "post URL info": [], "author": "rgneainrnevo", "ups": "44", "downs": "0", "number of comments": "40", "comments": ["From https://www.rfc-editor.org/rfc/rfc9106.html#section-4-4.3 :\n\n> Frontend server authentication, which takes 0.5 seconds on a 2 GHz CPU using 2 cores -- Argon2id with 4 lanes and 1 GiB of RAM.\n\nI don't know what frontend servers they are running, but typical frontend web authentication requirements I see are usually stated in 100s or 1000s of auths/second. The hardware costs of implementing this recommendation would be insane. Why is it so far out of whack with the [OWASP recommendations](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html#argon2id)?", "Great to see this is out.\n\nI'm curious if anyone knows if there's plans for a follow-up RFC for using Argon2 with PKCS#5/PKCS#8 encryption, assigning OIDs and defining the relevant ASN.1 structures. See [RFC7914](https://datatracker.ietf.org/doc/html/rfc7914.html#section-7) as an example of this for scrypt.", "The recommendation sections needs some clarification or reworking:\n\n- I would really *really* like to see a rationale for Argon2id. If you fear timing attacks, what is the point of using something that will (after the timing attack) effectively be slower and weaker than Argon2i? What threat model are we defending against exactly?\n\n- I've heard that nowadays it's better to just run 1-lane Argon2 several times (with different nonces of course), and hash the results together. Harder to attack than a multi-lane Argon2 (don't remember the source, though).", "It's also out of whack with itself https://www.rfc-editor.org/rfc/rfc9106.html#name-recommendations:\n\n> The Argon2id variant with t=1 and 2 GiB memory is the FIRST **RECOMMENDED** option and is suggested as a default setting for all environments.\n>\n> The Argon2id variant with t=3 and 64 MiB memory is the SECOND **RECOMMENDED** option and is suggested as a default setting for memory-constrained environments.\n\nThe first is crazy high and takes ~2.5 core-seconds (i5-6500). The second in similar to PHP's default (t=4, 64 MiB). To match the second's strength to the first you'd need to do t=22, 64 MiB (ignoring the strength difference between 2 GiB and 64 MiB). Obviously one would need a higher number of iterations to make up for the memory difference.\n\nAnother crazy part https://www.rfc-editor.org/rfc/rfc9106.html#section-4-3:\n\n> Argon2id is optimized for more realistic settings, where the adversary can\u2026 mount cold-boot attacks.\n\nA cold-boot attack is literally read the memory and no version of Argon2 is safe. You can clear the memory when done but that can be done with any version of Argon2.\n\n> frontend web authentication requirements I see are usually stated in 100s or 1000s of auths/second.\n\nAdjusting the standard advice for throughput it's >10 auths/second/core. Since it's \"auth should take <100 ms\".\n\nThe other way to think of settings is from an attacker's point of view, cracking speed. So find the fastest GPU before the large drop in performance/cost or basically \"find the fastest GPU for ~US$700 MSRP in 2015 money\". The current \"GPU\" is RTX 3080 (RX 6800 XT is faster for PBKDF2-SHA256 and looking at memory and bandwidth Radeon VII might be faster for memory hard). Now good settings for auth will be <10 kH/s/GPU.\n\nNow you want to put both of those together. Max settings are \"10 auths/second/core\" and min settings are \"10 kH/s/GPU\". The problem is when min is harder than max. Luckily that only happens for old/slow servers and PBKDF2 because PBKDF2 is bad it should feel bad. Also most other sequential computationally hard algorithms. Except maybe Makwa (and similar) because GPUs are slow at multiplying large numbers.\n\n> Why is it so far out of whack with the [OWASP recommendations](https://cheatsheetseries.owasp.org/cheatsheets/Password_Storage_Cheat_Sheet.html#argon2id)?\n\nThe RFC settings are based on feelings and maybe future proofing. The OWASP recommendations are minimums and will change when better hardware comes out. Also I was the one that came up with those and they are based on benchmarks. The Argon2 and scrypt settings are based on a GPU's max bandwidth (ie ideal cracking speeds). I have a tweet about this https://twitter.com/Sc00bzT/status/1372209728097517571.", "Edge compute", "This has been in the very first draft (the only change being swapping 2i for 2id in -02 in the post-CFRG-adoption draft around 2017) and I couldn't find any discussion about this on the cfrg mailing list. Hard to tell how they came up with that.", "Can we just repeat the password hashing competition? I think we've learned a lot since Argon2.", "> I would really *really* like to see a rationale for Argon2id. If you fear timing attacks, what is the point of using something that will (after the timing attack) effectively be slower and weaker than Argon2i? What threat model are we defending against exactly?\n\nI don't know, but at least Argon2id makes the attacker need to do some work vs Argon2d (after the timing attacks). Also Argon2id can be safely run with t=1 while Argon2i needs at least t=3. But I'm pretty sure the rational is \"we don't think you can do a timing attack in practice because they're fuzzy but if you want to pretend you're safe do Argon2id\". Which I'm like meh fine do Argon2i for the first half round it doesn't hurt that much.\n\nNow if Argon2id was all but the last half round is Argon2i then do Argon2d of a half round and you're told to do at least t=3 to have good timing attack resistance. Then I can't see a good reason for Argon2i because this removes the half memory attack on the last round of Argon2i because last half round is Argon2d and you don't know what blocks won't be read again. But I'm not sure this will thwart other Argon2i attacks. I'm sure there are die hard constant time people that will want no timing attacks. So you'd still need to keep Argon2i around.\n\n> I've heard that nowadays it's better to just run 1-lane Argon2 several times (with different nonces of course), and hash the results together. Harder to attack than a multi-lane Argon2 (don't remember the source, though).\n\nThis is wrong.\n\n1) Argon2 t=t', m=p\\*m', p=p'\n\nvs\n\n2) Running (Argon2 t=t', m=m', p=1) p' times and hashing together\n\nFor (1) if an attacker doesn't have p\\*m' memory then they can't run it. For (2) if an attacker doesn't have p\\*m' memory but has m' memory then they can run it with less threads.\n\nAs a side note, you should use p=1 for Argon2 if you are using it for auth. Unless you have set up a queue and looked at throughput instead of wall clock time of doing one password check.", "You're not the first to ask. I think it's /u/sc00bz who asked for the competition to be restarted with CPU cache hardness as a target instead of RAM memory hardness as a target.", ">  at least Argon2id makes the attacker need to do some work vs Argon2d (after the timing attacks). \n\nSure it does. But then we really need to quantify the threat model:\n\n* What\u2019s the attacker advantage on Argon2i?\n* What\u2019s the attacker advantage on Argon2id?\n* How probable, is an actual timing attack?\n* What\u2019s the attacker advantage on Argon2id after the timing attack?\n\nLet\u2019s assume for instance the totally fake and made up following numbers:\n\n* Attackers guess passwords 6 times as fast as a honest verifier on Argon2i.\n* Attackers guess passwords 1.5 times as fast as a honest verifier on Argon2id.\n* Attackers guess passwords 12 times as fast as a honest verifier following a timing attack on Argon2id.\n* The provability of a successful timing it 10%.\n\nSo, 90% of the time, attackers will have almost no advantage, and 10% of the time, they will be an order of magnitude faster. While on Argon2i, they\u2019re thrice as fast 100% of the time\u2026 and I still don\u2019t know which would be better with those made up numbers\u2026 a mere order of magnitude difference is not much after all.\n\n\n> 1. Argon2 t=t', m=p*m', p=p'\n> 2. Running (Argon2 t=t', m=m', p=1) p' times and hashing together\n>\n> For (1) if an attacker doesn't have p*m' memory then they can't run it. For (2) if an attacker doesn't have p*m' memory but has m' memory then they can run it with less threads.\n\nI believe we can safely assume the attacker has enough memory. Almost all threat models involve the attacker having access to a supercomputer, or even dedicated silicon. I\u2019m more interested in the advantage, measured by time\u00d7energy\u00d7amount of silicon.\n\nNow I\u202freckon my suggestion has a much better time/memory tradeof (it\u2019s linear up to the number of threads), so that may indeed affect the advantage I mentioned.", "Can we also make NIST run it so it becomes FIPS instead of yet another hash you can't use in FIPS mode?", "It might of been Jeremi Gosney that said this first.", "> > at least Argon2id makes the attacker need to do some work vs Argon2d (after the timing attacks).\n> \n> Sure it does. But then we really need to quantify the threat model:\n> \n> * What\u2019s the attacker advantage on Argon2i?\n\nAttacker can precalculate all the lookups which saves some computations. Also an attacker can stagger several instances. When one is on the last iteration it can free up memory that is not going to be read again. This memory can be given to another instance on it's first iteration. Basically you can save half the memory on the first and last iterations vs just the first with id and d. So for 1 iteration you can use 1/4 memory and for more iterations it's (t-1)/t vs (t-1/2)/t for id and d.\n\n> * What\u2019s the attacker advantage on Argon2id?\n\nTiming attacks?\n\n> * How probable, is an actual timing attack?\n\nUnlikely? So let's assume p=1 and that m fits in L3 cache. If you could pause the thread after reads a block (1 KiB), then you test how long it takes to read each cache line (64 bytes). This let's you average 16 timings per block. Maybe that's enough? Now resume the thread until the next block is read.\n\nFor p>1, you just pause all then resume one thread until the next block is read. Pause that, resume the next for a block etc.\n\nFor m that doesn't fit in L3 cache, you only get knowledge that 1 of m/L3_size blocks was read.\n\n1. If you can cause the CPU to read without changing cache, then you can test as many timings as you want per block.\n2. If you can cause the CPU to read something as a different vm and without changing cache, then it doesn't matter that m doesn't fit in L3 cache.\n\nMaybe there's a privileged instruction to do (1) but I doubt you can do (2).\n\n> * What\u2019s the attacker advantage on Argon2id after the timing attack?\n\nThe following assumes a perfect timing attack (ie you know which block was read and when (in the algorithm) and by which thread). I have a reddit post on this but basically for p=1 it's equivalent to Argon2i m=m'/2, t=1, p=1. It's trickier with p>1 but there's a chance that it's as low as Argon2i m=m'/2/p, t=1, p=1 or as high as Argon2i m=m'/2/p\\*3, t=1, p=1 (assuming p>3 and smallish m). If m is large then as high as Argon2i m=m'/2/p\\*1.5, t=1, p=1.\n\n> Let\u2019s assume for instance the totally fake and made up following numbers:\n> \n> * Attackers guess passwords 6 times as fast as a honest verifier on Argon2i.\n> * Attackers guess passwords 1.5 times as fast as a honest verifier on Argon2id.\n> * Attackers guess passwords 12 times as fast as a honest verifier following a timing attack on Argon2id.\n> * The provability of a successful timing it 10%.\n> \n> So, 90% of the time, attackers will have almost no advantage, and 10% of the time, they will be an order of magnitude faster. While on Argon2i, they\u2019re thrice as fast 100% of the time\u2026 and I still don\u2019t know which would be better with those made up numbers\u2026 a mere order of magnitude difference is not much after all.\n\nIf you compare Argon2i t=3, m=64 MiB, p=1 and Argon2id t=1, m=256 MiB, p=1 (both of these read and write a total of 512 MiB each), then Argon2id after a timing attack is basically Argon2i t=1, m=128 MiB, p=1. Which is at least twice as fast to attack than Argon2i t=3, m=64 MiB, p=1 and needs a little more than 32 MiB of memory per thread when running several in parallel. Then there's the other Argon2i t=1 attacks that I'm not too familiar with.\n\n> > 1. Argon2 t=t', m=p\\*m', p=p'\n> > 2. Running (Argon2 t=t', m=m', p=1) p' times and hashing together\n> >\n> > For (1) if an attacker doesn't have p\\*m' memory then they can't run it. For (2) if an attacker doesn't have p\\*m' memory but has m' memory then they can run it with less threads.\n> \n> I believe we can safely assume the attacker has enough memory. Almost all threat models involve the attacker having access to a supercomputer, or even dedicated silicon. I\u2019m more interested in the advantage, measured by time\u00d7energy\u00d7amount of silicon.\n\nOh then they are the same time\u00d7energy\u00d7amount of silicon.\n\n> Now I\u202freckon my suggestion has a much better time/memory tradeof (it\u2019s linear up to the number of threads), so that may indeed affect the advantage I mentioned.\n\nAs a defender (1) can run a little slower than (2) because (1) has to wait for all threads to finish their work 4\\*t times vs 1 time for (2)."]}
{"id": "pju6l6", "title": "age - A simple, modern and secure encryption tool (and Go library) with small explicit keys, no config options, and UNIX-style composability.", "url": "https://github.com/FiloSottile/age", "Created (UTC)": "2021-09-07 12:34:27", "body": "", "post URL info": [], "author": "binaryfor", "ups": "41", "downs": "0", "number of comments": "52", "comments": ["We like this, and we use/promote this, but we should also explain why this is an acceptable library compared to something else.", "Although potentially impressive, after 60 seconds of looking at it.  I can only tell it uses Curve25519, what's the symmetric algorithm.  I think you could update the documentation to say what primitives you are using.", "I took the time to read through the code, and it gave me no reason to feel confident in its security. But it is written in Go.", "[removed]", "the important thing: can i sign git commits with age? does git support different signing modes/methods/tools?", "I'd specifically like an explanation from OP as to how they know it's secure, what it's secure against (just better defaults compared to other solutions, or did it get audited by competent third parties).", "It uses ChaCha20Poly1305 as the symmetric cipher, with segmented AEAD based on the STREAM nonce-based OAE construction", "The entire spec is only eight pages, and linked right from the project's README: https://age-encryption.org/v1\n\nAgainst OpenPGP being spread across several RFCs, just RFC4880 being 90 pages long.", "> But it is written in Go.\n\nby the guy who is the golang project's Security Lead.  Don't forget that.\n\nIOW, any project using golang's standard crypto libraries is using either his code or code that he has overseen.\n\nnot sure about you, but to me that gives me a lot of confidence.  If I were qualified to review the code I probably would, but as it is, this is plenty good enough for me.", "That sounds like something I would say about a lot of code. But given this is run by someone who's written so much Go crypto code, I don't feel this should pass without some clear examples and descriptions of what you don't like. Certainly nothing in the spec is consistent with this view.", "Why are you copying other comments?", "Git doesn't officially support any signing method IIRC, but there's standardized tooling around OpenPGP signatures for Git.", "Better defaults, modern algorithms used, and they don't give options that allow for misuse. age only encrypts and decrypts. minisign only signs and verifies. They both work with Unix pipes.", "I'm not OP, but I don't see why OP can't post something relevant without having such proof.\n\nThat said, Age mandates modern ciphers, and solves a wide range of problems associated with crypto agility and strange packet encoding formats. It's written in Go and as an open standard, has a Rust alternative, but every implementation I'm aware of is memory safe.\n\nIt remove the cruft of things like keyservers, which some people are critical of, but those people should consider just how problematic they've always been and that GPG's keyservers are barely functional at the moment.\n\nThe public keys are very small, easily copy pasted and far easier to pass around or place on a command line than a PGP key.", "The `age(1)` manage versus `gpg(1)`:\n\nhttps://twitter.com/AaronToponce/status/1364775738050703367", ">https://age-encryption.org/v1\n\nWhere does it say what primitives are used without deep diving?", "I see, being on the golang team makes him a leading cryptographer. I guess since I've met Rob Pike, and he helped created Go, that makes me an astronomer.\n\nI would love for this to be awesome, but I need to see some validation for me to have any confidence in it. But what the hell do I know?", "Git itself supports GPG directly, which feels like official support for OpenPGP. And looking at the technical docs just now, the signature format is specified to use OpenPGP signatures. I don't think this was originally the case though.\n\nAnd of course, there is third party support for S/MIME, so I suppose something similar could be done for age with relative ease.", "Thanks for a rundown. Do you happen to know if they've been audited yet?", "> They both work with Unix pipes.\n\nWorth being aware these pipe examples produce corrupt output when used with Windows Powershell.", "> and that GPG's keyservers are barely functional at the moment.\n\nShit, one shut down not that long ago because of GDPR.  It's just not a good design at this point.", "Just under the Format header, along with the details about base64 encoding, etc, there's this paragraph;\n\n> encode(data)\u00a0is\u00a0canonical\u00a0base64 from RFC 4648 without padding.\nencrypt\\[key](plaintext)\u00a0is ChaCha20-Poly1305 from RFC 7539 with a zero nonce.\nX25519(secret, point)\u00a0is from RFC 7748, including the all-zeroes output check.\nHKDF\\[salt, label](key)\u00a0is 32 bytes of HKDF from RFC 5869 with SHA-256.\nHMAC\\[key](message)\u00a0is HMAC from RFC 2104 with SHA-256.\nscrypt\\[salt, N](password)\u00a0is 32 bytes of scrypt from RFC 7914\u00a0with r = 8 and P = 1.\nRSAES-OAEP\\[key, label](plaintext)\u00a0is from RFC 8017 with SHA-256 and MGF1.\nrandom(n)\u00a0is a string of\u00a0n\u00a0bytes read from a CSPRNG like\u00a0/dev/urandom.", "as I said, absent the qualifications to actually review the code, **I** consider this good enough.\n\nemphasised the \"I\", since you appear to have missed the \"for me\" in my previous message.\n\nI'm not objecting to your stance -- more power to you for being that paranoid.\n\nBut then, you also need to make sure you're not using any tool that uses go's native crypto.\n\nEdit: And he's the security *lead* not just \"on the team\".  But perhaps that distinction does not make a difference to you", "What would give you validation?", "In this case I think it's worth separating the protocol from the client. But yeah, it's kind of an officially approved bolt-on signature mechanism, as compared to signatures being part of the Git protocol, which is what I meant. The signatures aren't an integrated part of the repo's or commits, but are distributed together with them in a standardized way.", "I don't think so, but neither has GPG (the obvious competitor).", "Thanks.", "nothing; he's just being ornery\n\na guy who counters my statement that the guy who created age is also the golang project's security lead, by saying things like:\n\n> I've met Rob Pike, and he helped created Go, that makes me an astronomer\n\nwhich doesn't make any sense at all, clearly just wants an argument.", "To start, very broad test coverage. But I am sure the author knows that and will do it eventually, given his experience with HeartBleed.", "I don't know if this counts as audit, but we do know [GPG has had problems in the past](https://www.di.ens.fr/~pnguyen/pub_Ng04.htm).", "gpg was audited at least once by the BSI (german bureau for cybersecurity)", "Yes, the [NVD CVE list](https://nvd.nist.gov/vuln/search/results?form_type=Basic&results_type=overview&query=GnuPG&search_type=all&isCpeNameSearch=false) for GnuPG is a good start. A bunch of those are due to issues with the OpenPGP spec, not just GPG. It's simply too complex with too many options.\n\nOpenSSL's long history of CVEs is pretty well known. Some issues like Heartbleed were coding errors, others like Logjam were problems with an overly complicated encryption spec (and backwards compatibility).\n\nTrueCrypt/VeraCrypt are container/disk encryption, they don't encrypt individual files. And their use of XTS mode is potentially problematic, since it leaks information about what ciphertext has changed over time.\n\nMost cryptographic software hasn't actually had a full audit, that tends to be reserved for a libraries or those trying to pass FIPS compliance (which is more box checking than security auditing). Instead we just wait for vulnerabilities to be discovered. This is (IMO) suboptimal, but software engineering is a very immature discipline and reliability hasn't been figured out well, certainly not to the same extent as in other engineering fields."]}
{"id": "pjpfsr", "title": "kmstats - A tool for qualifying pseudo-random/random datasets", "url": "https://www.reddit.com/r/crypto/comments/pjpfsr/kmstats_a_tool_for_qualifying_pseudorandomrandom/", "Created (UTC)": "2021-09-07 08:35:01", "body": "[https://github.com/pvial00/kmstats](https://github.com/pvial00/kmstats)\n\nkmstats is a tool I've created to qualify sets of data as pseudo-random or random.  It's eventually meant to be a replacement for people that use \\`ent\\` and is entirely it's own beast incorporating various statistical tests and individual thresholds per test.  It's original design parameters are similar to NIST's NIST SP-800-90B in that it qualifies approximately 1 megabyte of data although I hope to expand this to qualify any length of text.\n\nThe tool is still experiemental but very usable.\n\nkmstats comes in 2 binaries (kmstats256 for binary data) and (kmstats26 for A-Z data).", "post URL info": ["https://github.com/pvial00/kmstats](https://github.com/pvial00/kmstats)"], "author": "None", "ups": "4", "downs": "0", "number of comments": "29", "comments": ["First and foremost, before anyone uses their tool, they should be well aware of what entropy and randomness is.  The difference between a fair die and a loaded die is the dice itself, not the outcome of the tosses. Yes, even though the point of statistical tests is to attempt to measure if the die is loaded or not, no actual observed sequence can be a definitive measure (especially with a few number of tosses).\n\nThat being said, there are already tools that attempt to do such batteries of tests. The Diehard (NIST SP 800-22) and Dieharder libraries exist and provide a great number of tests.\n\nFinally, passing of such tests is no indication of security! Perfectly bad pseudorandom generators like the Mersenne Twister defeat all such statistical tests but is also horribly insecure.", "What do you mean by this comment?  Isn't a PRNG's theoretical \"randomness\" entirely defined by it passing some series of statistical tests and simulations?  Mersenne for example does fail on some of the tests, that's why we know its cryptographically insecure.  Are there examples of PRNGs that pass all statistical tests but fail some type of analytic (or other type I don't know of) attack?\n\n>Nonetheless, since its very definition a number of problems plagued the Mersenne Twister. First of all, it would have failed statistical tests designed to find bias in linear generator, such as the Marsaglia\u2019s binary-rank test \\[20\\] and the linear-complexity test \\[3, 7\\] (see Section 2). On the other hand in 1997 few public, easy-to-use implementations of such tests were available, and finding bias at the largest state sizes would have required an enormous amount of computing time.\n\nhttps://arxiv.org/pdf/1910.06437.pdf", "There are issues with those tools (NIST, dieharder).  Dieharder is designed to actively test pseudo-random number generators (including the ones builtin), it does work on static sets of data but they have to be fairly large.  NIST's test takes a long time to run to qualify 1MB.  I believe there is a more efficient, more portable way that gives some sort of statistical report to the user.  This is what kmstats hopes to accomplish.", "> Isn't a PRNG's theoretical \"randomness\" entirely defined by it passing some series of statistical tests and simulations?\n\nFrom a purely cryptographic perspective, there is a strict definition of what a cryptographically strong pseudrandom generator is.  It is a positive definition (i.e. [you have a proof of security](https://en.wikipedia.org/wiki/Cryptographically-secure_pseudorandom_number_generator#Definitions)), and not just \"passes a bunch of tests\".\n\n> Are there examples of PRNGs that pass all statistical tests but fail some type of analytic (or other type I don't know of) attack?\n\nI gave the Mersenne Twister as a great example of what you asked for, it passed older tests, until people came up with more! If you want broken things that pass all modern tests too, old broken encryption schemes (think DES, modified into a PRG) will also pass all such tests but still be insecure.  That's why you need a positive definition of security for CSPRNGs, not a test-based one.\n\nTaking it from a practical perspective and not a mathematical perspective (since all provably secure CSPRNGs are much slower than the ones used in practice), modern PRG design is not based on tests.  It is based on modeling best-known attacks rather than best-known tests, and modeling security based on reductions to such things.  Granted, attacks will also improve in the future, it's a much more rigorous way to build PRGs than just test-based.  Tests are there as an important sanity check.", "For a regular PRNG yes, for a CSPRNG then no (cryptographically secure PRNG). The latter is defined by being unpredictable given all externally observable information, to a computationally bounded adversary. \n\nJust see Dual_EC_DRBG, as well as any proper cryptographic algorithm deliberately seeded with too little entropy (that bug Debian had one time).", "There's only one test that a CSPRNG can pass that would prove it's cryptographically secure (that's both necessary and sufficient). That's the [next-bit test](https://en.wikipedia.org/wiki/Next-bit_test). \"Reasonable computation power\" means a [Probabilistic Turing Machine](https://en.wikipedia.org/wiki/Probabilistic_Turing_machine) using polynomial time and unlimited memory. \n\nSince that test requires *all possible attackers* to fail to predict the next bit given all previous bits (but not the seed), it's not a physically possible test. \n\nThat's why we don't depend on tests, but instead on positive security definitions. Tests that can actually be executed in this universe can't work.", "Well this answer is much more clear than the second one.  I'll clarify why I asked my comment although I think we're aligned.\n\nThe next-bit test implies that there exist a set of (polynomial time) statistical tests that can cover all known PRNGs.  That's what I understand when I read [Thm 3](https://www.di.ens.fr/users/phan/secuproofs/yao82.pdf) a long time ago.  Stretching the domain over the range also begets a distributional test by definition.  Correct me if I'm wrong.\n\nState compromise extensions are just constraints of how we construct that CSPRNG in particular, they don't really change the statistical requirements of the CSPRNG right?  Is this what you meant by \"modeling known attacks\"?  Even ones that aren't provably secure should still be provably secure against all known statistical tests and its hard for me to imagine an attack where one wouldn't also be able to construct a statistical test by which to test a CSPRNG against that failure.  Maybe this is where I'm not up to the state of the art.\n\nSo I guess my question should have been: Do there exist methods to prove that a polynomial time statistical algorithm exists for a given CSPRNG without giving a construction of that statistical algorithm?", "> The next-bit test implies that there exist a set of (polynomial time) statistical tests that can cover all known PRNGs. \n\nThe set is infinite, it is \"for all polytime tests\", not \"for some set of polytime tests\": that's why it is desirable to have a proof rather than an enumeration of tests.\n\n>  Even ones that aren't provably secure should still be provably secure against all known statistical tests\n\nYes, statistical tests are a form of attack, I was just trying to make the point that the set of attacks known to us is larger than just the set of statistical tests known to us, and this includes looking at the structure of the PRG itself.\n\n> Do there exist methods to prove that a polynomial time statistical algorithm exists for a given CSPRNG without giving a construction of that statistical algorithm?\n\nEither you have a proof of security or you don't.  If you don't, there isn't necessarily an attack, but you also can't say that it is provably secure.  Most practical CSPRNGs fall into this gray area.  If you're interested in non-constructive proofs, the probabilistic method (the intro book by Noga Alon is one of my favorite reads) is one way you can get such existence theorems.", ">Yes, statistical tests are a form of attack, I was just trying to make   \nthe point that the set of attacks known to us is larger than just the   \nset of statistical tests known to us, and this includes looking at the   \nstructure of the PRG itself.\n\nWell this is where I'm confused.  How can a known attack (even an attack that utilizes whatever criteria the cryptologist uses for a state compromise exemption) not also imply a statistical test that could be used to detect if that attack will work (which also implies that there exists a polynomial time algorithm that can predict the next-bit etc...)?   I'll read that book but if you have an example of a non-constructive proof of test (or Polynomial time predictive algorithm) I'd love to see it because I'm having a hard time imagining it but I'll take your word for it that it exists.\n\nI don't know much about security proofs so maybe this is a second point of misunderstanding on my part, but don't most security proofs of CSPRNGs (at a high level) boil down to proving that some generating function a) passes all statistical tests (protects against all known attacks however you want to look at it) known at the time of construction or b) is equivalent to a hard problem (which passes all statistical tests/attacks etc...) known at the time of construction? (in addition to proving forward-security/other properties/blah blah?\n\nLike to me it seems like expanding that list of infinite (countable) tests on a given generating function is equivalent to the problem of picking some hard problem (that's usually hard because its not fallen to some attack/statistical test).  Or are they not equivalent?  Like the criteria of the definition you originally listed (and Yao's paper) seem to imply that these are equivalent.", "Perhaps we might be talking past each other just due to semantics, but I think you have the right mindset with this statement: \n\n> boil down to proving that some generating function a) passes all statistical tests (protects against all known attacks however you want to look at it) known at the time of construction or b) is equivalent to a hard problem (which passes all statistical tests/attacks etc...) known at the time of construction? (in addition to proving forward-security/other properties/blah blah?\n\nThe bar for a) is lower than the bar for b). Furthermore, there is a difference between \"provably passes a statistical test\" and \"passing one run of a statistical test\".  Granted, it's unlikely (astronomically unlikely) that you'll hit a bad run, but now you have to argue that your test software is legit, too.  Finally, and this is a personal point, I consider statistical tests to be ones that are actually used in real life, and not contrived ones. If you come up with a contrived test, then I would categorize that as an attack.\n\n> Like to me it seems like expanding that list of infinite (countable) tests on a given generating function is equivalent to the problem of picking some hard problem (that's usually hard because its not fallen to some attack/statistical test). Or are they not equivalent?\n\nIn essence, yes. You are able to do a proof by contradiction: assume an attack existed, even if you don't know what that attack is, you can then *generically* transform that attack to an attack on, say, factoring or some other hard problem.", "Roger.  Thanks."]}
{"id": "pj3jk5", "title": "How much does undergrad prestige matter when applying for a crypto PhD?", "url": "https://www.reddit.com/r/crypto/comments/pj3jk5/how_much_does_undergrad_prestige_matter_when/", "Created (UTC)": "2021-09-06 10:04:36", "body": "I know there are lots and lots of general questions about undergrad prestige but I wanted to try and give a little bit more information about my situation to make the best guess, I hope that's not a problem. I'm an high school graduate from Turkey. I'm able to go to the [Hacettepe University](http://www.mat.hacettepe.edu.tr/index-en.html) this year but next year I'll be able to go to [Middle East Technical University](https://math.metu.edu.tr). These are both considered good schools in Turkey but the math program of Middle East Technical University is considered more prestigious than Hacettepe's and its language of instruction is English. (Hacettepe's language of instruction is Turkish) Hacettepe is better known by its medicine program rather than STEM programs. Although, this difference is not greatly reflected in [US News rankings](https://www.usnews.com/education/best-global-universities/turkey) where Middle East Technical University ranks second and Hacettepe ranks fourth. My question is, granted I do great at college wherever I go and possibly even get a master's degree from a \"good\" college before my PhD, how much would going to Hacettepe affect my chances of admission to a PhD program (or a master's program for that matter)?\n\nTo give you a little bit more information about the universities:\n\n* I can't really see a big difference between the faculty members in both universities except that Hacettepe has 11 more faculty members and the h-index of one professor [Mustafa Turky\u0131lmazoglu](https://scholar.google.com/citations?user=F_6HfxsAAAAJ&hl=tr&oi=sra) is more than any professor in Middle East Technical University. \n* On average the h-indexes of the professors in Middle East Technical University seem better partly because the ones in Hacettepe often doesn't have google scholar profiles.\n* Hacettepe math program is [FEDEK](http://www.fedek.org.tr/) accredited, Middle East Technical University's math program doesn't have such an accreditation.", "post URL info": ["http://www.mat.hacettepe.edu.tr/index-en.html)", "https://math.metu.edu.tr).", "https://www.usnews.com/education/best-global-universities/turkey)", "https://scholar.google.com/citations?user=F_6HfxsAAAAJ&hl=tr&oi=sra)", "http://www.fedek.org.tr/)"], "author": "None", "ups": "23", "downs": "0", "number of comments": "38", "comments": ["You're in high school and you're already thinking about your PhD? Good for you!\n\nAs for getting into good PhD programs, I'd say about 3 things matter: 1) getting top marks at whatever university you go to, 2) doing undergrad research, 3) knowing people.  There's lots of other things you should be doing anyhow, like getting a good math background, finding out if you really want to do crypto(!), etc.", "Two main points:\n\nFirst, the most important part of any PhD application is generally which letters of recommendation you get from people who have done research with you. There are a variety of ways of getting these letters:\n\n1. Doing research with people in your home university\n2. Doing research some summer in another university (in the US, this generally goes by the name of a \"Research Experience for Undergrads\", or a REU).\n\nThe research you do doesn't have to be in cryptography (or whatever you apply for a PhD in), but it being closer helps --- so if you want to do theoretical cryptography, something within the theoretical part of mathematics usually is good. If one school sets you up better for/has more opportunities for undergraduate research, that might be better.\n\nSecond, an easy way to check which school may be better is to see what graduates from each school tend to do. This information isn't always public, but you might be able to talk with staff/faculty about it. If you are able to get this information, and one school sends many more students to PhD programs, that school may be a better choice.", "No offense but Turkish universities are not good. Get your undergrad from any university and then go to Switzerland for the rest.", "To add on to that, the more positive your relationship with your PI, the easier it'll all be. They'll be your most consequential advocates and teachers. You can have mediocre (in one case I know, even borderline-bad) grades but a PI willing to vouch for you will get you much further along. On the flip side, all the grades in the world don't mean so much if someone can't say \"X is good at carving their own path\".", "Thank you. Could you elaborate on what you mean by knowing people? Is this for recommendation letters?", "Thank you for the comprehensive response! Do you have any suggestions as to what I should look for in people when deciding who to ask to be my supervisor?", "[Huseyin Hisil](https://hhisil.yasar.edu.tr/) is an excellent cryptographer who studied and teaches in Turkey. I imagine he might have more informed advice than this!", "This somewhat depends on what you mean by supervisor. There are two natural interpretations of this:\n\n* Research supervisor\n* Academic supervisor (often called an \"Academic Advisor\" in the US)\n\nFor the second, the particular choice is not *super* important, it is just someone who is assigned to students to make sure they don't \"fall through the cracks\", and make sure they do the dumb bureaucratic things the university might want students to do.\n\nFor choosing research supervisors, there are a number of things to ask:\n\n* Who does work that you find interesting?\n* Who has prior students who have gone on to do things you want to do?\n\nThere are also things like making sure the supervisor's \"management style\" is a good fit for you, but I would not worry about this at your level.\n\nIn general though, I would suggest asking people who know the local situation better. For example, if you go to university X, ask seniors at university X. They will tend to be a much better resource than people online (unless you find someone online who randomly has experience with university X --- this can definitely happen, but is uncommon unless you are either on an X specific forum, or X is particularly famous).", "Thanks for the information. Do you know any other good cryptographers in Turkey or do you know how to find them?", "Thank you for yet another elaborate response!"]}
{"id": "pi9xek", "title": "Is pretty good privacy an encryption algorithm or a bundle of encryption algorithms?", "url": "https://www.reddit.com/r/crypto/comments/pi9xek/is_pretty_good_privacy_an_encryption_algorithm_or/", "Created (UTC)": "2021-09-05 02:21:35", "body": "Hello, quick question here, i'm trying to understand a little bit more about pretty good privacy, and i understand that it's a piece of \"software\" that uses at least RSA, but what i'm a little confused by is, is pretty good privacy only one encryption algorithm? or is it a bundle several different algorithms? \n\ni understand that GPG or gnu privacy guard is several different encryption algorithms bundled into one piece of software, but i'm not so sure about PGP. \n\nthank you", "post URL info": [], "author": "The_How_To_Linux", "ups": "0", "downs": "0", "number of comments": "17", "comments": ["You've created at least 3 different threads for mostly the same set of questions now. Why not write everything down in one thread and make it easier for us to understand what it is you need help with?", "GPG is one implementation of PGP. PGP is a protocol that describes how to format encrypted and/or signed data.\n\nFor example, if you encrypt or sign something, the result needs to contain meta data such as which algorithm was  used, what the length of the key is, how to parse a signed message, etc. Otherwise it would just look like random data and the recipient wouldn't know what to do with it. PGP defines the format of that metadata.", "PGP is a program.  GPG is a program.  OpenPGP is a standard protocol.", "Yeah op is kinda spamming subs for answers he can look up himself", "Curious about opinions on Mimblewimble, Lelantus and Dandelion while we are at it..", "[deleted]", "Just a small correction: OpenPGP is the standard of which GPG is an open source implementation. PGP is another implementation of OpenPGP and it's proprietary.", ">GPG is one implementation of PGP. PGP is a protocol that describes how to format encrypted and/or signed data.\n\nok, i understand that gpg is a bundle but what about pgp? is it just one algorithm or is it several?", "This subreddit is about cryptography, not cryptocurrency", "Looking at -72 comment karma, I think this is less of a bot and more someone who's twelve years old and figured out the Internet will answer all his questions if he just asks persistently enough.", "Neither. Its a protocol on how to sign encrypted data. The encrypting bit (which uses algorithms) is separate to this."]}
{"id": "phe2si", "title": "The RISC-V Scalar Cryptography Extension has reached public review", "url": "https://github.com/riscv/riscv-crypto/releases", "Created (UTC)": "2021-09-03 14:17:03", "body": "", "post URL info": [], "author": "bnmrshll", "ups": "41", "downs": "0", "number of comments": "40", "comments": ["Nice, I didn't know that they were working on accelerated cryptography for risc-v.", "Reading the ISA spec, this seems very well thought out:\n\n> MUL performs an XLEN-bit\u00d7XLEN-bit multiplication and places the lower XLEN bits in the\r\ndestination register. MULH, MULHU, and MULHSU perform the same multiplication but return\r\nthe upper XLEN bits of the full 2\u00d7XLEN-bit product, for signed\u00d7signed, unsigned\u00d7unsigned, and\r\nsigned\u00d7unsigned multiplication respectively. If both the high and low bits of the same product\r\nare required, then the recommended code sequence is: MULH[[S]U] rdh, rs1, rs2; MUL rdl, rs1,\r\nrs2 (source register specifiers must be in same order and rdh cannot be the same as rs1 or rs2).\r\nMicroarchitectures can then fuse these into a single multiply operation instead of performing two\r\nseparate multiplies.\n\nSource: https://riscv.org/wp-content/uploads/2019/12/riscv-spec-20191213.pdf\n\nFollowing Apple move to ARM, cryptographic workloads suffered significantly because ARMv8 requires 2 operations for extended precision 64x64->128 multiplication.", "Apple could do the same thing, detecting both the low and high multiply instructions and fusing them together.", "They would need to implement 64x64->128 in hardware though, does ARM give hardware designers some leeway for that kind of things?", "As long as from software\u2019s perspective, MUL and UMULH do as defined, yes, they can implement a decoder that recognizes the MUL+UMULH sequence and does a full multiply.\n\nMUL on ARM64 is actually MADD with XZR as the value to add after the multiply.  UMULH can\u2019t return a value that includes the carry, so it might be necessary to limit the 128 special support to when the add parameter of MADD is XZR."]}
{"id": "pghvas", "title": "Hat.sh V2 release - simple, fast, secure client-side file encryption.", "url": "/r/privacytoolsIO/comments/pftsnu/hatsh_v2_release_simple_fast_secure_clientside/", "Created (UTC)": "2021-09-02 06:26:56", "body": "", "post URL info": [], "author": "zshdv", "ups": "22", "downs": "0", "number of comments": "50", "comments": ["Thanks, this is a perfect illustration of everything wrong with modern development practices:\n\n* Pointless web-orientation that adds no value whatsoever (\"runs locally, the app never uploads the files to the server\"). There's no reason for this to be a web page.\n\n* A tangle of mystery meat dependencies of questionable origin and quality. `npm install`: \"added 655 packages from 414 contributors\", about *1.7 million lines of dependencies* according to `ohcount`. **How can you say you're secure if you haven't reviewed all this code?** Why on earth does a file encryption tool have *655 dependencies*? The number of dependencies should be somewhere around 0 to 1.\n\n* Bloated, wasteful, inefficient. Instead of an application that requires no more than about 64MiB of memory (chunk size), we have monstrosity that requires 1-2GiB of memory since it runs in a web browser. It wastes nearly all the resources it consumes. I didn't actually run it so I can't speak for how slow it is, but I have low expectations.\n\n* An interface that doesn't compose with other programs. For all its flaws, at least GnuPG lets me do something `curl \"$URL\" | zstd | gpg --encrypt >data.zst.gpg`.\n\nAt least the encryption scheme seems good since it's just using a libsodium stream.", "I like the ability to do this on desktop and mobile easily", "[deleted]", ".sh?  couldn't have come up with something original?  Makes me think of shell script file, or Saint Helena tld..", "It would be much better to port [Age](https://github.com/FiloSottile/age/) (which reached v1.0.0 recently) to the web instead of implementing another useless encryption software", "What can you expect when people are put through \"Learn coding in 12 weeks\"  bootcamps that just teach you how to throw together webservices?\n\nThe thing that really worries me is that if there are a sufficient critical mass of people trained this way, \"lightweight\" software as we know it will just turn into a series of bloated bundles.\n\n> An interface that doesn't compose with other programs. \n\nShh, you're going to be handed a you-know-what API if you start talking about such things...", "[deleted]", ">I didn't actually run it so I can't speak for how slow it is, but I have low expectations.\n\nIt's actually fast. or at least not slower than whats expected form it (as a Javascript/browser app).  on desktops it runs at 36 mb per second(Firefox). the faster the machine the faster the process.", "wish there was a way to upvote more than once on a comment\n\nall this plus \"nodejs\"  (spelled \"nothanks\" in my dictionary, at least on critical machines).  The \"mystery meat dependencies\" problem you referred to are endemic to nodejs.\n\nEdit: downvoters: never seen anyone reply \"node?  No thanks\" on reddit?  You must lead a very sheltered life.", ">Pointless web-orientation that adds no value whatsoever (\"runs locally, the app never uploads the files to the server\"). There's no reason for this to be a web page.\n\nThis is just to clarify for the normal visitor that there are no server-side communications involved. no file uploads or requests sent, Unlike any other sites people find when they google \"online file encryption\".\n\n&#x200B;\n\n>A tangle of mystery meat dependencies of questionable origin and quality.\n\nMost the dependencies are for UI/Design, and libsodium. All the dependencies are well developed and recently maintained. Welcome to the modern web development world.\n\n&#x200B;\n\n>The number of dependencies should be somewhere around 0 to 1.\n\nThis can be actually done, but you will have bad UX. For example, the prototype of this beta, which was 10 months ago, had only 1 dependency (libsodium). but had shitty ux and design.\n\n&#x200B;\n\n>no more than about 64MiB of memory (chunk size), we have monstrosity that requires 1-2GiB of memory since it runs in a web browser\n\nThat's why this version doesn't read the whole file into memory. to not use more ram than already used by the browser.\n\n&#x200B;\n\n>An interface that doesn't compose with other programs. For all its flaws, at least GnuPG\n\n\\- This project is not advertised or came to replace already known encryption software, it's just a hobby project that started with an idea that was not put to practice before. which is safe file encryption in browser. And it's mostly intended for people who don't have the knowledge needed to use complex tools when they never saw a command line interface in their life. its even mentioned in the FAQ section in the [documentaion](https://hat.sh/about/#faq) when not to use Hat.sh, and tools like VeraCrypt and GPG are recommended.\n\n&#x200B;\n\n>At least the encryption scheme seems good since it's just using a libsodium stream\n\nThanks", "[LICENSE](https://github.com/sh-dv/hat.sh/blob/master/LICENSE)", "I think you are correct, but the reason we went with this domain name because when the project first started a few years ago, it was deployed on \"[now.sh](https://now.sh)\" by ZEIT (now they rebranded to Vercel). And the app domain name was [https://hat.now.sh](https://hat.now.sh) . So when we decided to get a domain, we wanted to choose something that won't take away from the original address so much. and we kind of liked the 3 letters domain LOL. that's what we were thinking back then.", "`GOOS=js GOARCH=wasm go build`\n\nDone", ">What can you expect when people are put through \"Learn coding in 12 weeks\"  bootcamps that just teach you how to throw together webservices?\n\nWhat made you assume this ?", "Or if you only need symmetric encryption:\n\n    # apt install scrypt\n\nhttps://www.tarsnap.com/scrypt.html", "> This is just to clarify for the normal visitor that there are no server-side communications involved. no file uploads or requests sent\n\nthen why does your website say \"you are restricted to 1 GB because you are running in private mode\" (not exact words but close enough).\n\nwhat does it matter to you if I'm running in private mode, if all the processing is local on my browser?\n\nEdit: whoever downvoted this -- if you're not the author, why?  If you had an answer to the question you should have answered it.", ">Most the dependencies are for UI/Design, and libsodium. All the dependencies are well developed and recently maintained. Welcome to the modern web development world.\n>\n>>The number of dependencies should be somewhere around 0 to 1.\n>\n>This can be actually done, but you will have bad UX. For example, the prototype of this beta, which was 10 months ago, had only 1 dependency (libsodium). but had shitty ux and design.\n\nI don't necessarily agree. I wrote a [web-based password generator](https://github.com/atoponce/webpassgen) (and [a command line version](https://github.com/atoponce/nodepassgen)) that doesn't rely on any 3rd party libraries, like JQuery, Bootstrap, Vue.js, Angular, etc. with the primary focus being a clean UI and pleasant UX. I like to think I achieved those goals.", "I think you misunderstood. The question wasn't \"what is your license\" but \"what is the license and restrictions of all the components and libraries you are using\"", "I'm sorry, I believe you misunderstood. This is about license compliance. Neither in your compiled JavaScript blob nor anywhere on the website do I see the full list of required copies of license notices as is required by the MIT license of your dependencies.", ">then why does your website say \"you are restricted to 1 GB because you are running in private mode\" (not exact words but close enough).  \n>  \n>what does it matter to you if I'm running in private mode, if all the processing is local on my browser?\n\nOn desktops, the encryption is handled by the [service-worker](https://developers.google.com/web/fundamentals/primers/service-workers). Since we are not using any server-side processing, the app registers a fake download URL (/file) that is handled by the app [service-worker fetch api](https://github.com/sh-dv/hat.sh/blob/master/service-worker/sw.js). this service worker is installed and activated in the browsers once the user visits the site. \n\nIn cases when the app detects that the service worker [failed to register](https://github.com/sh-dv/hat.sh/blob/master/pages/index.js#L25) (e.g Safari, Mobile browsers, [Firefox Private Browsing](https://bugzilla.mozilla.org/show_bug.cgi?id=1601916)), the app will offer the same encryption without the use of service workers, the files are still chunked and encrypted the same way but the file will be read as a whole in memory, Hence the limitation of 1GB files. This was implemented mainly for mobile browsers.\n\nThat's the main difference between v2 and v1, that we found a way to get around encrypting large files in browsers without holding the whole file in memory and the leading to browser to crash.", "Nice projects, and your password generator i have used it before iirc. \n\nBut you ended up with a 1000+ lines of codes of Javascript in one file that is hard to read for others or to identify bugs or just for code review. It's a bad practice in my opinion. Using modern frameworks like React allows you to split up your code into multiple components that get bundled at build time, with interactivity in mind. even if it was just a button click that does something simple.", "They are all of MIT license.\n\nAll the dependencies :\n\n[React.js](https://github.com/facebook/react/blob/main/LICENSE)/ [Next.js](https://github.com/vercel/next.js/blob/canary/license.md) / [Material-UI](https://github.com/mui-org/material-ui/blob/next/LICENSE) / [Browserify](https://github.com/browserify/browserify/blob/master/LICENSE) (bundle packaging) / [Serve](https://github.com/vercel/serve/blob/main/LICENSE) (static site serving) / [React-Dropzone](https://github.com/react-dropzone/react-dropzone/blob/master/LICENSE) (file drag drop) / [React-Idle-Timer](https://github.com/SupremeTechnopriest/react-idle-timer/blob/master/LICENSE) / [zxcvbn.js](https://github.com/dropbox/zxcvbn/blob/master/LICENSE.txt) (Password strength estimation)\n\nFor documentation (about page) :  [Marked.js](https://github.com/markedjs/marked/blob/master/LICENSE.md) (Markdown Parser) / [PrismJS](https://github.com/PrismJS/prism/blob/master/LICENSE)(code syntax highlighter)\n\nAnd [libsodium ISC](https://github.com/jedisct1/libsodium.js/blob/master/LICENSE) for cryptography.", "The MIT license requires that \"the above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.\" By including the license in the source folder,I have met this obligation.", "then you should explain that (maybe a bit more briefly) at the bottom\n\nand downvoting a genuine question even if you had the answer?  You don't think others would have the same question?", "Thanks!", "[deleted]", "Right, I will take the time to update the documentations to be more clear. And the github main page too.\n\nI did not downvote the reply. I have no reason to.\n\nThanks for the feedback!", ">How so?\n\nWhen you run the app and the packages get installed, each package contains their license in it's directory.\n\n&#x200B;\n\n>anywhere in the bundle nor on the website itself.\n\nComments get deleted when you build and export the app (bundle), even if i put them there manually because Next.js provides gzip compression to compress rendered content and static files.\n\nAnd there is not only one bundle, Javascript files get bundled in multiple chunks in next.js!\n\nI am requiring libosdium-wrappers files using npm, i don't have to do anything else because the app has their license file already. and i made it clear on multiple location in github and in the documentation page that the app uses libsodium.js. the license comments are included in libosdium.js files. If you can't find it then you don't have to worry about that.", "u/jedisct1 I would like to have your input on this matter. And how can i solve this issue in order to have full License compliance. Thank you.", "It is clear enough that you\u2019re using libsodium.js, I don\u2019t think anything else is needed.", "Appreciated."]}
{"id": "pgg7e4", "title": "CRYFS Default aes-256-gcm vs OSX AES-256", "url": "https://www.reddit.com/r/crypto/comments/pgg7e4/cryfs_default_aes256gcm_vs_osx_aes256/", "Created (UTC)": "2021-09-02 04:45:08", "body": "I currently have an OSX Encrypted SparseImage for all important family documents(Passport scans, etc) on my MACBOOK as we travel abroad or even if it gets stolen from home. Sparse Images are not very compatible with cloud storage and will often corrupt if they have to be backup through a cloud storage provider like DROPBOX or GDRIVE. I've been seeking an alternative and came upon CRYFS. Is this a secure, feasible alternative to my security needs?", "post URL info": [], "author": "barcef", "ups": "8", "downs": "0", "number of comments": "20", "comments": ["CryFS has a paper: https://www.cryfs.org/cryfs_mathesis.pdf\n\nUnfortunately I didn't came across an audit (even 10 hours) like for encFS, gocryptfs and others:\n\n- https://defuse.ca/audits/encfs.htm\n- https://defuse.ca/audits/ecryptfs.htm\n- https://defuse.ca/audits/gocryptfs.htm\n\nI assume you read this as well: https://www.cryfs.org/comparison", "\nCryFS utilises GCM, an operation mode which allows for authentication and encryption, unlike XTS-AES. Since you plan to upload your data to the cloud and hand it over to a potential adversary with read and write access to your data, GCM seems to be the safer choice. \n\n\nI used CryFS for over 2 years and switched back to GoCryptFS. The overhead (speed penalty) was to much for me and the security win due to the hidden metadata wasn't worth it. \n\n\nBTW: there is also rclone, the \"rsync for clouds\". If you just want to backup your sparse bundle to Google or DropBox, this might also be a solution. Rclone comes with an optional encryption of it's own and can easily sync your sparse bundle with remote servers. A great tool to automatise backups.", "Yeah I read the comparison."]}
{"id": "pfxxqp", "title": "Verify your EU Green Pass by hand (with Linux tools)", "url": "http://www.corentindupont.info/blog/posts/Programming/2021-08-13-GreenPass.html", "Created (UTC)": "2021-09-01 09:52:21", "body": "", "post URL info": [], "author": "kaukaukau", "ups": "29", "downs": "0", "number of comments": "16", "comments": ["[deleted]", "Very well, I have been looking for breakdown like this, thanks! When you say verify \u2026 and use asn1parse afterwards, maybe rephrase, a bit confusing?", "That is right, I need to add it!!", "I think that in the article we are really verifying the green pass validity, see at the end:\n\n```\n$ openssl dgst -sha256 -verify public_key.pem -signature my_signature.der my_data\nVerified OK\n```\n\nEDIT: Oh I see now, there are some places where I say \"verify\" for just checking the signature format:\n```\nYou can verify your key this way:\n\n$ openssl asn1parse -in public_key.pem -inform PEM\n    0:d=0  hl=2 l=  89 cons: SEQUENCE\n    2:d=1  hl=2 l=  19 cons: SEQUENCE\n    4:d=2  hl=2 l=   7 prim: OBJECT            :id-ecPublicKey\n   13:d=2  hl=2 l=   8 prim: OBJECT            :prime256v1\n   23:d=1  hl=2 l=  66 prim: BIT STRING\n```\nWhat do you suggest?", "Take a look at letsencrypt.org if you haven't already"]}
{"id": "pfmpb4", "title": "Bulletproof TLS Newsletter Issue #80", "url": "https://www.feistyduck.com/bulletproof-tls-newsletter/issue_80_vulnerabilities_show_fragility_of_starttls", "Created (UTC)": "2021-08-31 21:41:21", "body": "", "post URL info": [], "author": "knotdjb", "ups": "13", "downs": "0", "number of comments": "17", "comments": []}
{"id": "pfk01b", "title": "NSA - Quantum Computing and Post-Quantum Cryptography - Frequently Asked Questions [PDF]", "url": "https://media.defense.gov/2021/Aug/04/2002821837/-1/-1/1/Quantum_FAQs_20210804.PDF", "Created (UTC)": "2021-08-31 18:54:54", "body": "", "post URL info": [], "author": "Natanael_L", "ups": "20", "downs": "0", "number of comments": "19", "comments": ["Notable excerpt:\n\n> Q: What is quantum key distribution (QKD) and quantum cryptography?\n\r\n> A: The field of quantum cryptography involves specialized hardware that makes use of the physics of quantum \r\nmechanics (as opposed to the use of mathematics in algorithmic cryptography) to protect secrets. The most \r\ncommon example today uses quantum physics to distribute keys for use in a traditional symmetric algorithm, \r\nand is thus known as quantum key distribution. This technology exists today and is distinct from the quantum \r\ncomputing technology that might one day be used to attack mathematically based cryptographic \r\nalgorithms. The sole function of QKD is to distribute keys between users and hence it is only one part of a \r\ncryptographic system.\n\n> Q: Should I use a QKD system to protect my NSS from a quantum computer?\n\r\n> A: No. The technology involved is of significant scientific interest, but it only addresses some security threats \r\nand it requires significant engineering modifications to NSS communications systems. NSA does not consider \r\nQKD a practical security solution for protecting national security information. NSS owners should not be using \r\nor researching QKD at this time without direct consultation with NSA. For specific questions, NSS owners can \r\ncontact NSA.", "> Q: I have long data life concerns and want to adopt CSfC solutions. How can I ensure my \r\ncommunications and data remain secure against an adversary with a quantum computer?\n\r\n> A: Some CSfC solutions may be implemented using symmetric, pre-shared keys that protect against the long-term quantum computing threat. NSA considers the use of pre-shared symmetric keys in a standards-compliant fashion to be a better near-term post-quantum solution than implementation of experimental post-quantum asymmetric algorithms that may or may not be proven secure and which will not be compatible with\r\nNIST standards. For more info, contact the CSfC program office.\n\nPre-shared keys work in a lot of person to person messaging scenarios when you can meet in person to share keys. However I am not sure why programs with pre-shared keys are so rare. So many things can go wrong with public key crypto and there's no guarantee of security in a post-quantum world even if NIST standardises something.", "> Q: Is NSA worried about the threat posed by a potential quantum computer...?\n> A: NSA does not know when or even if a quantum computer of sufficient size and power to exploit public key cryptography will exist.\n\nI read that as \"No\" :-)"]}
{"id": "pfjlco", "title": "What protocol prevents hackers from simply sending a copy of whatever a user sends while logging in?", "url": "https://www.reddit.com/r/crypto/comments/pfjlco/what_protocol_prevents_hackers_from_simply/", "Created (UTC)": "2021-08-31 18:30:44", "body": "To clarify, let me use an example.\n\nA user is logging into xyzxyz.com. They type their password, \u201cfoobar\u201d into the login, and the password is scrambled through use of whatever functions xyzxyz.com uses for their logins. Maybe it\u2019s put through a one-way hash function and compared to a hash of the password in the website\u2019s databases.\n\nNow, an \u201ceavesdropper\u201d sees the login traffic coming into the xyzxyz server. They decide to simply grab the hashed password and send it again, this time with their own computer.\n\nThis would generate a valid login, wouldn\u2019t it? What mechanisms are in place to prevent this from happening?\n\nI\u2019m sorry, I\u2019m sure this is probably a very basic question, but I just haven\u2019t been able to find answers to it online.", "post URL info": [], "author": "Nachf", "ups": "10", "downs": "0", "number of comments": "34", "comments": ["Let's consider two cases:\n\n&#x200B;\n\nCase 1: the connection is over HTTP. The login form/webpage/app/etc. will send the password over as plaintext and anyone who can eavesdrop on the connection can see it; game over. There is no point to doing hash(password) on the client and then only sending the hash to the server since, as you point out, if the server accepted hash(password) for logging in, that's effectively the same as knowing the plaintext password for logging in. (As an aside, the reason passwords are hashed in the database is so that even if someone can read the database and knows hash(password), the server is still expecting the plaintext password, not hash(password) so you still can't log in.  In reality, if someone can read the database and find hash(password) they probably also have enough other information that they don't need to bother logging in.)\n\n&#x200B;\n\nCase 2: the connection is over HTTPS. The TCP packets are encrypted via some TLS encryption method that the server and client have agreed on.  An eavesdropper can only see the encrypted packets and can't find the plaintext password.  Furthermore, even if the eavesdropper records all the encrypted packets and tries to replay them to the server, the server will reject them because each time a connection is made to the server, a new random nonce value is used as part of the encryption key.  Since the eavesdropper's nonce != original nonce, the server will reject the replayed packets from the eavesdropper.", "Replay protection (reuse) / relay protection (MITM). There are many ways to achieve it, typically by requiring single use values and session binding and/or by encrypting the transfer of the single use values. If you don't protect it, you do get vulnerabilities like \"pass the hash\".", "For any modern website, your connection is encrypted with a session key over https. Your traffic, and this ephemeral key, are stored in memory on the webserver, not on disk or any database ever. So, to decrypt your live traffic, an attacker would have to read the memory in use by the webserver process itself - possible, but unlikely.\n\nOn the other hand, the protections you mention (hashing and salting the password) apply to how it is stored on disk and/or some massively backed-up and duplicated database. That will persist long before and after your login session is gone, and it will be much easier for an attacker to access. So that's why you want and need those stronger protections.\n\nSo to answer your question: yes a hacker *could* read your plaintext password, but it would have to be a very lucky, sophisticated and \"live\" attack. Otherwise, for the usual hack where they will just get access to the database, the hashing and salting that hopefully the server employs will offer a good protection.", "Passwords are inherently replayable, but there are some password-authenticated challenge-response protocols that move the point of replay outside the view of a network eavesdropper.\n\nMost people are sending plaintext passwords to the server and are relying on TLS to provide eavesdropping and replay protection.  Digest authentication and augmented PAKEs can also accomplish this, though the tradeoffs are pretty subtle.\n\nThere are two big virtues of the traditional Unix password authentication model of storing a salted cryptographic hash and demanding a plain text password: first the protocol puts minimal constraints on the implementation, making it relatively easy to make major changes with a smooth migration path.  Any protocol that is more complicated makes at least some changes much more difficult. Secondly, an attacker who steals the server's password database cannot immediately impersonate a user, which isn't true of all protocols, and this anti-feature is especially common in digest authentication.  \n\nProtecting yourself against eavesdropers at the cost of allowing impersonation upon compromise of persistent storage is basically trading one kind of replay for another, and with the ubiquity of TLS, a bad trade off to make in practice these days. It's much better to either keep it simple with a more traditional Unix-like model, or move the point of replay completely outside the view of your servers, which basically means SCRAM or a PAKE.\n\nThere are huge potential advantages to using a protocol, but much of the advantage is inherently tied to the fact that properly implemented password authentication protocols are difficult to change.   Some of the existing ones are pretty awful:  woe to those throughly tied to MS-CHAP or HTTP digest authentication at this point... I doubt there are many companies in the latter category, but there are _huge_ numbers of companies in the first.\n\nWe are probably approaching a point where somebody can commit to an augmented PAKE and not regret the particulars of that decision 20 years later, but an answer on this count isn't exactly clear yet either, at least not to me.", "https://en.wikipedia.org/wiki/Reflection_attack", "digest authentication mitigates that to a large degree, but nobody uses it. frankly it's surprising that honeypot password collection sites for $$$ aren't more common. passwords over the wire suck and are not inevitable", "[removed]", "[removed]", "So, just to clarify since I\u2019m sure I could be totally wrong, what I\u2019m understanding from this is that every login protocol (I\u2019m sorry if I\u2019m butchering the vocabulary by the way) involves at least one use of a two way function?", "Also relevant: https://en.wikipedia.org/wiki/Replay_attack", "This subreddit is about cryptography, not cryptocurrency.", "You aren't getting through, just give up and delete your accounts", "Normally called an asymmetric function, like using authenticated diffie-hellman key exchange (DH) to create a session key to encrypt it, or alternatively for a more modern solution then using password authenticated key exchange (PAKE). There's even more options.\n\nThere's additional options like WebAuthn which uses public key cryptography directly using hardware tokens.", "Not necessarily. It can also be done with a one-way function. An extremely simplified example: The server could send the user a different word with each login form. If the user returns *hash(password+word)*, replaying wouldn't work.", "Sorry", "But that would yield a different hash output and would no longer be the same as the stored, hashed password in the login database. Unless, of course, they\u2019re storing the password as plain text, which I kind of assumed they weren\u2019t doing since that\u2019s really irresponsible.", "Let\u2019s undo the \u201cextremely simplified\u201d part \ud83d\ude01\n1) user sends username\n2) server answers with {\u201csha256\u201d, 20000, user\u2019s salt, word}\n3) client calculates the hash stored in the server: dk = pbkdf2(\u201csha256\u201d, password, user\u2019s salt, 20000)\n4) client sends hash(dk+word)\n5) server does its thing\n\nBut of course the responsible thing to do is to encrypt the communication from the beginning with TLS 1.2 or higher \ud83d\ude42"]}
{"id": "pfelax", "title": "Who's hiring?", "url": "https://www.reddit.com/r/crypto/comments/pfelax/whos_hiring/", "Created (UTC)": "2021-08-31 13:51:21", "body": "Please state the location and include REMOTE, INTERNS and/or VISA when that sort of candidate is welcome. When remote work is *not* an option, include ONSITE.\n\nPlease only post if you personally are part of the hiring company\u2014no recruiting firms or job boards. Only one post per company. If it isn't a household name, please explain what your company does.\n\nCommenters: please don't reply to job posts to complain about something. It's off topic here.\n\nReaders: please only email if you are personally interested in the job.", "post URL info": [], "author": "davidw_-", "ups": "23", "downs": "0", "number of comments": "34", "comments": ["Trail of Bits | Crypto Analyst | Remote or New York, NY\n\nJoin the Trail of Bits [Cryptography Team](https://twitter.com/veorq/status/1159575080109662208)! We help secure the next generation of privacy-preserving cryptography, including advanced uses of [ZKPs](https://blog.trailofbits.com/2020/05/21/reinventing-vulnerability-disclosure-using-zero-knowledge-proofs/), [MPC](https://blog.trailofbits.com/2019/10/04/multi-party-computation-on-machine-learning/), differential privacy, and [machine learning](https://blog.trailofbits.com/2020/10/08/privacyraven-has-left-the-nest/). We regularly review and [publish](https://blog.trailofbits.com/category/cryptography/) new research, invest in building our own tools, and closely collaborate with engineers across the company.\n\nWe're proud of our ability to offer \"large company\" benefits despite being a very friendly 80 people. Read more about our company culture and extensive benefits on [BuiltInNYC](https://www.builtinnyc.com/company/trail-of-bits), who awarded us a Best Place to Work in NYC for [overall](https://www.builtinnyc.com/companies/best-places-to-work-nyc), [small company](https://www.builtinnyc.com/companies/best-small-places-to-work-nyc), and [best paying](https://www.builtinnyc.com/companies/best-paying-companies-nyc).\n\n[Apply on Lever](https://jobs.lever.co/trailofbits/56af8506-3205-4c7b-b28d-ba8292bd1a47).", "\\[HIRING\\] \\[REMOTE\\] \\[FULL-TIME\\]   \n\\- [Protocol Research Engineer](https://jobs.status.im/en/jobs/17893): Looking for those with experience/knowledge of P2P, Cryptography & Protocols (or a mix).  \n\n\n\\- Our teams at [Status.im](https://Status.im) have a lot of exciting projects, overall they're helping to build the web3 ecosystem forward through research, creation of developer tools, and support of the open source community.   \n\n\n\\- [VAC](https://vac.dev/) is one of our the teams doing this by building a modular, peer-to-peer messaging stack for private, secure, censorship resistant communication.  \nDM me on Discord (LilChiChi#0021)", "O(1) Labs | Crypto engineer | REMOTE\n\nWe're looking for zero-knowledge/Rust/OCaml people (and people interested in that stuff). We're doing really cool things in the space (working on the Mina cryptocurrency and recursive zero-knowledge proofs). Check it out you're interested in modern and secure programming languages (Rust/Ocaml), bleeding-edge cryptography (recursive zero-knowledge proofs, new hash functions, schnorr signatures, etc.), and nice coworkers :D\n\njob description: https://boards.greenhouse.io/o1labs/jobs/4023646004", "one of the top 5 tech company | ASIC crypto/security architect or designer | onsite is preferred, remote can be negotiated | easier if you're able to work in the US", "[deleted]", "Freedom of the Press Foundation is a ~25 person nonprofit that leads development of the SecureDrop open source whistleblower platform used by 70+ news organizations.\n\nWe're currently looking for Software Engineers (mid-level to senior) and for a Sr. Security Engineer. All jobs are REMOTE. See our [jobs page](https://freedom.press/jobs/) for more details.\n\nSecureDrop currently uses gpg to encrypt messages and files submitted by sources, and anonymizes traffic using the Tor network. We've started experimenting with the Signal Protocol as a potential foundation for fully end-to-end encrypted comms between journalists and sources using the Signal Protocol; see https://github.com/freedomofpress/securedrop-e2e/ for this experimental work.", "[Bolt Labs](https://boltlabs.tech) | Blockchain & Software Engineers | REMOTE\n\nWe're a small, privacy-focused startup on a mission to empower everyone with the tools they need to realize financial privacy. To achieve this, we\u2019re building [zkChannels](https://github.com/boltlabs-inc/zeekoe): a **scalable and usable privacy-preserving payment infrastructure** that integrates with existing payment networks, including but not limited to public blockchains. We're leveraging cutting-edge technologies like **zero-knowledge proofs** and **multi-party computation** to realize fast private transactions on public blockchains.\n\nWe're hiring for [blockchain engineer](https://hackmd.io/@NBpY2rNqQxe6-Vxxmn8bXw/S1l5QGguY), [software engineer](https://hackmd.io/@NBpY2rNqQxe6-Vxxmn8bXw/S1pPcX7Pt), and [senior software engineer](https://hackmd.io/@NBpY2rNqQxe6-Vxxmn8bXw/HytKoEmwY) roles right now and offer competitive salaries, great health benefits, equity in the company, and a strong remote work culture. Lastly, we're building all of our infrastructure in **Rust** so you'll be working in Rust from day one.\n\nThese are fully remote positions available to anyone living in and with work authorization in the United States. We are only able to offer these positions to someone who is living and working in the US.\n\nYou can read more about our work [here](https://medium.com/boltlabs) and can submit a job application [here](https://boltlabs.tech/apply).", "That's a pretty barebones post. Can you share more? Like location of offices if you want it onsite", "Looks like a cryptocurrency company - note that this subreddit is about cryptography, so do you have positions specifically for cryptography?", "This is a 102-day old thread :) you might want to post a new \u201cwho\u2019s hiring\u201d thread to the sub and comment on it", "Purposely left it vague because we can make things happen for the right candidate. As for locations, we'll preferred someone either in the bay area or Seattle for onsite.", "I misread my apologies! I\u2019ll delete.", "Main position posted by OP himself is for a cryptocurrency company", "Good point! :-) Just created [here](https://www.reddit.com/r/crypto/comments/rf4czk/whos_hiring_december_2021_edition/)", "I don\u2019t mean to be critical, but I wouldn\u2019t imagine \u201cthe right candidate\u201d would be attracted to a post with little to no information.", "The general rule here is that what you post has to be relevant to cryptography", "obviously I'm inviting for people to pm me for more information. you'd figure that doesn't work?", "The people you consider to be the right candidate probably have no idea that they are the people you're looking for, given this information. They'd have to guess, and you'll probably get a lot of false positives, and some choosing not to reply.", "Recruiting strateji goes bonk"]}
{"id": "pfqz0e", "title": "What does it mean that \"openpgp is an internet standard\"?", "url": "https://www.reddit.com/r/crypto/comments/pfqz0e/what_does_it_mean_that_openpgp_is_an_internet/", "Created (UTC)": "2021-09-01 03:19:11", "body": "Hello, recently i asked [https://www.reddit.com/r/crypto/comments/pbywh4/what\\_is\\_the\\_difference\\_between\\_pgp\\_and\\_openpgp/](https://www.reddit.com/r/crypto/comments/pbywh4/what_is_the_difference_between_pgp_and_openpgp/)\n\nand someone replied \"openpgp is an internet standard\"  \n\n\ni am a complete beginner with cryptography, but what does that mean? what does that mean that \"openpgp is an internet standard\" and pgp isn't?  \n\n\nwhat is an internet standard? who sets and creates internet standards? how does something become an internet standard? why does it become and internet standard? why did openpgp become and internet standard?   \n\n\nthank you.", "post URL info": ["https://www.reddit.com/r/crypto/comments/pbywh4/what\\_is\\_the\\_difference\\_between\\_pgp\\_and\\_openpgp/](https://www.reddit.com/r/crypto/comments/pbywh4/what_is_the_difference_between_pgp_and_openpgp/)"], "author": "The_How_To_Linux", "ups": "0", "downs": "0", "number of comments": "65", "comments": ["OpenPGP is specified in an RFC that anyone can follow.\n\nYou should have just replied there instead of creating a new thread.", "The [IETF](https://en.wikipedia.org/wiki/Internet_Engineering_Task_Force) is an independent, non-profit, open standards body that publishes proposed technology standards related to networks and the internet.\n\nNew standards are submitted to the IETF as [RFCs](https://en.wikipedia.org/wiki/Request_for_Comments) by various authors/companies, and proposals are reviewed and published. If published, they're referred to as an internet standard.\n\nThere is a published RFC for OpenPGP, but not PGP. So OpenPGP is classified as an internet standard and PGP is not.", "https://datatracker.ietf.org/doc/html/rfc4880\n\nhttps://datatracker.ietf.org/doc/draft-ietf-openpgp-rfc4880bis/", ">...does that mean that \"openpgp is an internet standard\" and pgp isn't? \n\nOpenPGP defines what messages look like. PGP\u2122 is a commercial program that generally conforms to that definition and produces and can consume messages in the OpenPGP format.\n\n>why did openpgp become and internet standard?\n\nFor interoperability. There are several OpenPGP programs/libraries in common use and lots of email clients that have OpenPGP support. There are advantages to not letting a single entity control a standard.", "as i recall, pgp basically came to IETF to make an informational RFC of what was already deployed. it looks like they decided to go standards track though. IETF is the standards body that creates documents for the internet\n\nto be super nitpicky, openpgp is not an \"internet standard\", but instead just a proposed standard. there are very, very few internet standards (< 100, iirc, and i have one that became one) including rfc 791 which has its 40th birthday today.", "I wish I could understand it, but a complete newbie :(((", ">OpenPGP is specified in an RFC that anyone can follow.\n\nwhat does this mean? what is an RFC?\n\nwhat does it mean that \"openpgp is specified in an RFC\"?", ">The   \n>  \n>IETF  \n>  \n> is an independent, non-profit, open standards body that publishes proposed technology standards related to networks and the internet.\n\nthis is a good answer, thank you, this answer provides at least part of the back ground and context\n\nso when i look at wikipedia \n\n  \n\"The Internet Engineering Task Force (IETF) is an open standards organization\"\n\nwhat does that mean? an \"open standards organization\"?    \n\n\n\\> New standards are submitted to the IETF as RFCs by various authors/companies, and proposals are reviewed and published. If published, they're referred to as an internet standard.\n\ninteresting, why would they call it a RFC? or (request for comments)? \n\n\\> There is a published RFC for OpenPGP, but not PGP. So OpenPGP is classified as an internet standard and PGP is not.\n\nthis is the crux of the issue, i'm simply not understanding what it means to be an \"internet standard\" \n\ni don't understand how that means anything.", "This is the correct answer!", "i don't know what this means", "PGP started as open back in the early nineties. The first PGP RFCs started back then. At some point it forked into a commercial release and a version under the MIT license and the RFCs were maintained to keep interoperability. There has been other software since then that works with the standards that contains none of the original code like gpg.", "i'm not trying to troll, and i'm stuggling here, i just don't know what the context is, \n\nwhat is the IETF, what is a RFC, what does it mean to be a \"standard\"\n\nwhy did openpgp become a standard and pgp didn't? especially that pgp started as open source? \n\ni'm trying to get the history and the context here but i'm just not understanding", "You didn't read the Wikipedia article I linked to you last time?", "It means that its details are available in an open manner and that anyone can access and implement it accordingly. Contraste with a proprietary protocol such as the Skype one, where only Skype can use and implemented.", "It is the IETF standard specification (RFC) for OpenPGP.\n\nIt is reference to implement an OpenPGP client.\n\nRFC 4880 is the current standard, RFC4880*bis* is the upcoming changes.", ">PGP started as open back in the early nineties. \n\nthis is part of how i'm getting confused\n\nPGP started as open, then how did the need for openpgp start?", "\\[nb for nitpickers: i know there are many exceptions in IETF process but this is generally how things work for the OpenPGP case\\]\n\nIETF is the Internet Engineering Task Force which is the global standards body that creates the standards for lots of protocols on the internet like IP itself, email, http(s), etc. RFC means \"Request for comments\" which is somewhat historic, but is the output of an IETF working group, typically of a document(s) which specifies how a protocol works. protocols themselves are the way a sender and a receiver come to agreement on what the bits on the wire mean, and the actions that are required. this is extremely important when you want to have multiple independent implementations from various vendors, etc.\n\nPGP is a company that commercialized the PGP protocol that Phil Zimmerman designed back in the early 90's, iirc. they didn't necessarily care about independent implementations though i'm pretty sure the spec was open for anybody to implement from the beginning. often when that happens the original spec has many holes and ambiguities in it so independent implementations often either don't work together at all, or have lots of problems. the other problem is that various vendors often extend their implementations with potentially proprietary extensions. all of that is almost certainly the case with PGP.\n\nwhen that happens and the protocol is fairly useful and/or popular, people can make an attempt to write a new spec which cleans things up and codifies implicit unwritten rules. this is often with the blessing of the group or company that wrote the original spec for which you can see Jon Callas as one of the lead authors of OpenPGP. this new spec is taken to IETF to become an RFC which gives it sort of a world-wide audience and a way for people to find the new spec. \n\nthis can be done one of two ways: a fully baked document can be taken to IETF to become an individual submission and given an RFC with the status of \"informational\". informational means that it's worthwhile but has not  been fully vetted by the larger IETF community. in OpenPGP's case, however, they went for what's called \"standards track\" which usually involves creating a working group where the larger internet community is involved with vetting and improving the protocol spec. in both cases, RFC's are given numbers for future reference.\n\nWhen OpenPGP was finalized, all of the interested parties including PGP would implement it. in fact, they are all implementing it along the way and hence the IETF's creed is:\n\n\"We reject: kings, presidents and voting.\n\nWe believe in: rough consensus and running code\"\n\nwhich means that actual code interoperating with other implementations is extremely valued and frankly is the entire point of network protocol standards. this process is pretty much how the internet was implemented and built: come to rough consensus on what the spec should be and have running code to prove that it works.", "https://en.wikipedia.org/wiki/Request\\_for\\_Comments\n\ni read it but it doesn't make any sense, i cannot make heads or tails of whatever that is. \n\n\"A Request for Comments (RFC) is an individually numbered publication in a series, from one of a small group of bodies, most prominently the Internet Engineering Task Force (IETF), the principal technical development and standards-setting bodies for the Internet.\"\n\ni have no idea what any of this means, this is a word salad to me", "i have no idea what any of this means\n\nit's \"details\" what?", "i don't know what the IEFT (internet enginnering task force) is, i don't know who they are, i don't know why they exist, i don't know why they first came into existence,  i don't know what they do, i don't know anything about the context of them. \n\ni don't know what the RFC (request for comments) even means at all\n\ni don't know what \"implementation\" means in this context\n\ni don't know what an internet standard in this context mean\n\ni'm just missing the history background and context.", "It started as open but there were some issues. Phil Zimmerman produced the original and then it became available for download. A team started work on it around the world. After a while there was commercial interest and Phil started PGP Inc with a more commercially polished version and most importantly the OpenPGP standard. The basic PGP code remained in the public domain and both adhered to the RFC.", ">IETF is the Internet Engineering Task Force which is the global standards body that creates the standards for lots of protocols on the internet like IP itself, email, http(s), \n\nwhy did the IETF come into existence in the first place? what was the need?", "Then you're probably in over your head here. If this is complicated for you, then you need to start at something much more basic. How much do you know about programming and such topics?", ">individually numbered publication in a series\n\nPublications are documents. These are numbered, in order. Thus, a series of numbered documents.\n\n> from one of a small group of bodies, most prominently the Internet Engineering Task Force (IETF)\n\nThe Internet Engineering Task Force is a \"body\" of individuals. AKA, \"a group of people\".\n\n> principal technical development and standards-setting bodies for the Internet.\n\nThis group of people approves technical standards, like OpenPGP.\n\n>this is a word salad to me\n\nA group of people lead the development and publication of technical documents surrounding Internet-related things. These documents are individually numbered and published as a series in order.", "No idea of anything?\n\nSorry, but I'm not taking it from the top.", "it was an outgrowth of the ARPANet project which was the precursor to the Internet. the need was simple: there was no such thing as networking before it came into being. ARPANet was invented out of whole cloth and was a remarkable achievement.  \n\nyou can read about it in a book called When Wizards Stayed Up Late.", "> How much do you know about programming and such topics?\n\ni don't i'm just trying to get a basic idea of the history of pretty good privacy", "I think what they're missing is in understanding of the \"why\". The \"what\" isn't getting parsed because there's no mental model to connect it to.\n\nThey need to start at a much more basic level and learn the concepts one at a time.", "i have no idea what any of this means\n\npublication? what publication? i get publications are documents, but what is the context here? what the history? why do these publications exist? who made them? what are they for? \n\n\\> The Internet Engineering Task Force is a \"body\" of individuals. AKA, \"a group of people\".\n\nright but who are they? why do they exist? why does the group exist? what purpose do they serve? how did they come into existence?", ">I'm not taking it from the top.\n\ni don't know what you mean by this.", "Which is curious given their username. Unless \"The_How_To_Linux\" means they are actually learning how to use Linux, rather than trying to provide a set of resources for others.\n\nOr maybe just trolling. \u00af\\\\\\_(\u30c4)\\_/\u00af", ">They need to start at a much more basic level and learn the concepts one at a time.\n\ni think i just need the history and context here so i can understand what is happening in a linear order\n\ni'm not trying to learn programming or cryptography, i'm trying to learn the history of public key cryptography.", "Yeah. I'm not feeding the troll any longer.", "You need the first to understand the second", "> the first to understand the second\n\nwhat is the first?", "Understanding how software and protocols are developed and why the process like like it does is necessary to make sense of how and why OpenPGP was created.", ">Understanding how software and protocols are developed and why the process like like it does is necessary to make sense of how and why OpenPGP was created.\n\nok, \" how software and protocols are developed and why the process like like it does is necessary to make sense of how and why OpenPGP was created.\"?"]}
{"id": "pezowx", "title": "How to Use Hash Function ?", "url": "https://www.reddit.com/r/crypto/comments/pezowx/how_to_use_hash_function/", "Created (UTC)": "2021-08-30 22:39:43", "body": "Hello Everyone, The professor told us during our class  that we cannot use hash function to send confidential information to othe user. \n\nEg: Alice wants to send a movie to Bob. \n\nProfessor says She cannot Send the hash of the movie name along with the Encrypted File of the Movie., This is a bad practice and the invader spying on the network and easily get the hash and know the name of the movie. \n\nWhere as I believe if I send the hash result of the Hash(name of the movie ) along with the Movie in encrypted format it should be sufficient enough. Hash function will help the Bob to verify the authenticity of the Movie he is decrypting.\n\nI am still learning, can anyone help me whether the hash function is suitable in this case to protect the confidentiality of the movie and how ?", "post URL info": [], "author": "sweetFLUFFYpanda", "ups": "8", "downs": "0", "number of comments": "34", "comments": ["`H(name of movie)` is relatively easy for an attacker to learn the plaintext `name of movie` as there's a (relatively) small set of such names.", ">I am still learning, can anyone help me whether the hash function is suitable in this case to protect the confidentiality of the movie and how ?\n\nHash functions are not used to protect confidentiality, they protect integrity in this scenario.\n\nConsider this: an attacker intercepts the hash and switches it out with random noise. How can Bob determine if he decrypted the correct movie?\n\nWhat you're looking for is a MAC, which uses an hash function, but has some importante modifications.", "Send the encrypted hash of the movie. Then the valid holder of the decryption key can decrypt both the movie and the hash, hash the decrypted movie and compare with the hash.", "I'm pretty sure the professor was trying to avoid people sending the plain hash of the title alongside the encrypted message which would generally be bad (someone could try movie titles to see if they match the hash, or possibly tinker with it since it's not strongly correlated to the ciphertext).\n\nSending the encrypted hash is possible, although it would make little sense alongside the encrypted message if they use the same key: an attacker able to decrypt the movie to modify it can do the same with the hash (assuming non-malleable encryption, otherwise other vectors appear). It can be useful for things like cache management though I suppose: user wants to receive movie, server sends encrypted movie hash, user checks that he doesn't already have it, server sends encrypted movie.\n\nBut whenever you're thinking of encrypted hash I think it's time to consider HMAC: not an encrypted hash, but a hash that requires a key. Use a different key from the encryption one and you've got a good way to exchange hashes securely. You probably want to throw some random value in there using a nonce to make them different each time but that's about it.\n\nNow the question of what to hash should also be asked. You talked about the movie title but what if two movies have the same title? You generally want to hash all relevant information, not just what you feel is enough, because every part of the message that can be modified without being verified is a liability. Of course if you use authenticated encryption as you should that's not nearly as much of an issue since all the necessary verifications are already done at the encryption level: you really don't need a complementary hash to make sure the message wasn't modified in any way.", "The hash of the movie name is essentially a [Message Authentication Code](https://en.wikipedia.org/wiki/Message_authentication_code), so the [standard arguments of Encrypt-then-MAC vs MAC-then-Encrypt vs Encrypt-and-MAC](https://crypto.stackexchange.com/questions/202/should-we-mac-then-encrypt-or-encrypt-then-mac) apply. Your suggestion is Encrypt-and-MAC.", "> I send the hash result of the Hash(name of the movie )\n\nHow will Bob recover this information? Or does Bob already know what movie he is receiving?\n\nAnyway, with websites such as IMDB and Wikipedia, knowing every single movie title in existence would be a fairly straight forward exercise (plus there's always bruteforcing new titles by stringing together common words, numbers, and phrases). You also did not use a salt, which means anyone can pre-compute a database of every single hash for every single movie, meaning the hash can be looked up in O(1) time (instantly) to see the input.", "Cybersecurity researcher here. Hashes are not encryption, they are a method of verifying integrity (even HMAC requires a MAC as the second part of the solution). Hashes can be used to verify that you have sent or recieved a file, and that file has reached its destination without being changed or corrupted; they can also be used as a method of file storage integrity checking (for example, on local disks). If you wanted to create a hash of the movie to ensure it's the same movie you sent to someone, and that it hasn't been changed or modified, you could do that. Collision attacks are possible on weaker hash functions, such as MD5, and SHA-1 (although, breaking SHA-1 requires a lot of computing power.). Using SHA-224 or longer (you'll usually encounter SHA-256 or SHA-512) will prevent collision attacks, at least for now. As for pre-image attacks (reversing the hash to its original input), which are what you seem to be worried about, they have not been practically successful even against MD5 (theoretical attacks exist, but have not been known to have been used with today's computing power), so there is no reason to worry about them.", "[deleted]", "Thanks Mate :)", "The [question](https://crypto.stackexchange.com/q/202) **\"Should we MAC-then-encrypt or encrypt-then-MAC?\"** has got an accepted [answer](https://crypto.stackexchange.com/a/205) by [user46](None) with the score of 329:\n\n>I&#39;m assuming you actually know all of this better than I do. Anyway, [this paper][1] neatly summarizes all these approaches, and what level of security they do or don&#39;t provide. I shall paraphrase it in English, rather than Mathematical notation, as I understand it.\r\n>\r\n> * Encrypt-then-MAC:\r\n>      - Provides integrity of Ciphertext. Assuming the MAC shared secret has not been compromised, we ought to be able to deduce whether a given ciphertext is indeed authentic or has been forged; for example, in public-key cryptography anyone can send you messages. EtM ensures you only read valid messages.\r\n>      - Plaintext integrity.\r\n>      - If the cipher scheme is [malleable][2] we need not be so concerned since the MAC will filter out this invalid ciphertext.\r\n>      - The MAC does not provide any information on the plaintext since, assuming the output of the cipher appears random, so does the MAC. In other words, we haven&#39;t carried any structure from the plaintext into the MAC.\r\n>\r\n> * MAC-then-Encrypt:\r\n>      - Does not provide any integrity on the ciphertext, since we have no way of knowing until we decrypt the message whether it was indeed authentic or spoofed.\r\n>      - Plaintext integrity.\r\n>      - If the cipher scheme is [malleable][3] it may be possible to alter the message to appear valid and have a valid MAC. This is a theoretical point, of course, since practically speaking the MAC secret should provide protection.\r\n>      - Here, the MAC cannot provide any information on the plaintext either, since it is encrypted.\r\n>\r\n> * Encrypt-and-MAC:\r\n>      - No integrity on the ciphertext again, since the MAC is taken against the plaintext. This opens the door to some chosen-ciphertext attacks on the cipher, as shown in section 4 of [Breaking and provably repairing the SSH authenticated encryption scheme: A case study of the Encode-then-Encrypt-and-MAC paradigm][4].\r\n>      - The integrity of the plaintext can be verified\r\n>      - If the cipher scheme is malleable, the contents of the ciphertext could well be altered, but on decryption, we ought to find the plaintext is invalid. Of course, any implementation error that can be exploited in the decryption process has been by that point.\r\n>      - May reveal information about the plaintext in the MAC. Theoretical, of course, but a less than ideal scenario. This occurs if the plaintext messages are repeated, and the MACed data does not include a counter (it does in the SSH 2 protocol, but only as a 32-bit counter, so you should take care to re-key before it overflows).\r\n>\r\n>In short, Encrypt-then-MAC is the most ideal scenario. Any modifications to the ciphertext that do not also have a valid MAC can be filtered out before decryption, protecting against any attacks on the implementation. The MAC cannot, also, be used to infer anything about the plaintext. MAC-then-Encrypt and Encrypt-and-MAC both provide different levels of security, but not the complete set provided by Encrypt-then-MAC.\r\n>\r\n>\r\n>  [1]: http://cseweb.ucsd.edu/~mihir/papers/oem.html\r\n>  [2]: https://en.wikipedia.org/wiki/Malleability_(cryptography)\r\n>  [3]: https://en.wikipedia.org/wiki/Malleability_(cryptography)\r\n>  [4]: http://www.cs.washington.edu/homes/yoshi/papers/SSH/index.html\n\n^(This action was performed automagically.) [^(info_post)](https://www.reddit.com/user/stack_bot/comments/pel66h/info_post/) ^(Did I make a mistake?) [^(contact)](https://www.reddit.com/user/stack_bot/comments/pel563/contact/) ^(or reply: error)", "Makes sense, completely agree with you , So i guess creating hash of the movie name and encrypting it would be a much better option.", "Thank you so much, This Helps a lot.", "This is certainly not a solution. Hash cracking can easily be done with random padding vs standard hashing, due to the fact that random characters can be tried to generate the supposedly random hash you created, just as password cracking does when people don't know any of the characters."]}
{"id": "pckt97", "title": "Intel Labs Establishes Crypto Frontiers Research Center", "url": "https://www.intel.com/content/www/us/en/research/blogs/crypto-frontiers.html", "Created (UTC)": "2021-08-27 03:39:49", "body": "", "post URL info": [], "author": "Natanael_L", "ups": "38", "downs": "0", "number of comments": "37", "comments": ["Just saw this show up.\n\nExcerpt:\n\n> Research areas include Post-Quantum Cryptography (PQC); privacy-preserving cryptography; and lightweight, low-latency cryptography.", "> Areas of Research \n\nI wonder, all the names dropped, are they going to contribute to the research center? If yes (and even if they do not infact)n it's quite interesting to follow, you have some quite known names in there!", "[removed]", "This subreddit is about cryptography, not cryptocurrency."]}
{"id": "pbywh4", "title": "What is the difference between PGP and openPGP?", "url": "https://www.reddit.com/r/crypto/comments/pbywh4/what_is_the_difference_between_pgp_and_openpgp/", "Created (UTC)": "2021-08-26 05:53:40", "body": "Hello, i don't know much about cryptography, and i'm reading the article on pretty good privacy\n\n[**https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy**](https://en.wikipedia.org/wiki/Pretty_Good_Privacy)\n\nand i'm trying to understand what openpgp is and the difference between pgp and openpgp\n\n\"Within PGP Inc., there was still concern surrounding patent issues. RSADSI was challenging the continuation of the Viacrypt RSA license to the newly merged firm. The company adopted an informal internal standard that they called \"Unencumbered PGP\" which would \"use no algorithm with licensing difficulties\". Because of PGP encryption's importance worldwide, many wanted to write their own software that would interoperate with PGP 5. Zimmermann became convinced that an open standard for PGP encryption was critical for them and for the cryptographic community as a whole. In July 1997, PGP Inc. proposed to the [IETF](https://en.wikipedia.org/wiki/IETF) that there be a standard called OpenPGP. They gave the IETF permission to use the name OpenPGP to describe this new standard as well as any program that supported the standard. The IETF accepted the proposal and started the OpenPGP [Working Group](https://en.wikipedia.org/wiki/IETF_Working_Group).\"  \n\n\ni'm not understanding this, what does this mean? there was a licensing problem?   \n\"Zimmermann became convinced that an open standard for PGP encryption was critical for them and for the cryptographic community as a whole.\"  \n\n\nwhat do they mean \"open standard\"?   \n\n\nthank you", "post URL info": ["https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy**](https://en.wikipedia.org/wiki/Pretty_Good_Privacy)", "https://en.wikipedia.org/wiki/IETF)", "https://en.wikipedia.org/wiki/IETF_Working_Group).\""], "author": "The_How_To_Linux", "ups": "17", "downs": "0", "number of comments": "54", "comments": ["* PGP is proprietary software, currently owned by Symantec. PGP supports encryption, decryption, signatures, and verification. PGP can encrypt hard drives.\n* OpenPGP is an Internet standard, like TLS. Its specifications are outlined in several RFCs, notably RFC 4880.\n* GnuPG, or GPG is an open source implementation of the OpenPGP standard, kind of like how OpenSSL is an implementation of TLS. GPG supports encryption, decryption, signatures, and verification. Unlike PGP however, GPG cannot encrypt hard drives.", "* PGP (=pretty good privacy) is (was?) a commercial software\n* OpenPGP is a specification of all kinds of binary/ASCII data formats for encrypted messages and (IIRC) key rings (originally derived from the PGP software)\n* GPG (=GNU Privacy Guard) is a popular open-source implementation of the OpenPGP standard.\n\nFrom what I know PGP and GPG are mostly interoperable since they \"talk the same language\" (OpenPGP). There might be some incompatibilitie, though. It's possible that PGP supports ciphers that GPG does not and vice versa.\n\nI think there are other less-known / less-tested OpenPGP implementations. I've come across one written in the Rust language.", "PGP is licenced while openPGP is a public standard.\nYou can't use PGP without paying while openPGP is free, even though PGP is using the open standard and fully compatible with it\n\n\nHow can PGP exist then when openPGP is the same thing but free ?? Well corporates like to know there is a company behind the product, and they are ready to buy something free if they can have someone reassure them they will fix any bugs or other issues asap", "They wanted to create an open system in which no single party (including Zimmermann) controlled the way it works, and many different competing implementations / apps could be developed by different people while all would be compatible with each other, meaning it doesn't matter which app you use to send and receive pgp email and which app your interlocutor uses, it should all work.\n\nThis model of open standard (federated tools) has shown a bunch of weaknesses for security tools, and some say it failed. You should read Signal's opinion: https://signal.org/blog/the-ecosystem-is-moving/ though I guess the current federated competitor is not pgp but [matrix](https://en.wikipedia.org/wiki/Matrix_\\(protocol\\)). \n\nIf you don't know, [Signal protocol](https://en.wikipedia.org/wiki/Signal_Protocol) is definitely the state of the art secure chat protocol. Its double ratchet is an improvement on OTR's ratchet, while pgp is \"zero ratchet\" - a leak of any party's key will decrypt all the history of messages.\n\nThese days, pgp/openpgp/gpg is not recommend by security practitioners and experts on this sub and elsewhere. It never really fixed its many issues (see EFAIL, Johnny, you are fired!, the keyserver issue, etc.). email is currently believed to not be possible to really secure, and the recommendation is to not share anything secret using email. Very very few people have the operational know how to use pgp securely, and they all are better off with better, modern tools.", "One of them is open", "The title of [RFC-4880](https://datatracker.ietf.org/doc/html/rfc4880) is \"OpenPGP Message Format\". So it defines what should be found in an OpenPGP \"Message\". How you generate such a message and how you might interpret such a message is up to you. You can choose from a bunch of different implementations that all work together due to this message standard. So the OpenPGP initiative has been quite successful in producing a situation where there is more than one program that does PGP stuff.\n\n>\"Unencumbered PGP\" which would \"use no algorithm with licensing difficulties\".\n\nThis refers to the problems that software patents were causing at the time. Software patents are still a problem in the world but the patents have all run out on the algorithms that were causing problems at the time OpenPGP first became a thing.\n\nThere is some discussion of the patent situation from back in the day here:\n\n* https://www.gamers.org/~tony/pgp-legal.html\n\nSo the attempt to avoid software patent problems represented by OpenPGP did not really work out in practice...", ">Internet standard\n\nwhat does that mean? an \"internet standard\" \n\nwhat is an internet standard?", "Can confirm, I have a client that bought a PGP hardware appliance. It literally sits in a rack, but they tell every auditor that because it exists, \"everything is encrypted\".", "``` Well corporates like to know there is a company behind the product, and they are ready to buy something free if they can have someone reassure them they will fix any bugs or other issues asap```\nThis^ and also corporates love to have company behind a product so that incase of security mishaps, the blame can be shifted easily", "https://www.ietf.org/standards/rfcs/", "> sits in a rack\n\nWhere should it go if not a server rack.", "thank you but i don't understand what i'm looking at, what is this? \n\nRFC? what is an rfc?", "https://en.wikipedia.org/wiki/Request_for_Comments"]}
{"id": "pbofzs", "title": "Any security implications to showing a short visual hash during password entry to quickly catch simple typos?", "url": "https://www.reddit.com/r/crypto/comments/pbofzs/any_security_implications_to_showing_a_short/", "Created (UTC)": "2021-08-25 17:38:33", "body": "Say I took the first few bytes of the salted Blake3 hash of the current password, encoded those few bytes into perhaps a color hex and a shape respectively. Then, while entering your password, it displays this shape and color on each keystroke. That way, once you learn your password's corresponding color and code, you can spot a typo before pressing enter. Are there any security implications to something like this? Would you find it helpful while entering your password? Are your passwords even long enough to warrant something like this? \n\nPersonally my password is 50 characters long, and KeePassXC takes about 5 seconds to unlock after entering it (added lots of iterations), so it adds a lot of time if I make a typo. I don't really think I'm the typical case but I'm thinking it could be helpful regardless possibly.\n\nExample I wrote: https://i.imgur.com/EG6KePc.png", "post URL info": ["https://i.imgur.com/EG6KePc.png"], "author": "throwaway27727394927", "ups": "22", "downs": "0", "number of comments": "55", "comments": ["Yes, there are implications.  If a video of those shapes were captured (or similar) the password could be deduced with relatively low effort, by brute-forcing just one character at a time until the symbol matches, and moving on to the next symbol.", "for this to be effective it assumes you memorize the hash/color pattern, which i doubt many people would do unless this is common place and they reuse the same password everywhere but ideally they aren't :) I don't usually make errors in my password entry (passphrases ftw) and it doesn't take long enough to unlock my pw manager that this would be useful to me. Regardless...\n\nOne potential security issue is that if someone is able to see the screen as you type, and they know the hashing algorithm, it's fairly trivial to brute force the keystrokes a character at a time since you are hashing and showing the result a single keystroke at a time.\n\nI bring that up because otherwise if someone can't see your screen, then \"show password\" seems simpler and doesn't require any memorization", "For some reason, my muscle memory is better than my visual memory: even if I see my password with a mistyped letter, it takes me longer to 1) delete the mistake, 2) get back to rhythm... than to just retype the whole long thing.\n\nI still think your idea is cute though!", "[deleted]", "Thanks OP for triggering an old memory and a deep dive to find it back :) in Lotus Notes, they had a login screen that would change symbols based on your typing. Supposedly to distract people watching over your shoulder but... It turns out the sequence was related to your typing. Providing some hints about your password. More info here https://security.stackexchange.com/questions/41247/changing-picture-as-characters-entered-into-password", "It'd be cool if the color/shapes were displayed instead of the dots in the password entry field. So you'd have a sequence of different colored shapes/symbols instead of dots. Though might be annoying since it wouldn't be 1 to 1 with characters entered.", "I'd prefer a short sequence of emoji, keyed from a deterministic RNG based on the hash of the input, over just colors. Emoji have distinct shapes and would be more accessible to people with colorblindness.", "[removed]", "Hm. Perhaps as otherwise mentioned, as an alternative to the view password button, or shown before unlocking?", "I was thinking only in specific applications, like KeePassXC or the authorization popup on some linux distros. I guess I think it would be useful since it takes me so long :p\n\n>One potential security issue is that if someone is able to see the screen as you type, and they know the hashing algorithm, it's fairly trivial to brute force the keystrokes a character at a time since you are hashing and showing the result a single keystroke at a time.\n\nIt would only be perhaps seven hex values so very few bytes, so I'm not sure if that's enough to brute force? I should do the math for that though \ud83e\udd14", "Couldn't you just add a salt value such that effectively you cannot brute force the hash given you know the visual hash output?\n\nEdit: i.e. Bind the visual hash to the machine/prompt.", "Mine as well! This is really for verifying at the end quicker than deriving the whole Argon2 hash as mine is a whole-hell-of-a-lot of iterations.", "> As long as your hash follows the standard cryptographic hash properties, I can\u2019t think of any issues\u2026 though that certainly doesn\u2019t mean there aren\u2019t any\n\nI believe /u/vimmz and /u/washtubs and /u/smorga have shown that there are issues with it.", "Ooh, lots of good answers there. Thanks!", "Why don't you just delete your account?", "I think they're saying you have an over the shoulder evesdropper that can't see your keyboard but is able to video tape your screen.\n\nEvery time you enter a character the hash changes and updates on the screen, so a program could be written that tries every possible character until that hash is achieved. Then you type the next character, and it repeats checking all the possible characters you might have typed until the hash matches again. Basically you have an n length password, and you've revealed n hashes which are all very closely related.\n\nMaybe if it's such a big password you could show 5 hashes, one every 10 characters? You could even just show the first 2 characters of each hash cause chances are that would be enough to catch a mistake, and it's not the end of the world otherwise.", "It\u2019s enough to significantly narrow the range of possible values. A short hash value means there will be more collisions, but it still leaks information about the password.\n\nAfter a single character you see haha \u201cab01\u201d, so you try each character until you get that and now you know the first value.\nSecond character is typed and now you see hash \u201cc1af\u201d, so you put in the known first char and guess the second one until you get that hash.\nRinse and repeat until you have the whole thing.\n\nCollisions are possible so it might be that two possible characters would result in the same hash, but at that point you just branch off and continue trying both and find the one that makes more sense or just try them both", "Then the value would be nondeterministic, which I think defeats the point. OP's idea, to my understanding, is for the user to be given a value that is comparable to something they have seen before. So if the value is not what they expected it to be after typing in the password, they know that they made a typo.", "Not a random one every time. Just generate a long random value and store it on the machine. Then you have a unique pattern per machine. It isn't portable anymore, but maybe you can also save it along the password DB or something if you need portability between machines.", "Yeah a persistent salt fed as input to the hash that\u2019s not visible on screen would mitigate this, but adds portability issues as y\u2019all said. \n\nYou could fix this by having the service allow you to set your own salt value so you could carry it between them, but now we\u2019re building an even more complicated thing to provide a small benefit over a \u201cshow password\u201d feature\n\nFor OPs single use case in keepass this might be fine though since it\u2019s only needed in one place"]}
{"id": "panm2d", "title": "How did public key cryptography go from an idea in James H. Ellis head, to an actual usable program like gnu privacy guard?", "url": "https://www.reddit.com/r/crypto/comments/panm2d/how_did_public_key_cryptography_go_from_an_idea/", "Created (UTC)": "2021-08-24 06:43:57", "body": "Hello, i have been trying to wrap my head around public key cryptography for a while, and this is what i have so far\n\nit all started with this guy [https://en.wikipedia.org/wiki/James\\_H.\\_Ellis](https://en.wikipedia.org/wiki/James_H._Ellis) he was the first to really think up public key cryptography, but what i'm confused about is this, how did public key cryptography get transformed from an idea in this guys head?\n\nto an actual free and work able program like gnu privacy guard? [https://en.wikipedia.org/wiki/GNU\\_Privacy\\_Guard](https://en.wikipedia.org/wiki/GNU_Privacy_Guard)\n\nhow did public key cryptography come so far? what were the big steps in between? who made these steps and why?\n\ni know diffe helman and RSA is in there, but i'm not clear and what came first and what built off what first and why, if anyone could help me so i can have a clear linear what came before what history i would really appreciate it, thank you.", "post URL info": ["https://en.wikipedia.org/wiki/James\\_H.\\_Ellis](https://en.wikipedia.org/wiki/James_H._Ellis)", "https://en.wikipedia.org/wiki/GNU\\_Privacy\\_Guard](https://en.wikipedia.org/wiki/GNU_Privacy_Guard)"], "author": "The_How_To_Linux", "ups": "30", "downs": "0", "number of comments": "37", "comments": ["The \"missing link\" you're looking for is [PGP](https://en.wikipedia.org/wiki/Pretty_Good_Privacy#History), whose inventor worked off the publicly available papers by Diffie, Hellman, Rivest, Shamir and Adleman, who came up with the necessary building blocks independently of Ellis (who wasn't allowed to publish anything) and published them in the late 1970s.", "You're right that James Ellis was one of the first people to conceive of public key cryptography. In fact I just [posted about him in /r/crypto the other day](https://www.reddit.com/r/crypto/comments/p7atax/what_is_the_history_of_public_key_cryptography/h9iyhuq/). However, he worked at GCHQ and all of his work was kept secret until long after the civilian sector independently (re)discovered the same algorithms they discovered at GCHQ (which we now know as \"RSA\" and Diffie-Hellman).\n\nIn civilian life, it was probably Ralph Merkle who originally came up with the idea in the form of [Merkle's Puzzles](https://en.wikipedia.org/wiki/Merkle%27s_Puzzles). His ideas would go on to inspire Whit Diffie and Martin Hellman of the eponymous Diffie-Hellman construction. The three of them were [effectively a trifecta in the same way the creators of RSA were](http://news.stanford.edu/pr/2016/images/turing_news.jpg), although unfortunately Merkle receives little credit for it.", "If you're interested in that history, and perhaps the history of the development of other algorithms, then definitely pick up these two books:\n\nhttps://en.wikipedia.org/wiki/The_Code_Book\n\nhttps://en.wikipedia.org/wiki/The_Codebreakers\n\nBoth books cover your question (Chapter 7 in TCB is entirely dedicated to your question) as well as many other interesting topics.", "I think the disconnect you may be seeing is that, while James Ellis was an early inventor of the idea of public key crypto, and his peers Cocks and Williamson claim to have first come up with the ideas for RSA and Diffie-Hellman, it doesn't sound like they actually implemented them for lack of available computing power in the early 1970s, and the work was ultimately set aside. And since all these chaps worked for the UK Government Communications Headquarters, their discoveries were kept secret and not declassified until 1997.\n\nIn the meantime, and independently, Diffie and Hellman created the idea of public key crypto, as published in their readable 1976 paper, [New Directions in Cryptography](https://ee.stanford.edu/~hellman/publications/24.pdf).\n\nThe Wikipedia article on RSA picks up the story:\n\n> The idea of an asymmetric public-private key cryptosystem is attributed to Whitfield Diffie and Martin Hellman, who published this concept in 1976. They also introduced digital signatures and attempted to apply number theory. Their formulation used a shared-secret-key created from exponentiation of some number, modulo a prime number. However, they left open the problem of realizing a one-way function, possibly because the difficulty of factoring was not well-studied at the time.\n>\n>Ron Rivest, Adi Shamir, and Leonard Adleman at the Massachusetts Institute of Technology, made several attempts over the course of a year to create a one-way function that was hard to invert. Rivest and Shamir, as computer scientists, proposed many potential functions, while Adleman, as a mathematician, was responsible for finding their weaknesses. They tried many approaches including \"knapsack-based\" and \"permutation polynomials\". For a time, they thought what they wanted to achieve was impossible due to contradictory requirements. In April 1977, they spent Passover at the house of a student and drank a good deal of Manischewitz wine before returning to their homes at around midnight. Rivest, unable to sleep, lay on the couch with a math textbook and started thinking about their one-way function. He spent the rest of the night formalizing his idea, and he had much of the paper ready by daybreak. The algorithm is now known as RSA \u2013 the initials of their surnames in same order as their paper.", "PGP/GPG is a \"workable\" solution, if you are careful.   You won't be careful enough, however... so it doesn't seem that workable by more modern standards.\n\nBut yes, it's a relatively workable solution compared to having the abstract concept of asymmetric key cryptography.  How we got to PGP is a big question, and I only have the vaguest understandings of cryptographic history.  It basically involved being wrong, a lot.", "so it was james ellis, then pgp then gnu privacy guard?\n\nwhere does diffie helman and rsa fit into this?", "> Merkle receives little credit for it\n\nWell, considering the credit he gets for Merkle trees, I think he's probably assured to not fade away in history.", "To add a few points:\n\nThe guys at GCHQ never imagined that this would actually be used some day.  In fact, it never saw the light of day until well after our friends DH/M and RSA re-invented it and sold the concept to the world, but not without help from others.  Below are some key points.\n\nIn [Diffie/Hellman's paper](https://ee.stanford.edu/~hellman/publications/24.pdf), they realised it could be practical, which is clearly seen by the first 2 sentences of their paper:\n\n> WE  STAND TODAY on  the  brink of  a revolution in  cryptography. The development of  cheap digital \nhardware has  freed it from the design limitations of  mechanical computing and brought the cost of high grade  cryptographic devices down to  where they can  be  used  in  such  commercial applications as remote cash  dispensers and computer terminals. \n\nThen came RSA, who saw the potential and as a consequence, [patented it](https://www.freepatentsonline.com/4405829.html).\n\nA company was formed around the RSA encryption algorithm.  At that time, it was called \"RSA Data Security\".  To my knowledge, the only inventor involved in this company was Rivest (I could be wrong, but when I was part of the company from 1997-1999, he was the only one involved with it).\n\nEven then, not many people believed that this was an important technology for commercial companies.  Remember: back then there was no such thing as e-commerce.  It was the CEO of RSA Data Security who sold it to the world.  [Jim Bidzos](https://en.wikipedia.org/wiki/James_Bidzos) made people believe that they needed it.\n\nThe RSA patent and the way that RSA Data Security demanded lots of money to use their technology pissed off a lot of people.  This naturally led those people to [Phil Zimmermann's freely available PGP implementation](https://en.wikipedia.org/wiki/Pretty_Good_Privacy), which at the time was mainly used for encrypted email.\n\n[GPG was designed to interoperate with PGP but not be subject to US export laws](https://www.propublica.org/article/the-worlds-email-encryption-software-relies-on-one-guy-who-is-going-broke), because it was written outside of the USA."]}
{"id": "passyg", "title": "Another stupid Ed25519 question", "url": "https://www.reddit.com/r/crypto/comments/passyg/another_stupid_ed25519_question/", "Created (UTC)": "2021-08-24 11:10:07", "body": "Hi folks,\n\nI've been reading about the differences between PureEdDSDA and HashEdDSA.\n\nI understand why we need the hash first variant, as described here:\n\n\"The main motivation for HashEdDSA is the following storage issue (which is irrelevant to most well-designed signature applications). Computing the PureEdDSA signature of M requires reading through M twice from a buffer as long as M, and therefore does not support a small-memory \u201cInitUpdate-Final\u201d interface for long messages. Every common hash function H0 supports a smallmemory \u201cInit-Update-Final\u201d interface for long messages, so H0 -EdDSA signing also supports a small-memory \u201cInit-Update-Final\u201d interface for long messages.\"\n\n\nThough, looking at the process for EdDSA I don't see why it's necessary to have a \"buffer as long as M\"? (where M is the message)...\n\nIsn't the process just:\n\n1. compute the nonce as HASH(nonce_key || message)\n2. compute the commitment R = [nonce]G with G the generator of the group.\n3. compute the challenge as HASH(commitment || public_key || message)\n4. compute the proof S = nonce + challenge \u00d7 signing_key\nthe signature is (R, S)\n\nWhere is the need to hold the full message in memory there? The hashing process doesn't need it right?", "post URL info": [], "author": "anonXMR", "ups": "11", "downs": "0", "number of comments": "41", "comments": ["Because of this:\n\n>1. compute the nonce as HASH(nonce_key || message)\n\nand this:\n\n>3. compute the challenge as HASH(commitment || public_key || message)\n\nEach of these invocations of HASH require the entire message M as input. Therefore, you need a buffer in memory large enough to store M.", "> HashEdDSA\n\nFYI, RFC8032 calls this \"Ed25519ph\" (for prehash)\n\nI think @__enr0n already answered your question, but tl;dr: traditional Ed25519 does two passes over the message, so it's required to either keep the message in memory or be able to recompute it twice. But generally all Ed25519 APIs are going to have you pass in a message buffer, and the implementation does two passes over a message buffer.\n\nFunny thing about Ed25519ph: when the CFRG was working on the drafts that would become RFC8032, a big deal was made of Ed25519ph and how it was required for HSM support. It of course has a big drawback: by doing two passes over the message, traditional Ed25519 can better tolerate collisions in the underlying hash function, i.e. SHA-512.\n\nBut even after a bunch of work was done to specify Ed25519ph and shoehorn a weak form of domain separation into it, so far I haven't seen it used by any HSMs. The only notable use I can think of is signing extremely large messages. Every HSM, KMS, and token I've encountered that supports it only supports the traditional (non-IUF/prehash) version. And that's probably for the best.", "> Computing the PureEdDSA signature of M requires reading through M twice from a buffer as long as M\n\nThis doesn't literally mean \"has to be a one-shot API that reads the entire message from RAM\". You can implement it as a streaming API that reads from disk twice if you *really* want to.", "You have many answers already, but I believe you don\u2019t have the whole story yet.\n\nHere\u2019s a little secret: EdDSA does _not_, strictly speaking, require two passes. Recall how you compute the nonce:\n\n    private_key = random_secret()\n    nonce_key   = HASH(private_seed)[32:63]\n    nonce       = HASH(nonce_key || message)\n\nClearly the nonce is meant to look random. We compute it deterministically to avoid user error, but the truth is, we could use an actual random number instead. Do that, and you can skip the first pass entirely.\n\n---\n\nNote that even if you stay true to the letter of EdDSA, only signing requires two passes. Signature verification can easily do this in a single pass, and as such needs the big buffer even less. The real problem is, APIs rarely provides an incremental interface: I wrote [the only one](https://monocypher.org/manual/advanced/sign-incr) I  know of.\n\nThere\u2019s a reason for the lack of an incremental interface, though: signature can botch the first pass and use a constant instead of a random nonce, and incremental verification easily runs awful of the [Cryptographic Doom Principle](https://moxie.org/2011/12/13/the-cryptographic-doom-principle.html).\n\nThis is why minising provides a warning when using PureEdDSA on big files: libsodium does not have an incremental verification API, and thus forces minisign to allocate a ginormous amount of memory, even for \"single pass\" verification. We could add an incremental verification API to libsodium, if /u/jedisct1 is willing to accept such a contribution.\n\nNow to be honest, as much as I\u2019m tempted to moan about the loss of hash collision resilience caused by the use of `-H` (HashEdDSA), I\u2019m not actually worried. SHA-512 looks very safe already.\n\n---\n\nNow, another question might pop up: how come  Bernstein, Yang, Duif, Schwabe, and Lange did not designed EdDSA in such a way that signature would require only one pass? The problem with how they do this is that we must the message once to get the nonce, and only then can we even *start* to hash the message for real. But no matter how I look at it, we can\u2019t even allow the two hashes to run in parallel without losing hash collision resilience. In the end, we\u2019re better just giving up and just using HashEdDSA when we need it.", "Thanks! So that\u2019s what\u2019s confusing me. \nNormally when we hash large files we read them in bit by bit and digest them. \n\nThat\u2019s the whole point of pre hash!\n\nSo why here does the entire message need to be in memory. Can\u2019t we just concatenate nonce_key and message and hash it bit by bit?\n\nLike when I sha512 a 2gb file, it doesn\u2019t use 2gb memory.", "Interesting thank you!! Normally when we hash large files we read them in bit by bit and digest them.\nThat\u2019s the whole point of pre hash!\nSo why here does the entire message need to be in memory. Can\u2019t we just concatenate nonce_key and message and hash it bit by bit?\nLike when I sha512 a 2gb file, it doesn\u2019t use 2gb memory.", "I worked on a HSM that supported HashDSA, and customers did use it (it had a ~8 MB limit and customers had to sign 30 MB PDFs or something like that)", "Why does minisign give this warning then why trying to sign a file bigger than 1GB?\n\nData has to be smaller than 1 GB. Or use the -H option.\n\nthanks", ">  You can implement it as a streaming API that reads from disk twice if you _really_ want to.\n\n[I have done it](https://monocypher.org/manual/advanced/sign-incr). And if you\u2019re feeling lucky, you can even use it to perform only one pass. That said, I understand why most (all besides Monocypher?) don\u2019t provide this particular foot-gun.", "Super interesting thank you!", "You can do that. This issue is more related to streaming and APIs.\n\nFor example, if you use the PKCS#11 API, it allows you to pass the message in chunks in order to be signed. But it doesn't allow you to do that in two passes, as it would required for PureEdDSA. The same applies to other crypto APIs (JCA, CNG, etc.)\n\nAnother example: suppose you have a binary that signs what you pass to stdin. So you could call e.g. `cat 2gbfile | sign`. It's impossible to support PureEdDSA with this, since the message is passed only once to `sign`.", "> Normally when we hash large files we read them in bit by bit and digest them. That\u2019s the whole point of pre hash!\n\nUnfortunately this single pass prehash method can be catastrophic when there are collisions in the underlying hash function. There's a long history of this with MD2, MD5, and SHA1, with critical impacts to the X.509 PKI.\n\nEd25519's construction is a bit closer to something like HMAC which also hashes the message twice. In doing so it gains resistance to collision attacks against the underlying hash function.\n\nThough I don't suspect we'll see collisions in the SHA2 family used by Ed25519, at least for quite some time, this is still a very nice property to have, but it is directly at odds with an IUF-style API.", "Hint: what does the -H option do?", "Perfect thanks!", "But all crypto hash functions are collision resistant by definition right?", "it invokes HashEdDSA, whereby the file is first hashed and then that hash is signed.\n\nMy question was, why does PureEdDSA by definition require memory the size of the underlying message to function? - the answer proposed above is, \"it doesn't\".\n\nThen though, I see most implementations, like minisign, don't support  large messages...\n\nI'm confused.", "Secure ones are. Unfortunately attacks only get better, which is what we saw with MD2, MD5, and SHA1, none of which are considered secure today because practical collision attacks are possible."]}
{"id": "paoxp1", "title": "Programmers Don\u2019t Understand Hash Functions", "url": "https://soatok.blog/2021/08/24/programmers-dont-understand-hash-functions/", "Created (UTC)": "2021-08-24 07:53:55", "body": "", "post URL info": [], "author": "Soatok", "ups": "10", "downs": "0", "number of comments": "26", "comments": ["I learned about non-security related uses for hashing in my CS courses well before I studied security related stuff. Maybe other schools are different, but I feel like this specifically doesn't apply to general software engineers and programmers as the article claims.\n\nRegardless, has some good info.", "(This is a general comment about your blog and not specific to this post: I really like how you write about crypto, a very very nice reading) \\[sorry for the off-topic\\]", "Haha interesting choice for an article title but good read. Nicely summarizes a lot of application-level considerations in one place.", "[removed]", "(thanks for the award! :-) )", "Srsly, if you keep this up you may get banned.", "srsly"]}
{"id": "paoexb", "title": "GRETA (Gated Rotor Encryption Table Algorithm) - Card Cipher", "url": "https://www.reddit.com/r/crypto/comments/paoexb/greta_gated_rotor_encryption_table_algorithm_card/", "Created (UTC)": "2021-08-24 07:26:54", "body": "Inspired by the design of the SIGABA rotor machine, I have devised a card cipher (GRETA S) that is designed to be more secure than Bruce Schneier's Solitaire.\n\nGRETA S involves a lot of deck stepping or rotation (removing the top card and placing it in the rear, not your rear) and is inspired by William Friedman et al.  However, there is no need to know any math as all operations are either stepping or substitution look up.\n\nI have penned a (52!) strength of the cipher and hope it lives up to that.  Happy rotor stepping!\n\nDocumentation:  [https://github.com/pvial00/GRETA/blob/master/docs/GRETA%20S%20Card%20Cipher.pdf](https://github.com/pvial00/GRETA/blob/master/docs/GRETA%20S%20Card%20Cipher.pdf)\n\nPython simulation:\n\n[https://github.com/pvial00/GRETA](https://github.com/pvial00/GRETA)", "post URL info": ["https://github.com/pvial00/GRETA/blob/master/docs/GRETA%20S%20Card%20Cipher.pdf](https://github.com/pvial00/GRETA/blob/master/docs/GRETA%20S%20Card%20Cipher.pdf)", "https://github.com/pvial00/GRETA](https://github.com/pvial00/GRETA)"], "author": "None", "ups": "12", "downs": "0", "number of comments": "23", "comments": ["\"GRETA Card Cipher.pdf\" only has the following content on a single page:\n\n> Cipher Deck has a random assortment of hearts and clubs. Stepping Deck has a random assortment of diamonds and spades.\n\n\"GRETA S Card Cipher.pdf\" doesn't actually describe the stepping and rotor operations. How would you encrypt `DO NOT USE PC`? The PDF does not make any of the encryption or decryption steps clear.", "[removed]", "I'll see what I can do to clear up the steps.  I did make a revision while this was posted.  The glossary item of stepping is the \"Removing a card from front of the deck and placing it in the rear\" perhaps isn't clear enough.  Thanks for the feedback.", "Give it a look see, I added test vectors and an example of the two deck arrangement.  I'm trying to make the document short because most card cipher instructions read like voodoo (or game operation cut, this, value that).", "Much cheesy very banned wow"]}
{"id": "pa8mhs", "title": "How to do E2EE in the Browser correctly if even possible?", "url": "https://www.reddit.com/r/crypto/comments/pa8mhs/how_to_do_e2ee_in_the_browser_correctly_if_even/", "Created (UTC)": "2021-08-23 13:54:27", "body": "Hi Guys,\n\nMy first Post on here! Been reading for a few Days and decided to join and just drop my Question.\n\nCurrently a few Pals of mine and me are creating an App and the next Feature will be an Chat. We would like the Chat to be End-to-End Encrypted. I've looked into the Problem and often saw that E2EE (or Encryption in general) using JS in the Browser is often discouraged.\n\nWe're building our App for Three Platforms: Web, iOS and Android. The Bundle for the Web will be served by an Server, the Bundle for iOS and Android is in the IPA / APK directly and will be loaded in a WebView there. So the most feasible Attack-Target would be the Web-App because this could most easily be tampered with.\n\nIn my first Tests are generating an ECDH Key-Pair with a P-256 Curve, deriving the Key using the respective Public and Private Keys to an AES-GCM Key and then En-/Decrypting with AES-GCM. (I hope how I articulated it makes sense to you Guys. Noob here!)\n\nWhat I would like to know is:\n\n1. Why is Encryption in the Browser Insecure? (I already read about AES-GCM and it's caveats, but the Browser part interests me. I read [this](https://github.com/PeculiarVentures/2key-ratchet/blob/master/DIFFERENCES.md) post about AES-GCM)\n2. Is safe E2EE in our Architecture even possible?\n3. If yes: How could I make it as secure as possible without changing much about the Platforms (using Web, iOS and Android and not cutting Web)\n\nBonus:\n\nI found a Library ([2key-ratchet](https://github.com/PeculiarVentures/2key-ratchet)) which claims to have implemented the \"Double Ratchet\" protocol and X3DH in Typescript. Due to the [Differences](https://github.com/PeculiarVentures/2key-ratchet/blob/master/DIFFERENCES.md) stated in the Repo: Is this a good Replacement for my Testing \"Stack\"?\n\nThanks in Advance!\n\n(To 3. : I don't want a Step for Step Explanation, just a Hint in a better/right direction. I started a few Weeks ago with Encryption and Crypto in general and haven't had this much fun coding in years!)", "post URL info": ["https://github.com/PeculiarVentures/2key-ratchet/blob/master/DIFFERENCES.md)", "https://github.com/PeculiarVentures/2key-ratchet))", "https://github.com/PeculiarVentures/2key-ratchet/blob/master/DIFFERENCES.md)"], "author": "TheThirtyFive", "ups": "7", "downs": "0", "number of comments": "28", "comments": ["1. Encryption in the browser isn't insecure. E2EE is. It's the \"End-to-End\" bit that's problematic. Encrypting communications to the server is easy and safe, just use TLS. Encrypting between clients is the hard part. \n\n2. No. The server (assumed malicious in an E2EE model) is providing the encryption code every time the site is loaded, so it can provide a backdoor instead.\n\nThat's the core problem: there's no practical way for the client to verify that the code they're using hasn't changed from the last time they used the site.", "When Google was looking at implementing E2E mail via a browser plugin, it gave up in part because of the difficulties of doing it right. They published the library and documentation, but the more valuable part was the [threat model](https://github.com/google/end-to-end/wiki/Threat-model). In it they examine the assets to protect, threat sources both inside and outside the threat model, UI threats, message threats, key-related threats, cryptographic threats, and other threats. It's an excellent walk-through of just how difficult it is to do general encryption right, and why doing it in the browser is so hard.", "The first thing you need to do is take a step back and ask what the threat model is.\n\nThe goal of E2EE is typically to protect a user of a particular piece of software from malicious actions by its authors. This concept goes back to [Kerckhoffs's principle](https://en.wikipedia.org/wiki/Kerckhoffs%27s_principle) which is briefly stated in that the security of a system should rely on the secrecy of the key, not the secrecy of the algorithm.\n\nA well-designed cryptosystem is one which is secure when its algorithm/source code is both public and well-scrutinized. Only then can we say that it is free from malicious authorship.\n\nE2EE thus relies on some sort of external auditing authority to audit/\"bless\" the software and ensure the authors can't change it in malicious ways.\n\nJavaScript is not a reliable platform in this regard, because it's designed to dynamically load \"software\" on-the-fly, and can't provide any form of reliable static artifact.\n\nYou can try to build such a thing leveraging various new web features (e.g. Service Workers), but there is not a reliable well-audited approach to doing so which can even be used to bootstrap such a system and provide a root-of-trust.", "You could in theory make your E2EE chat app be a browser plugin. Mailvelope is in example of this approach.", "I think others already covered the big thing, the threat model makes it tricky, but it does depend on your specific threat model, and what you're willing to compromise on. If you're okay with the web only being supplemental, you could have the iOS and android apps sync to web in a similar way to google messages or whatsapp. If you need primary users on web its tricker, but not impossible using JS. You'll just inevitably have users that are uncomfortable with it because it would be so much more trivial to do a MitM. There's really good JS libraries though, so you can have full client side encryption running, you just need users that trust or audit what the server gives. It also makes the asynchronicity provided by a double-ratchet protocol to be quite tricky, but not impossible. I guess you'd just have cookies store an encrypted state of the ratchet with a passphrase or something.\n\nI'm curious why you (and this library you've found) are using P-256 curves though? ed25519 should almost universally be a better option, and I don't see a reason for using P256 if you're doing a new implementation of anything. You can pretty easily use libsodium/NaCl bindings in JS too, [as described in this article](https://soatok.blog/2020/11/14/going-bark-a-furrys-guide-to-end-to-end-encryption/)", "Thanks!\n\nIt\u2018s harder to Update an App for an Attacker than just upload a new JS-File to an Server, didn\u2018t think about this part so much.\n\nI understand that TLS would be enough for the Communication between the Client and the Server but then we would keep the Users Private Chats in Plain Text on our Servers and that\u2018s not what we want.\nIt\u2018s not just about: \u201eYour Chats are safe from Hackers\u201c it\u2018s also about: \u201eIt\u2018s safe from us\u201c. \n\nHow could we achieve this? Is my \u201eEncryption Model\u201c which I explained in the Original Post good enough for this purpose or should we use something entirely different?\n\nI think it would be best to cut the Web-App so we would only keep the iOS and Android Apps. The Web part would just be an convenience for the Users which isn\u2018t really that needed.\n\nThis App isn\u2018t designed and quite honestly will never be Enterprise grade in Forms of User count. It\u2018s just fun to build something and overengineer it and learn new things!", "A solution to this that cryptocurrency \"dApps\" have began using is to host the webapp on IPFS, then the client just runs IPFS locally and opens the IPFS hash of it in the browser.", "Oh, that\u2018s pretty interesting. Thanks for the link!\n\nIt\u2018s kinda scary to read how \u201eeasy\u201c Things like this can be and how easy you can fuck up.", "**[Kerckhoffs's principle](https://en.wikipedia.org/wiki/Kerckhoffs's_principle)** \n \n >Kerckhoffs's principle (also called Kerckhoffs's desideratum, assumption, axiom, doctrine or law) of cryptography was stated by Netherlands born cryptographer Auguste Kerckhoffs in the 19th century:  A cryptosystem should be secure even if everything about the system, except the key, is public knowledge. Kerckhoffs's principle was reformulated (or possibly independently formulated) by American mathematician Claude Shannon as \"the enemy knows the system\", i. e. , \"one ought to design systems under the assumption that the enemy will immediately gain full familiarity with them\".\n \n^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/crypto/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)", "Yeah in theory this would be an option. For our App though it isn\u2018t an option since the Apps would have E2EE out of the Box. So to even read Messages from other User in the Web the Users would need the Extension.\n\nAnd as u/NetworkLlama said, even Google gave this approach up because of the difficulties of doing it right.", "Actually the approach Whatsapp Web uses might be Suitable for this. Thanks for the Idea!\n\nI was almost certain that the Web-App would be the hardest part to get right. If *we* could even get it right. We\u2018re no Cryptographers, just Developers who would like to do something new.\n\nI chose P256 cause I\u2018ve read, it would be a good compromise between Security and Performance. As stated perviously we\u2018re no experts, this was a part where we trusted the Internet. Since our first Implementation was made in a few Hours we just choose what was easily available with the SubtleCrypto API. \n\nThanks for the recommendation, will look into it!", "In terms of security model, that's just another take on those ancient browser addons which \"pinned\" the Javascript on a web page", "The link provided by /u/NetworkLlama has an \"Backdoor in End-To-End source code\" section that is quite relevant here. In general, you can't have effective end to end encryption unless the user is in control of the software used. So, yeah, it is awkward to require that but if you want E2EE it is a prerequisite. Otherwise you would be better off accepting that your system has to have a trusted third party (that might be you) which simplifies things a lot."]}
{"id": "p9uegm", "title": "FHE.org meetup | Google's C++ to FHE compiler", "url": "https://www.reddit.com/r/crypto/comments/p9uegm/fheorg_meetup_googles_c_to_fhe_compiler/", "Created (UTC)": "2021-08-22 23:56:10", "body": "Hello,\n\nThe next FHE meetup is this coming thursday on zoom. The team at Google will present the technical details of their C++ to FHE compiler.\n\nLink to attend: [https://www.meetup.com/fhe-org/events/279950583](https://www.meetup.com/fhe-org/events/279950583)\n\nSee you there!", "post URL info": ["https://www.meetup.com/fhe-org/events/279950583](https://www.meetup.com/fhe-org/events/279950583)"], "author": "randhindi", "ups": "18", "downs": "0", "number of comments": "20", "comments": []}
{"id": "p9u5i7", "title": "What is the Best Encryption Program for USB Drive?", "url": "https://www.reddit.com/r/crypto/comments/p9u5i7/what_is_the_best_encryption_program_for_usb_drive/", "Created (UTC)": "2021-08-22 23:36:31", "body": "Hi, what is the best (portable) encryption program for a USB drive. I've been using Windows Bitlocker so far, but prefer not to trust Microsoft with my encryption. :) I was thinking VeraCrypt, but based on the article below it seems VeraCrypt can be cracked quite easily? Would love to hear what you guys think is the best option for a portable drive. Thanks. :)\n\nmacobserver.com/news/elcomsoft-cracks-veracrypt/", "post URL info": [], "author": "perpetualvagabond", "ups": "13", "downs": "0", "number of comments": "25", "comments": ["VeraCrypt cannot be cracked, that article is misleading clickbait.\n\nAll security software is susceptible to the same \"attack\" which requires the software to have kernel privilege on the target computer, while it is running. No security software can save you from someone that has kernel access to your computer.", "This subreddit might be more relevant to the type of attack described in the link:\n\n* /r/antiforensics/", "Is there a particular reason you don't want to trust MS? I know there's a lot of \"The NSA have a backdoor\" chat but the fact it's approved in lots of countries for (lower level) classified material suggests it's has good baseline security (and are you likely to be of interest to the NSA?)  It has the upside that bitlocker is part of windows so it's easily portable without having to install software or need admin rights to unlock.\n\nI use Veracrypt but I'm under no illusion that it's not a bit creaky at the seams; it's development processes and coding quality aren't up to scratch and bits of it are outdated and overdue replacement. While various audits haven't found any horrendous issues, it's still largely a one-person project with all the limitations that brings. It's also not portable without admin rights.\n\n[https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/Studies/Veracrypt/Veracrypt.html](https://www.bsi.bund.de/SharedDocs/Downloads/EN/BSI/Publications/Studies/Veracrypt/Veracrypt.html)\n\nI'd had nice experience with some usb encryption software from Avanti which had a useful portable version that didn't need admin rights. But I have no idea how secure the underlying encryption is, plus it only seems to be sold in to the corporate market.", "What about Usecrypt Safe? Hybrid Virtual Key Managment cannot be cracked, maybe if you steal some1 pc..", "Exactly\u2026\n\nAnd thus the reason for non-persistent, no HD access, boot from CD / USB, trusted Linux OS\u2019s like Lightweight Portable Security / TENS  and others\n\nhttps://www.spi.dod.mil/lipose.htm", "Yeah after reading the article closely it seems this only work in very specific cases. Thanks for the comment. :)", "thanks", "Thanks for the reply. I do use Bitlocker on my laptop at the moment and love how easy it is to use. Apart from the fact that I would be it seems like that Microsoft have included a backdoor somehow, one thing I don't realy like is that it can only run on PC with Windows Pro installed. So I'm happy to keep using it for my laptop, but for portable drives I would like something that I can open on any (windows) laptop.", "I might be wrong but I believe you only need Pro or Enterprise to initially encrypt a drive. Home can decrypt an existing drive for access.", "Thanks, I thought I read somewhere that you could only open it with Windows Pro but looks like you are right. That makes it a lot more user friendly at least. :)"]}
{"id": "p9eoze", "title": "Does using Windows-compatible filesystems introduce any sort of open source blobs?", "url": "https://www.reddit.com/r/crypto/comments/p9eoze/does_using_windowscompatible_filesystems/", "Created (UTC)": "2021-08-22 08:40:29", "body": "I want to create a small volume for documents which I will open with Tails Linux distro only (so the contents of the encrypted file are opened only on RAM), so I don't really care about Windows. Which filesystem should I use?\n\nIm also paranoid about any possible leak of information because i've heard journaling file systems leak information so im not sure which to use.\n\n>When a file-hosted VeraCrypt container is stored in a journaling file system (such as NTFS or Ext3), a copy of the VeraCrypt container (or of its fragment) may remain in the free space on the host volume. This may have various security implications. For  example, if you change the volume password/keyfile(s) and an adversary finds the old copy or fragment (the old header) of the VeraCrypt volume, he might use it to mount the volume using an old compromised password (and/or using compromised keyfiles using an  old compromised password (and/or using compromised keyfiles that were necessary to mount the volume before the volume header was re- encrypted). Some journaling file systems also internally record file access times and other potentially sensitive information. If you need plausible deniability (see section Plausible Deniability), you must not store file-hosted VeraCrypt containers in journaling file systems. To prevent possible security issues related to journaling file systems, do one the following:\n\nAlso, in case I use FAT32, since it's Windows compatible, does it mean there any proprietary blobs on the bootloader or something?\n\nPossible options given:\n\nFilesystem:\n\n1. None\n2. FAT (I assume this is FAT32? It only says \"FAT\")\n3. Linux Ext2\n4. Linux Ext3\n5. Linux Ext4\n6. NTFS\n\nIs there any Linux only option where you are safe from any possible leaks and whatnot?\n\nDoes this leaks due journaling file systems problems only matter for containers or for FDE too?", "post URL info": [], "author": "cryptomann1", "ups": "15", "downs": "0", "number of comments": "27", "comments": ["The leakage comes from the file system you're using to store the container, not what the container is itself, so it doesn't matter which one you choose from that list of 6.", "The Linux versions of FAT32, NTFS, and ExFAT are their own clean room implementation, so no, there shouldn't be anything proprietary in there. Though be aware that NTFS and ExFAT don't get great performance on Linux &mdash; the drivers aren't very mature.\n\nJournaling-related leaks don't really happen with modern LUKS or VeraCrypt, you're better off just using ext4, f2fs, btrfs, or zfs as they have the best support.\n\nLeaking of data is more of a concern with the caching system that certain programs use, and with swap. For example, you may have your browser profile at `~/.mozilla/firefox` symlinked to an encrypted volume, but the entire `~/.cache` folder is unencrypted.  Or you could run out of RAM and accidentally let sensitive data get written to an unencrypted swap file or partition. You can avoid this by using full-disk encryption.", "Fat32 aint as proprietary as you would think these days, it certainly doesn't require external blobs anywhere unless you count the FAT on the disk image itself.\n\next2 is unjournaled and you can make unjournaled ext3... AKA ext2.\n\nIts more an issue for containers than FDE. with FDE all the journals everywhere are also encrypted so the point is moot. The issue arises in container formats that may store journal data on other(outer) volumes, or swap to it to disk when its unused for long enough. (the container stuff, journal and keys will be memory resident after all)\n\nI would probably use FAT. ext2 works perfectly fine but its old. I wouldn't be super surprised if some linux distros don't ship with it by default anymore. So FATs even a better bet for cross linux interoperability.", "Do the GUI setup on your typical distro encrypt everything including the swap partition?What about the boot one? For some reason I think Linux does not encrypt that one but FDE with Vera on Windows does. You enter the pass in pre-boot too compared to Linux (not sure if related)\n\nIm using ElementaryOS right now im not sure which ones are encrypted, last time I checked I think there was no swap partition.", "Well couldn't these proprietary bits on FAT contain surprises?  But according to poster above if you use Veracrypt in Linux to create the container it will not have? he said \"should\" tho\n\n&#x200B;\n\n>The Linux versions of FAT32, NTFS, and ExFAT are their own clean room implementation, so no, there shouldn't be anything proprietary in there", "Encrypting boot partition (and enabling UEFI secure boot) is intended to prevent a different kind of attack &mdash; an attack where a device is off, an attacker has physical access to the device to implant a keylogger into the bootloader, and the device ends up back in the hands of the owner without them being aware that their hardware was modified.\n\nIt usually is overkill. Maybe if you knew that a large government is after you.\n\nAs for swap, major distros automatic setup will either have swap encrypted or not have swap at all. It would be a mistake you would make with manual setup.", "Well, why FDE for Linux doesn't encrypt the boot partition then?"]}
{"id": "p8g67s", "title": "STARTTLS implementations in email clients & servers plagued by 40+ vulnerabilities", "url": "https://therecord.media/starttls-implementations-in-email-clients-servers-plagued-by-40-vulnerabilities/", "Created (UTC)": "2021-08-20 16:09:55", "body": "", "post URL info": [], "author": "Natanael_L", "ups": "36", "downs": "0", "number of comments": "33", "comments": ["[deleted]", ">Surprisingly, our analysis showed that some popular email clients use it (STARTTLS) as default despite having the option to use the implicit TLS ports without STARTTLS.\n\nI could not find a mention in the paper of which email clients these were. My impression is that STARTTLS has been almost entirely abandoned for client-sever connections in practice so the exceptions would of been interesting.", "Email is more holey than swiss cheese. There were 2 major exchange vulns this year and now its in the news that all the legacy implementation (POP3/IMAP/SMTP over STARTTLS) is not secure. \n\nRest at ease though STARTTLS hasn't been a standard option in many clients in years and if you use any normal service that you didn't set up your self you probably aren't using this.\n\nIf you are concerned about email security set up mail in a box in a public cloud like digital ocean and encrypt your messages with s/mime", "Surely this is already good advice (use TLS not STARTTLS).\n\nSTARTTLS is a hack to improve mail server-mail server Comms without breaking backwards compat. Not end user-mail server Comms.", "If you are concerned about email security, don't use email (use Signal for private comms). Alternatively, use Gmail and enable Advanced Protection (requires two U2F keys such as yubikeys). Google Advanced Protection requires disabling legacy protocols (pop3 etc).\n\nhttps://landing.google.com/advancedprotection/", "yeah that is why I specified email security specifically, totally agreed on not using email.\n\nI don't trust Google's platform personally which is why I'd go with using GPG to encrypt messages off line, use signal to transmit keys, and use your own self hosted smtp server (like mail-in-a-box). Agreed in advanced this is too complicated for most users, but not out of reach for a weekend project.", "> If you are concerned about email security, don't use email (use Signal for private comms).\n\nSignal have 3 problems, at least one of which will be a show stopper for many people:\n\n* Unless you compile it yourself, it\u2019s only available on the Android App store (and maybe the iPhone?). This is an explicit choice, I believe to avoid having unsuspecting users download modified version with spyware turned on. The problem is that it reduces availability.\n\n* Signal wants to know your phone number. It makes it very convenient, but some users don\u2019t want to reveal their phone number. I personally know one.\n\n* Signal is an instant messaging app. It\u2019s whole UI is directed towards short messages, comparable to SMS or tweets. Email is culturally slower paced, and email clients allow much longer, structured messages.\n\nIf those aren\u2019t show stoppers, sure, use Signal. I do. Just be aware that it\u2019s not a drop-in replacement for the kind of communication that usually happens over email.", "[deleted]", "> This post is neither trying to express or imply any kind of political messaging nor is it trying to influence or otherwise impact political discourse or opinions on others.\n\nIt nevertheless has political impact. As it should.\n\nMerely making an encrypted messaging app like Signal is a political act: some people are dedicated their time and their clout to say to the world that private communications should be a thing. That phone number business has pretty big implications on the practicality of private messages, and thus has a political impact: now Signal has to chose between easy contact discovery & key management and making phone numbers optional. Between securing technically illiterate US/Western users, and securing more people but risking more user-level screw ups.\n\nI'm not sure we currently have it all, so it's mostly about setting priorities \u2014that is, making a political choice."]}
{"id": "p8hq1j", "title": "Can KeepassXC leak data?", "url": "https://www.reddit.com/r/crypto/comments/p8hq1j/can_keepassxc_leak_data/", "Created (UTC)": "2021-08-20 17:47:48", "body": "There's an entire section on the pdf manual about Veracrypt about how the encrypted container may leak data when journaling filesystems are present, USB pendrives, etc. \n\nHow can one guarantee that no leakages happen? It's just not possible unless you use HDD?", "post URL info": [], "author": "cryptomann1", "ups": "12", "downs": "0", "number of comments": "39", "comments": ["Where exactly are you seeing this?  Link to PDF?  Online user manual doesn't seem to have anything on this.", "The veracrypt leak you're talking about *may* leak your keepassxc file (with some difficulty).  One of the other replies has explained it in a comment.\n\nBut keepassxc is not plain text -- so even if Veracrypt manages to leak it, it has its own encryption, protected by a stretched key.\n\n(Argon2, now, though if you have an older file you may have to fiddle with the UI to make it start using the stronger setting).", "What does this have anything to do with KeepassXC? \n\nIf the entire drive holds random (or encrypted) data, and any subsequent write to the drive is encrypted, there will be no leak.", "Quite possibly [You Don't Want XTS](https://sockpuppet.org/blog/2014/04/30/you-dont-want-xts/). XTS does leak data if an attacker can observe multiple versions of the ciphertext. That's a problem any practical full-disk encryption has. Which is why encrypting files with AEADs is generally a better choice. FDE is a \"last resort\" encryption, and container files using XTS like True/Veracrypt use are far worse than encrypting the entire disk. XTS is only safe if the attacker only gets a single chance to see the encrypted data (an \"evil maid\" attack), not if they can continually observe it (eg container file on cloud storage).\n\nKeepassXC uses the KBDX4 format which [uses HMAC-SHA-256 to authenticate the ciphertext](https://keepass.info/help/kb/kdbx_4.html). It's IND-CCA2 secure, and doesn't leak data (other than total size) about the contents.\n\nIf you want to encrypt arbitrary files, I'd generally recommend [age](https://age-encryption.org).", "Can you describe all possible scenarios a file inside a VC container may leak and how to avoid?\n\nI've used VC for ages, im too paranoid to use other software.", ">not if they can continually observe it (eg container file on cloud storage).\n\nHas a veracrypt volume with a strong 64 char password ever been compromised in practice? I mean im sure it's a common practice that people leave their containers online as backups. This made me extra paranoid so now im not sure what to sure. I've never heard of that age software. I would need that the software as a GUI so I don't screw up on the cli.\n\nIm really confused now. I thought veracrypt was a safe software to use. Why are they using this XTS format if it leaks data?", "gocryptfs and rclone with a `crypt` remote are safe too, in the sense that they're not using the XTS model, but actual AE(AD), with some overhead for each block/chunk.", "Almost certainly not all of them:\n\nIf an attacker sees a container multiple times, they know which blocks changed and which blocks stayed the same. That's a leak inherent to any FDE system, to prevent it you'd have to re-encrypt the whole disk for every change. For an attacker with repeated access to the disk or volume, it's no more secure than ECB mode. Patterns within the plaintext can leak.\n\nIt's malleable. If the attacker can write to the disk, they can overwrite blocks and the decryption won't fail (you might get junk, but you won't get an error). Done correctly (with some known plaintext, eg knowing what OS is installed) this can let an attacker corrupt and disable security features like the firewall or antivirus.\n\nVC containers only protect things if the container is unmounted, for full-disk encryption that's only when the computer is powered **off**, not sleeping or hibernating. You have to shut down the computer for it to do anything. Regular malware can extract data from the running computer without issue. Backups won't necessarily be encrypted (depends on the backup software).\n\nVeracrypt is good at what it's intended for: protecting against someone who gets access to a computer once (and only once) while that computer is off. The classic scenario is the \"evil maid\" where someone brings a laptop on a trip, and leaves it turned off in their hotel room. The evil hotel maid boots the laptop and steals all the secrets. With FDE, that's not possible.", "I can't know. I've never worked for a cloud provider or the sort of agency where I might have seen it done, and even if I had I'd likely be under NDA.\n\nBut the password length doesn't matter for this attack. It's fundamental to the use of XTS mode.", "Yes, anything using an AEAD should be safe in such a scenario.", "The idea is to have FDE, but also have important files encrypted inside an encrypted volume cointainer with a different password for an extra layer of security (and have them stored in an airgapped device).Btw please check this thread I made:\n\n[https://www.reddit.com/r/VeraCrypt/comments/p9ee35/does\\_using\\_windowscompatible\\_filesystems/](https://www.reddit.com/r/VeraCrypt/comments/p9ee35/does_using_windowscompatible_filesystems/)", "There are essentially 3 types of encryption we're talking about:\n\nFDE, encrypts an entire disk (or partition). \n\nContainer encryption, encrypts a file which contains other files (and an inner filesystem). \n\nFile encryption, encrypts a single file. \n\nVeracrypt is only good for the first two. The first two have the \"leak data if an attacker can observe changes over time\" problem. The latter doesn't (if it uses an AEAD, which is why I recommended `age` since it uses an AEAD and can't be made not to). Container encryption is more problematic than FDE, since it's common for changes to a file within a filesystem (ie a container) to leak in various ways than for changes to an entire partition to be observable.\n\nContainer encryption on top of FDE doesn't really add anything. File encryption on top of FDE does. Or file encryption alone.\n\nThe one big advantage of FDE is that it can hide some accidental leakage, such as temporary files an application might store. \n\nThe one case where I'd recommend a container instead of encrypting the whole partition is to have a portable copy of the Veracrypt (and possibly age) executable on the drive. But you can usually do this by just having two partitions, one encrypted and one not."]}
{"id": "p7vzdv", "title": "memfd_secret() Secret memory that the kernel can't access - usecase is cryptographic keys", "url": "https://lwn.net/Articles/865256/", "Created (UTC)": "2021-08-19 22:38:31", "body": "", "post URL info": [], "author": "Karyo_Ten", "ups": "49", "downs": "0", "number of comments": "38", "comments": ["Can someone explain how exactly the kernel is restricted from accessing it? \n\nFrom my naive understanding of how OS's work, restriction can only be through 2 ways  \n\n- privileges/permission - in which case, something running as superuser should be able to access it.   \n\n- encryption - in which case, where are the encryption keys stored?", "Only the kernel and the process that created it can access this memory. And the kernel can't access it via 'normal' means, it has to manually re-map those pages again first.\n\nIn terms of legitimate users: Root can't access it if the kernel is locked down to a point where arbitrary kernel modules can't be loaded. Being UID0 in userspace won't give you access. If you can load a kernel module then yes, this security is defeated.\n\nIn terms of active attackers: It moves the requirement from needing an address and a read-what-where primitive, to needed arbitrary code execution. Bugs allowing reading arbitrary kernel memory are much more common than bugs allowing ACE (e.g. meltdown/spectre/etc.).", "Per this comment, the protection is mostly against unwanted access via syscalls, not against kernel exploits;\n\nhttps://lwn.net/Articles/865654/", "It protects against some but not all bugs. I.e. if there is an app buffer overflow and exploit tries to utilize syscall like write to dump secret to some file (including stdout) it will not work. Or if there is a debug feature in app to duma some stuff, it will not work easily. There is more. Sure app can still copy things to different buffer, but it will need to be more intentional a bit. Also if there is kernel crash, kernel core dumper and debugger will not have access to it by default, which is also reasonably good idea l.\n\nIt is interesting feature, and will have some uses. Hard to say if it is good enough time justify the trouble.", "Cannot root just inject code in the process to get the process itself to export the secret where root can read it?", "Thank you.", "Ah, ok, got it. Thank you.", "[deleted]", "In theory you can additionally set up SELinux up prevent root from injecting code into a protected process.", "I realize that this requires jumping through some hoops, but for something that goes as far as saying \"we'll disable hibernation to avoid someone catching the secret from the kernel during the wake up process\" it sounds like a huge oversight. We're already trying to defend against sophisticated attacks."]}
{"id": "p7mems", "title": "Hash quine generated for Apple's content matching neuralhash algorithm [Twitter]", "url": "https://mobile.twitter.com/ghidraninja/status/1428269674912002048", "Created (UTC)": "2021-08-19 13:00:27", "body": "", "post URL info": [], "author": "Natanael_L", "ups": "41", "downs": "0", "number of comments": "37", "comments": ["Related:\n\nhttps://www.washingtonpost.com/opinions/2021/08/19/apple-csam-abuse-encryption-security-privacy-dangerous/\n\nhttps://act.eff.org/action/tell-apple-don-t-scan-our-phones\n\nhttps://www.reuters.com/technology/exclusive-policy-groups-ask-apple-drop-plans-inspect-imessages-scan-abuse-images-2021-08-19/\n\nhttps://arxiv.org/abs/2106.09820 - Adversarial Detection Avoidance Attacks: Evaluating the robustness of perceptual hashing-based client-side scanning\n\nCollision attacks are getting better fast: https://mobile.twitter.com/matthew_d_green/status/1428179884954853379\n\nDiscussion around creating collisions: https://github.com/AsuharietYgvar/AppleNeuralHash2ONNX/issues/1#issuecomment-901769661", "neat trick! Also I'm wondering why it's such a big deal if collisions are found? it's not meant for that as I understand\nedit: i'm not sure what they mean by two iterations to produce the self-referencing picture, anyone can give more details? It's impressive how clean the picture is considering the github shows very corrupted base image.", "It's a perceptual hash. Those are inherently vulnerable to collisions. I'm not sure why anyone is acting surprised.", "It's worse than collisions, it is that you can minimally tweak images to collide with a target hash.\n\nStep 1) Find NeuralHashes of CSAM\n\nStep 2) Take 100s of innocuous pictures and adversarially adjust them to match those CSAM hashes\n\nStep 3) Send to your iphone friend (from your android)\n\nStep 4) Enjoy your friend getting grabbed by the FBI!", "[deleted]", "[deleted]", "\n\n>It should be easy to find collisions with similar x, i.e. `h(x) = h(t(x))` where `t` is a perceptually \"small\" transform. This is is a feature!\n\nIt also is a critical vulnerability if collision resistance is a requirement. It means that the hash function is at least to some extent differentiable, which leaves it vulnerable to a whitebox attack using gradient descent. This is exactly how neural-hash-collider works, but this technique easily transfers to any other perceptual hash.", "This is on device scanning. Not iCloud. Which is new and a huge distinction!", "I've seen reports that What'sApp automatically uploads photos received to iCloud by default on Apple devices.", "The scanning only takes place on pictures that are about to be uploaded to iCloud", "The way it's designed means it can trivially be extended to on-device photos.\n\nAlso, if you have backups on them most saved images (those in the photo roll) will get scanned.", "They can trivially just scan each and every photo on your device whenever they want, since it\u2019s closed source software.\n\nI think there is an element of trust in play here"]}
{"id": "p7atax", "title": "What is the history of public key cryptography?", "url": "https://www.reddit.com/r/crypto/comments/p7atax/what_is_the_history_of_public_key_cryptography/", "Created (UTC)": "2021-08-19 01:29:45", "body": "Hey guys quick question here,\n\nI was doing some research on public key cryptography and i'm having trouble understanding the linear history of public key cryptography.\n\nso first there was this guy james h ellis\n\n[https://en.wikipedia.org/wiki/James\\_H.\\_Ellis](https://en.wikipedia.org/wiki/James_H._Ellis)\n\nand he was the first guy to really think up public key cryptography.\n\nthen Diffie\u2013Hellman key exchange\n\n[https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman\\_key\\_exchange](https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange)\n\nthen RSA (cryptosystem)\n\n[https://en.wikipedia.org/wiki/RSA\\_(cryptosystem)](https://en.wikipedia.org/wiki/RSA_(cryptosystem))\n\nthen PGP pretty good privacy\n\n[https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy](https://en.wikipedia.org/wiki/Pretty_Good_Privacy)\n\nthen openpgp\n\n[https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy#OpenPGP](https://en.wikipedia.org/wiki/Pretty_Good_Privacy#OpenPGP)\n\nthe gnu privacy guard?\n\n[https://en.wikipedia.org/wiki/GNU\\_Privacy\\_Guard](https://en.wikipedia.org/wiki/GNU_Privacy_Guard)\n\nis that everything? did i get everything in linear order?\n\nthank you", "post URL info": ["https://en.wikipedia.org/wiki/James\\_H.\\_Ellis](https://en.wikipedia.org/wiki/James_H._Ellis)", "https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman\\_key\\_exchange](https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange)", "https://en.wikipedia.org/wiki/RSA\\_(cryptosystem)](https://en.wikipedia.org/wiki/RSA_(cryptosystem))", "https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy](https://en.wikipedia.org/wiki/Pretty_Good_Privacy)", "https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy#OpenPGP](https://en.wikipedia.org/wiki/Pretty_Good_Privacy#OpenPGP)", "https://en.wikipedia.org/wiki/GNU\\_Privacy\\_Guard](https://en.wikipedia.org/wiki/GNU_Privacy_Guard)"], "author": "The_How_To_Linux", "ups": "21", "downs": "0", "number of comments": "40", "comments": ["I wouldn't include GPG, PGP, OpenPGP etc. \n\nI would add [Merkle's Puzzles](https://en.wikipedia.org/wiki/Merkle%27s_Puzzles)  & [ECC](https://en.wikipedia.org/wiki/Elliptic-curve_cryptography)", "[deleted]", "Some important details on the early history...\n\nJames Ellis's ideas were inspired by [Bell Labs Project C-43](https://techpinions.com/an-old-mystery-solved-project-c-43-and-public-key-encryption/18205), which was designed to allow one-directional encrypted telephone calls without setting up a preshared key in advance. The idea at the time was called \"non-secret encryption\".\n\nTwo of James Ellis's colleagues, Clifford Cocks and Malcolm Williamson, independently came up with the cryptosystems we call RSA and Diffie-Hellman in secret at GCHQ, years before their public (re)discovery.", "The root problem is secure key distribtution. I recommend Kahn's \u00bbCodebreakers\u00ab (a thick book) if you like to dive into history.", "Clifford Cocks gave a talk at Eurocrypt 2008. I don't think there is a video of it, but his slides are here: https://iacr.org/conferences/eurocrypt2008/sessions/CliffordCocks\\_20080417.pdf", "You're missing a lot of important *randomized* algorithms that modern crypto is based off of.  You should look into El-Gamal encryption, probabilistic encryption (Goldwasser-Micali), Paillier encryption.  Other commenters are right on for ECC, that's also an important area in public-key cryptography.\n\nFurthermore, public-key cryptography is much wider than just encryption: signatures, key exchange, oblivious transfer (and subsequent implications), homomorphic encryption, among other things.", "I would include several things:\n\n1. Elliptic Curve cryptosystems, invented independently by Neal Koblitz and Victor Miller in 1985 (published later, but they both won the Levchin prize).\n2. Merkle-Hellman knapsack cryptosystem. Broken quickly but looked attractive at first.\n3. Fiat-Shamir proof of knowledge and signature scheme. \n\nThere is a history of Ellis contributions https://web.archive.org/web/20060615061935/http://jya.com/ellisdoc.htm", "Came to answer this.\n\nAlso it might be worth mentioning quantum resistant attempts at pk crypto, such as with lattices and hash-based if I recall that lesson from a while ago", "[Merkle's part of the history is wild](https://www.merkle.com/1974/). He invented it as an undergrad project and it was rejected by the professor. He submitted to a journal and it was rejected again because it was not \"mainstream\" enough", "**[Merkle's Puzzles](https://en.wikipedia.org/wiki/Merkle's_Puzzles)** \n \n >In cryptography, Merkle's puzzles is an early construction for a public-key cryptosystem, a protocol devised by Ralph Merkle in 1974 and published in 1978. It allows two parties to agree on a shared secret by exchanging messages, even if they have no secrets in common beforehand.\n \n^([ )[^(F.A.Q)](https://www.reddit.com/r/WikiSummarizer/wiki/index#wiki_f.a.q)^( | )[^(Opt Out)](https://reddit.com/message/compose?to=WikiSummarizerBot&message=OptOut&subject=OptOut)^( | )[^(Opt Out Of Subreddit)](https://np.reddit.com/r/crypto/about/banned)^( | )[^(GitHub)](https://github.com/Sujal-7/WikiSummarizerBot)^( ] Downvote to remove | v1.5)", "interesting, ok, i guess for my purposes this is the way i'm getting it in my head\n\ni'm not a crypto researcher i'm just a guy trying to use public key cryptography, and i'm trying to see an extremely rough overview of PKC and how it started then how it developed and finally how it became GPG\n\nmaybe the better question is, how did PKC start as something that james ellis thought up to the gnu privacy gaurd? how did that transformation happen?", "Are signatures normally considered public key? On one hand, there is a oublic/private key separation, on the other hand they are in minicrypt, e.g. only require one-way functions (and maybe hashing) rather than trapdoor one-way functions.", "Public key is quite useless without authentication on public keys, so yes I think signatures are an essential part of public key. The RSA paper has \"digital signatures\" in the title.", "If you have a public verifier string and a secret signing string, you have a public key system. Even with Lamport signatures that's true."]}
{"id": "p6vuv0", "title": "Help with college advice", "url": "https://www.reddit.com/r/crypto/comments/p6vuv0/help_with_college_advice/", "Created (UTC)": "2021-08-18 10:26:01", "body": "I'm going to be a senior in high school this year and I love math and technology so obviously I've become interested in cryptography. Is there anything specific I should look for in a college? Any specific colleges that are good? Cryptography isn't a huge field so it's hard to find advice about it, so any help at all would be greatly appreciated. I live in Wisconsin if that helps so my #1 choice is UW Madison, but idk what other options I really have. Thanks everyone!", "post URL info": [], "author": "Noxta_", "ups": "19", "downs": "0", "number of comments": "46", "comments": ["For undergrad, any school would be fine. Look to other factors for picking a school. Doing at least one solid internship will matter a lot more that which school has the strongest cryptography subspecialty. If you decide to go to grad school for cryptography, again the school is not the most important factor. It's about picking a lab that's a good fit. \n\nSo maybe focus on a CS program that has a strong extern/intern system. Tell the admissions person about your interests and ask about what similar placements they've made. Don't take \"Google\" etc as an answer unless they can convince you that the extern got placed on a project/team that fit their narrow interest.", "**Go to the state school. UW Madison is absolutely fantastic.**\n\nThis was my path, and I love going out for drinks with my colleagues from Princeton, Duke, etc. who are still siphoning off funds to repay their gargantuan college loans, all the while trying to shame me for being a state school kid.\n\nI also personally know some of the CS faculty at UW Madison and they are terrific. Best in the country? No, but if you are serious about this field you will go to grad school anyway, and this is a perfect way to get on that trajectory.", "I've heard that Madison is good. A lot of the math that goes on in crypto is at the graduate level. I'd suggest looking to see if there's a school you like that has strong faculty in CS and math (particularly in number theory). Get a strong foundation in both (if you can't douuble major, then major in one subject and minor in the other). Try to see if you can do research as an undergrad!", "You can also take a look into online courses (for example I did part of a crypto course in Coursera and it was quite ok). From my point of view the professor matter more than the actual course.", "Not sure about colleges but here are two threads with good university authors and a selection of textbooks, both from r/cryptography\n\n**Help - I want to get into cryptography**   \n[https://www.reddit.com/r/cryptography/comments/ly0osr/Help\\_-\\_I\\_want\\_to\\_get\\_into\\_cryptography/gpr2d4s/?utm\\_medium=android\\_app&utm\\_source=share&context=3](https://www.reddit.com/r/cryptography/comments/ly0osr/Help_-_I_want_to_get_into_cryptography/gpr2d4s/?utm_medium=android_app&utm_source=share&context=3)\n\n**The joy of cryptography Free Undergraduate textbooks**   \n[https://www.reddit.com/r/cryptography/comments/ii6q2y/the\\_joy\\_of\\_cryptography\\_free\\_undergraduate/?utm\\_medium=android\\_app&utm\\_source=share](https://www.reddit.com/r/cryptography/comments/ii6q2y/the_joy_of_cryptography_free_undergraduate/?utm_medium=android_app&utm_source=share)", "[removed]", "That's really interesting. Thanks for sharing!", "Ah I see, I\u2019ll get in contact with the admissions people and ask about that, thanks!!!", "I agree.  Madison is a great school, and I believe Eric Bach still works there.  He will know the basics of crypto and advanced number theory.\n\nI actually did a masters at a neighbour school, UW Milwaukee, because they had a crypto group there.  But that was long ago, and if I were to make the decision today, Madison would definitely be a serious choice to consider.", "Tysm! Are graduate programs at Madison worth considering or is somewhere else better?", "Do you know if Madison's graduate program is good? I'm planning to double major in CS and Math for undergrad, I haven't looked into grad nearly as much yet so I'm still open to any advice relating to that :)", "I probably will look into those, ty!", "Tysm! I'll definitely give those a read once I'm no longer busy with college apps :)", "This subreddit is about cryptography, not cryptocurrency.", "Nice. I don't know how Madison is set up, but whatever school/college that has the computer sci/eng department will have a much better internship program then the math department.", "Yeah he does (he's still on the faculty page), I'll definitely make sure to get in contact with him if I get accepted :)", "I believe it is, I saw that their math program ranks highly in the U.S. Looks like a lot of areas in math are represented in their faculty, which is good. I considered applying there (I'm applying to grad school programs this fall) but I didn't see any advisors that really aligned with my interests.\n\nLet me know if you have any other questions!", "[removed]", "Oo ok cool, I'm actually planning to double major in math and computer science so I would most likely have access to both departments, I just don't really know if there's anything I should be doing outside of that to set me on the right path for an actual career since it's hard to find info about cryptography careers", "And it's posted in the wrong subreddit. Off topic here"]}
{"id": "p70ju9", "title": "Simple Image encrypt/decrypt", "url": "https://github.com/s3nh/img-cryptor", "Created (UTC)": "2021-08-18 14:21:35", "body": "", "post URL info": [], "author": "f00kew", "ups": "0", "downs": "0", "number of comments": "20", "comments": ["Using a static, configured IV is a bad idea. You'd be better off generating one per file, and prefixing the encrypted output file with it.\n\nAlso, why CFB and not GCM? https://github.com/s3nh/img-cryptor/blob/41fc7826065421eb72b159abbc7970cf5f903089/src/crypto.py#L42", "OCB3 gang report in, GCM is last year's news"]}
{"id": "p6az39", "title": "How does the PLONK zero-knowledge proof system work? Part 1: What's PLONK?", "url": "https://www.cryptologie.net/article/529/how-does-plonk-work-part-1-whats-plonk/", "Created (UTC)": "2021-08-17 12:48:24", "body": "", "post URL info": [], "author": "davidw_-", "ups": "30", "downs": "0", "number of comments": "23", "comments": []}
{"id": "p4s433", "title": "This blog shows how PDF encryption is implemented\u2026. Looks pretty scary to me!", "url": "https://medium.com/aia-sg-techblog/implementing-encryption-feature-in-pdf-lib-112091bce9af", "Created (UTC)": "2021-08-15 04:57:48", "body": "", "post URL info": [], "author": "ScottContini", "ups": "49", "downs": "0", "number of comments": "62", "comments": ["I have a rule - never rely on the security features of a product in which security is not the main feature. For example, if you want encryption, you should use a tool whose number 1 feature (and better yet, the only feature) is encryption, not a tool that has 100 features and one of them is encryption.\n\nOf course a dedicated security tool might suck too, but it avoids the failure mode of security features designed, implemented, documented, tested, maintained by people who primarily work on non-security features.", "I found this blog in /r/programming and was just amazed how I was seeing MD5 everywhere and rc4.  They do have AES-CBC but no secure way to turn a password into a key as far as I can see.", "When I see things like this, I fail to understand why they are so complicated.\n\nI would completely understand if something was just a massive fail because they took shortcuts and proper crypto cost a lot more time. I can't knock RC4 before this standard probably dates to that being more accepted.\n\nBut someone actually put a lot more effort into these weird custom KDF schemes than a na\u00efve \"SHA1\" or whatever might get you.", "Why they didn't just wrap it with an encrypted ZIP file!", "[deleted]", "One job - one tool. Good old Unix philosophy.", "I personally consider file compressors (e.g. 7zip) and crypto lockers (e.g. Petya) to be notable exceptions to the rule.", ">  Of course a dedicated security tool might suck too, but it avoids the failure mode of security features designed, implemented, documented, tested, maintained by people who primarily work on non-security features.\n\nEhh that depends on how \"mature\" the tool in question is, usually my rule is to not use things that don't take security into account.", "Yes, and even then: the way AES-CBC is implemented in PDF (even PDF 2.0) has some glaring malleability issues that make it trivial to inject arbitrary content without knowing the key. There\u2019s ongoing standardisation work to do something about that, but the status quo is anything but satisfactory\u2026\n\nThe lack of proper KDFs is another painful issue, as you point out.\n\nHonestly, if you don\u2019t need to interact with unknown PDF viewers directly, steering clear of the PDF standard\u2019s encryption features is probably for the best\u2026", "Looking back at thie history, AES was introduced into PDF format in 2004 (see https://en.wikipedia.org/wiki/History_of_PDF).  Back then good key derivation functions were pbkdf2 and bcrypt, but they didn\u2019t use them. Instead they did some crazy rc4-md5 combination, even though there was a push to get away from MD5 from years before then.  The worst part is that they never seemed to upgrade against this mess.", "not sure I understand this, are you saying there is nothing wrong in this implementation?", "It's complicated because backward compatibility is required.", "[removed]", "To learn. To challenge oneself.", "Quality of encryption options varies greatly between the various compression tools, 7zip is more of an exception than the rule.", "[removed]", "they are saying that given the time period that this was written in it may have been acceptable for the time. it does not mean that nothing is wrong by today's standards.", "This type of spam is illegal under EU and US law, you should delete these posts.", "I'm talking about the PDF specs.", "Permabanned due to triple rule violation (off topic, spam, and begging for votes)"]}
{"id": "p50zde", "title": "VeraCrypted SSD at android", "url": "https://www.reddit.com/r/crypto/comments/p50zde/veracrypted_ssd_at_android/", "Created (UTC)": "2021-08-15 13:22:10", "body": "Hello (Its my firsts post here),\n\nI got external SSD (SanDisk Extreme Portable SSD 1TB USB 3.2) which is all crypted by veracrypt.\n\nI need to open it at my android phone.\n\nI download EDS Lite. Plug SSD via USB to phone, run EDS and choose Manage Containers, then \"Add existing container\", change container format to veracrypt and thats the moment I stuck.\n\n&#x200B;\n\nI dont know how to select external device as a path.\n\n&#x200B;\n\nIs it even possible?\n\n&#x200B;\n\nThe only instruction I found are based on this: [https://www.how2shout.com/how-to/how-to-mount-encrypted-veracrypt-or-other-volumes-on-an-android-device.html](https://www.how2shout.com/how-to/how-to-mount-encrypted-veracrypt-or-other-volumes-on-an-android-device.html)", "post URL info": ["https://www.how2shout.com/how-to/how-to-mount-encrypted-veracrypt-or-other-volumes-on-an-android-device.html](https://www.how2shout.com/how-to/how-to-mount-encrypted-veracrypt-or-other-volumes-on-an-android-device.html)"], "author": "henryk_kwiatek", "ups": "2", "downs": "0", "number of comments": "36", "comments": ["Seems like a question for an Android sub, my android phone does not recognize USB storage devices connected to the USB connection.", "where are people picking up this word 'crypted'\n\nI've seen it many times and I can't figure out where it came from", "Most recent devices should support either using host mode via USB OTG adapters (USB micro B) or native USB host mode (USB C) to connect external storage.\n\nThen the next question is giving the app permission to access it. You may need to look for the path using a file explorer app.", "I connect it directly to USB-C.\n\nAnd drive isn't at any file explorer (I tried google file, builded huawei File App, and Amaze)\n\n&#x200B;\n\nThats why I asked here :)", "Does the drive need an external power source (powered USB hub)?\n\nYou might want to try a sub like /r/Android or similar to get the drive recognized by the phone", "Nope, it doesn't need any external power. Or second cable.\nI posted it also at r/android"]}
{"id": "p4537r", "title": "A writeup on the Quadratic Sieve algorithm", "url": "https://www.reddit.com/r/crypto/comments/p4537r/a_writeup_on_the_quadratic_sieve_algorithm/", "Created (UTC)": "2021-08-14 02:40:42", "body": "I am not from a Math background, so it took me a lot of time to understand the simplest version of the Quadratic Sieve algorithm. Each line in any text had at least 2 things I didn't understand and had to go searching for more info. So at the end, I decided to document the algorithm in detail with explanations.\n\nHere is a link - https://risencrypto.github.io/QuadraticSieve/ \n\nThere is also a link to a Google Spreadsheet inside which contains an example Sieving. \n\nI am sure there are mistakes - so please feel free to point it out - that's one of the main reasons I am posting it here. Same again if something is not clearly explained.", "post URL info": ["https://risencrypto.github.io/QuadraticSieve/"], "author": "HenryDaHorse", "ups": "42", "downs": "0", "number of comments": "40", "comments": ["I only had a cursory look, but it looks pretty good.\n\nA couple small points:\n\n- in theory, ECM is as fast as quadratic sieve.  In practice, QS wins if primes are same size.\n\n- I\u2019m pretty sure Kraitchik was doing combinations of congruences (I.e not just hoping for a perfect square on the rhs)\n\n- there are some o(1)s missing\n\n- what is special about Dixon\u2019s method is that if you choose values randomly, you can actually prove that it works.  Other algorithms are heuristic.\n\n- a subtle point is that Pomerance viewed his QS as a slight modification of Schroeppel\u2019s linear sieve.", "Read more about Kraitchik\u2019s method [here](https://link.springer.com/content/pdf/10.1007%2F3-540-39757-4_17.pdf)", "> I only had a cursory look, but it looks pretty good.\n\nThank you. Your 1997 Thesis on the Self-Initializing Quadratic Sieve is one of the papers I have downloaded in my search for material on the QS. Haven't read it yet, though (I do this as a hobby, not professionally - so only every now & then).  \n\n> I\u2019m pretty sure Kraitchik was doing combinations of congruences (I.e not just hoping for a perfect square on the rhs)\n\nOk, thank you. \n\nSo then it's not clear to me as to what is the improvement which Dixon did on Kraitchik's method. Pomerance's paper that you linked to in the other comment doesn't seem to mention Dixon at all. Is it the Gaussian elimination which Dixon used which is the difference?  \n\n> there are some o(1)s missing\n\no(1)'s missing where?\n\nThank you for the feedback. Much appreciated.", "Dixon\u2019s contribution was to modify it in such a way that you can prove it will work.  Quadratic sieve is not provable: it just should work, and has never failed, so we use it.  But in mathematics, they love proving things so the best provable method is Dixon\u2019s.  For Dixon\u2019s method, you have to choose your squares randomly.", "Thank you."]}
{"id": "p3nfmk", "title": "I built a Password Manager - Was told I would get a classy tear down here!", "url": "https://www.reddit.com/r/crypto/comments/p3nfmk/i_built_a_password_manager_was_told_i_would_get_a/", "Created (UTC)": "2021-08-13 08:37:49", "body": "Hey r/Crypto!\n\nI've recently built a Password Manager in Python for the terminal. It's my first public [repo on GitHub](https://github.com/MarkMcKinney/DIY-Password-Manager) and I built it to improve my understanding of data security and encryption. I was told that I would get even further feedback here - so feel free to break it!\n\nWhen I posted originally in r/Python, I was asked:\n\n1. Why are you using PBKDF2 instead of a memory intensive one like scrypt or Argon2?\n\nWhen researching this project, it looked like several password managers use PBKDF2 (like 1Password), so I decided to follow suit. From my understanding, 1Password also combines the master password with a [secret key](https://support.1password.com/secret-key-security). I believe that is the salt in my project, but correct me if I'm wrong! Someone did [mention incorporating a certificate](https://www.reddit.com/r/Python/comments/p22p35/i_made_a_password_manager_for_the_terminal_let_me/h8i5nf1?utm_source=share&utm_medium=web2x&context=3) file on top of the master password for authentication. This would prevent key logger efforts. I don't know a lot about scrypt or Argon2, so I'd love to hear more from you guys about the advantages of switching to those methods.\n\n2. Threat model, Python is meh if we can trace what the VM executes.\n\nI never considered that. Could you guys also expand on this as well?\n\nCheck out the DIY Password Manager on GitHub: [https://github.com/MarkMcKinney/DIY-Password-Manager](https://github.com/MarkMcKinney/DIY-Password-Manager)\n\nhttps://preview.redd.it/585jmciha5h71.png?width=2208&format=png&auto=webp&v=enabled&s=8df46b13a0a1c13c288d3ed47c890c3945fffec5", "post URL info": ["https://github.com/MarkMcKinney/DIY-Password-Manager)", "https://support.1password.com/secret-key-security).", "https://www.reddit.com/r/Python/comments/p22p35/i_made_a_password_manager_for_the_terminal_let_me/h8i5nf1?utm_source=share&utm_medium=web2x&context=3)", "https://github.com/MarkMcKinney/DIY-Password-Manager](https://github.com/MarkMcKinney/DIY-Password-Manager)", "https://preview.redd.it/585jmciha5h71.png?width=2208&format=png&auto=webp&v=enabled&s=8df46b13a0a1c13c288d3ed47c890c3945fffec5"], "author": "M2com", "ups": "39", "downs": "0", "number of comments": "63", "comments": ["Everyone using the same salt defeats the purpose of using a salt in the first place. Attackers must build a unique rainbow table per salt, so if there's only one salt value then one rainbow table works with everyone. Instead generate a unique salt per database (`secrets.randbytes()`) and store it as plaintext alongside the database.\n\nPBKDF2 isn't awful, but there's no reason not to do better with Argon2 (my preference) or scrypt.\n\nFernet is a reasonable, safe choice. The API is kind of weird (key must be base64-encoded?) and AES-CBC is a bit dated, but it's hard to misuse.\n\n>> 1. Threat model, Python is meh if we can trace what the VM executes.\n>\n> I never considered that. Could you guys also expand on this as well?\n\nThis makes no sense. You can also trace a native program with a debugger.\n\n> Someone did mention incorporating a certificate file on top of the master password for authentication.\n\nFernet already authenticates for you. No need for this.", "> Python is meh if we can trace what the VM executes\n\nSave for some sort of secure enclave (e.g: SGX), even native code could be traced.\nIf you have malware locally, you're pretty much screwed.\n\nIf some account is that important, hardware backed 2FA is a must anw. Something like Yubikey.", "Please consider a command line interface (CLI), providing a bit more discretion. Displaying a password should provide an option to wipe it from the screen and maybe memory by pressing any key while displaying it. Your password manager could display only one of the three (site, username, password) so an observer can't glimpse too much information with one peek or by taking a photo.\n\nOther password managers copy the password into a clipboard or paste buffer, and allow pasting it into a password prompt, not showing it at all. Such buffers are accessible to other applications (race condition), still it is worth a try if you run on a tty that the user owns exclusively.\n\nWithout proper integration (like e.g. the Firefox password manager) a standalone password manager causes a lot of headache while handling the password.", "So your salt is probably a pepper. Pepper is per database, salt is per password.\n\nA certificate file or yubikey for 2FA as mentioned by others might be helpful.\n\nSomething I like from KeePass is automatically cleaning clipboard after 30 seconds from copy.\n\nOverall I'd suggest working on making the workflow \"search -> copy password\" take as few steps as possible. That's where people spend the time. Fuzzy search helps too.", "Don't have the time for full feedback right now, but I've been thinking about making exactly such a project for the same reason! I'll definitely star and/or fork it and have a look at it.", "Haven't looked at your code yet but I suggest you check out https://www.vaultproject.io/ they have  some good papers too. Its more of a KMS but they have great workflow i think you would benefit from.", ">Fernet already authenticates for you. No need for this.\n\nPretty sure the other post was talking about *user* authentication to the app, not data authentication.\n\n(I don't know *why* they were talking about user authentication if it's a local app, much less where the password is needed for decryption and doesn't seem like something that could be replaced with a cert.)", "Thanks for your comment!\n\nYou bring up a good point about using different salts per database. I believe my DB setup file (god_key_hasher.py) does this with:\n\nos.urandom(random.randint(16,256))\n\nHowever, I think I need to change the random to secrets.\n\nI\u2019ll take a look at Argon. Is there any particular reason it\u2019s better? Sorry, I\u2019m pretty new to the various crypto algos.", "Yeah, its best to never display it. First python library i found that can put data into clipboard  http://coffeeghost.net/2010/10/09/pyperclip-a-cross-platform-clipboard-module-for-python/", "Just added that clipboard function instead of showing the password! I was using tkinter, but it kept crashing whatever I pasted in. Pyperclip is so so so much better.", "Great feedback, thanks! Another redditor mentioned KeePass, I\u2019ll be adding that 30 sec timer to clean the clipboard.\n\nThanks for the clarification on salts and peppers. So the ideal fix is to salt each password, then pepper the entire database. And this pepper is different than the certificate file?", "Thanks! I appreciate it. I\u2019m looking forward to seeing what you new additions you make!", "Will check it out, thanks for the link!", "Long answer: https://www.password-hashing.net/argon2-specs.pdf  \nShorter answer: https://en.wikipedia.org/wiki/Argon2  \nShort answer: Memory-hardness. It makes certain kinds of attacks, like GPU cracking, prohibitively expensive due to mandatory memory requirements to run the algorithm.", "The key solution here would be to use one salt per *entry*, not per database. This means an attacker would need to create rainbowtables (pre-calculated hashes off a wordlist with the salt in question) for every single password. Otherwise you could potentially find the salt of all passwords by just calculating one lucky match with a weak password and its salt.", "[removed]", "Virtual keyboard may be an even better solution (harder to spy on than the clipboard)", "Something that helped me was viewing everything as keys. If you need a piece of data to decrypt something it's a key. Kind of.\n\nRegarding pepper you don't strictly need it, if you use proper schemes encryption for your storage. A pepper will make it more secure, but if someone loose their yubikey or certificate file they loose access to their passwords. There are reset schemes, but then you *really* need to know what you're doing to not open up holes.\n\nYour certificate file can be a pepper. Ideally you want 1) something the user knows, i.e. their password and 2) something they have, i.e. a yubikey or a file. Two factors.", "[deleted]", "AH! Of course! Thank you for that clarification. I see the issue now. So I would assume that I would replicate my process now of generating hashes, but create one for each entry and store those salts?\n\nIs there a better way to store the salts? Right now they\u2019re stored in a text file. From an attacker that doesn\u2019t have access to the computer, it\u2019d be useless to just have the master password without the salt. But for an attacker that could have access, is there a way to circumvent that?", "Begone spammers", "Ooo, is this a thing? Any Python packages you recommend?", "Hmmm okay, I\u2019ll be taking a look into this.", "Thanks for the links, I think I\u2019ve got a bit better understanding of how all this works. Will be trying to use  Argon2id. Thanks!", "Not an expert per-se, but generally salts are stored in the clear along side the password hashes, and no extra effort is made to obscure them. Their purpose is to screw up rainbow tables and such, not necessarily to serve as a second key of sorts.", "Minimum good settings for encryption (<1 kH/s/GPU):\n\n    Argon2{id,d}:   m\u2265363 MiB, t=1, 1\u2264p\u2264CPU cores\n    Argon2{id,d}:   m\u2265145 MiB, t=2, 1\u2264p\u2264CPU cores\n    Argon2{id,d,i}: m\u2265 91 MiB, t=3, 1\u2264p\u2264CPU cores\n    Argon2{id,d,i}: m\u2265 66 MiB, t=4, 1\u2264p\u2264CPU cores\n    Argon2{id,d,i}: m\u2265 52 MiB, t=5, 1\u2264p\u2264CPU cores\n    Argon2{id,d,i}: m\u2265 43 MiB, t=6, 1\u2264p\u2264CPU cores\n\nThese memory settings might be higher than necessary due to the GPU being limited by memory. This likely starts around p\\*128 MiB. These are for theoretical max GPU (RTX 3080) speeds.\n\nIn general minimum m is found from this formula:\n\n    m = ceiling(742187.5 / (3 * t - 1) / (4 * p)) * 4 * p\n\nWhere 742,187.5 is 760,000,000,000/1,000/1024 which is from RTX 3080's memory bandwidth (760 GB/s) divided by max cracking speed (1 kH/s) in KiB. Also \"GPU\" is basically a GPU with an MSRP of ~US$700 in 2015 money (ie US$700 with inflation since 2015). It's really the fastest GPU where the performance/cost is still high.", "Ok good to know! Thanks."]}
{"id": "p31cd7", "title": "Is The McEliece Cryptosystem Secure?", "url": "https://www.reddit.com/r/crypto/comments/p31cd7/is_the_mceliece_cryptosystem_secure/", "Created (UTC)": "2021-08-12 07:48:02", "body": "Hello, i wanted to ask as a guy who doesn't know anything about crypto, i was told that The McEliece Cryptosystem is very secure and even more secure then traditional RSA encryption, i wanted to ask what you guys thought about this, is this true?\n\nthank you.", "post URL info": [], "author": "how-to-ubuntu", "ups": "20", "downs": "0", "number of comments": "53", "comments": ["Classic McEliece is a finalist in the NIST Post-Quantum standardization process and McEliece has been around for quite awhile now and has held up pretty well, so (without knowing a lot of the specifics about it) I'd say it's secure. As far being more secure than RSA, it's thought to be secure against quantum enabled adversaries, which RSA is not.", "As almost everything in cryptography, **it depends**.\n\nWhen we say that X is more secure than Y, we have to state under what model we are comparing them.", "Yes, fair enough, the problem is the key size", "[removed]", "Aside from that, Bob McEliece was a nice guy. He died in 2019.", "It's almost as old as RSA, and it has fast encryption and decryption, and small messages.  The downside of McEliece is that the public key is enormous and key generation is very slow.", "Agree!", "You haven't even existed for an hour and you're already a detriment.", "\"Almost as old as RSA\" is an interesting statement. RSA published it in 1978, but even CACM back then took some time. McEliece published in 1978 as well and was reporting work supported by NASA (it is in a JPL technical report). About five years earlier, on 20 November 1973, Clifford Cocks, working for GCHQ (the British equivalent of the NSA), invented a very similar algorithm. His classified memorandum \"A note on non-secret encryption\" remained secret for 24 years. In fact, when you read the Cocks memorandum, you will see that the idea of public-key encryption was proposed by J. H. Ellis three years earlier in 1970.\n\nIn the \"open world,\" Ralph Merkel and Martin Hellman get credit for the idea of public-key cryptography, and it is well-deserved. But in the spooky world of NSA and GCHQ, Ellis proposed it, and Cocks provided a practical algorithm.", "Not sure if large public keys and slow key generation are real issues with all applications or today's powerful computers and cheap storage. For a long lived key it sounds feasible. For short lived keys, maybe it's too slow, but it might not be either.", "A whole bunch of dormant pre-subscribed bots are being activated now for spamming. I wish reddit had genuine useful anti-spam tools, like being able to preemptively identify and ban such accounts from the sub.", "Interesting, I\u2019d forgotten that Cocks came up with RSA before RSA did.  (Your comment makes it sound like Cocks discovered McEliece \u2014 did he do that too?)  I just meant that RSA was published a year earlier, in Scientific American\u2019s Mathematical Games column in 1977.", "Depending on security level, Classic McEliece (which by the way is based on Niederreiter\u2019s improvement with smaller keys) has 251kB - 1.35 MB key that take 10-100ms to generate on a server core.  You can use this to encrypt email to your coworkers, but it\u2019d be painful for eg TLS, especially on a phone or IoT device.\n\nDJB tried to claim on the mailing lists that this was no big deal: you\u2019d just engineer a system to cache the public keys of the top 1000 websites and update them every night using WiFi or something.  And yeah, if everything but McEliece were broken we\u2019d work something out, but it wouldn\u2019t be cheap.", "No, I\u2019m sorry if it sounded like Cocks discovered McEliece. Cocks is a very nice fellow, BTW. I had the pleasure of meeting him about 10 years ago."]}
{"id": "p2u00t", "title": "You're Doing IoT RNG | numerous IoT devices have weak randomness due to improper use of HWRNG:s", "url": "https://labs.bishopfox.com/tech-blog/youre-doing-iot-rng", "Created (UTC)": "2021-08-11 23:09:05", "body": "", "post URL info": [], "author": "Natanael_L", "ups": "58", "downs": "0", "number of comments": "62", "comments": ["Somehow, I am not surprised.  Great article, thanks.", "Interesting stuff", "Every random number generator (RNG) needs to acquire entropy from various sources and is eventually bound to fail when the demand is high. Broken, predictable or biased hardware RNGs are not a new problem either. And before this long story gets longer and even more complex I recommend to take a look at [haveged](https://www.issihosts.com/haveged/) ([paper, pdf](http://www.irisa.fr/caps/projects/hipsor/publications/havege-tomacs.pdf)). I find the article somewhat misleading: There is no magic in an xor function neither is it necessary to kill a process or wait forever until entropy arrives. The solution is simply to wait for randomness until the timeout expires. If there isn't enough of it, there is either the option to wait longer or fail gracefully.\n\nIIRC [OpenBSD](https://man.openbsd.org/arc4random.3) addressed this issue a long time ago.\n\nTLDR; You don't roll your own crypto and you don't roll your own RNG, PRNG or CSRNG.", "Decided to watch the Defcon talk, and uhh\n\n>  The way that the CSPRNG subsystem works is you start with a number of entropy sources. So these can include the hardware random number generator, but also lots of other things that an operating system might have access to such as interrupt timing from various devices, networking receive times, like tiny nanosecond receive times has a quite a bit of entropy to the network. You XOR them all together into this big entropy pool. So it's important to know about this, is all of them are XOR together so that it's not sufficient to break just a single one of these entropy sources in order to predict the output of the random number generator, an attacker would need to simultaneously predict all of them. So that's very strong. Additionally, what you can do is then read from the entropy pool by a cryptographically secure random number generator. These are typically just a hashing function, like a Linux kernel, just MD5 the entropy pool. And then in order to produce more numbers afterward, MD5 the last output with the entry pool itself, so you can kind of chain basically key stretching your way out to produce the functionally infinite amount of entropy from a static amount.\n\nsomeone please tell me this was some sort of joke >.>\n\n---\n\nAlso, I just entered a 2 year programme to learn IOT development, so I figure I'll ask: libhydrogen would be a pretty good choice for this problem, right?", "[removed]", "[deleted]", "[removed]", "One of the many troubles with taking the strategy of spin-looping on the HWRNG HAL call is that a lack of entropy is not the only cause for error. If you spin-loop on the call and some other kind of error crops up, your device will block forever. (Some device SDKs even specifically warn about this)\n\nClearly the correct solution is as we recommended in the article: for an upper layer (like an IoT operating system) to implement a CSPRNG subsystem. Just like is done in every major thick OS (Linux/Windows/MacoS/etc...) That way nobody needs to write their own RNG code and can safely get secure randomness without blocking and other nonsense.\n\nAlso, I hope from context that it was clear that XOR isn't ACTUALLY magic. :) That was shorthand for \"entropy pooling is complicated and not important to explain right now\".", "In practice the mixing and extraction functions are more modern than MD5, but in general it works like this.", "This assumes you have correctly fed the CSPRNG pool with entropy. That's more than just a language problem.", "This is a rule violation, further violations of the rules may result in a ban", "In some types of IoT devices, the HWRNG is the only source of (sufficiently high entropy) randomness. If it's not implemented correctly then the other sources available by the CSPRNG can't save you because they're all predictable. So basically, if your HWRNG give your errors then blocking behavior may even be preferable.", "I found the approach (in your article) to RNGs on IoT devices via public key crypto, using Alice and Bob a bit winded, thats all. On the other hand, you can't point out these issues often enough, so well done. To me it feels like we are repeating the same mistakes again, running circular arguments. What I tried to say was something like \u00bbHardware constraints aren't a good enough excuse anymore. Take a look how other vendors approach the problem and benefit from it.\u00ab", "Yeah, it was the mention of MD5 that got me, and the method of mixing. Seemed oddly out of place in a discussion of how things should work.", "[deleted]", "Correct, that's why it would be the job of the CSPRNG subsystem to manage that. You can reasonably wait for entropy one time upon initialization (enough to seed the PRNG) and then just grab more entropy opportunistically going-forward as it's available.", "I misspoke, sorry. Should have said SHA-1. (https://github.com/torvalds/linux/blob/a4a78bc8ead44c3cdb470c6e1f37afcabdddfc14/drivers/char/random.c)", "The whole article is about completely trusting a naive HWRNG integration is a terrible idea and why you should maintain an entropy pool. Hardware RNG:s often have outputs which needs a lot of quality checks and post-processing. This is easy to screw up hard, while it's much easier if you find simply feed it all to a CSPRNG's mixer. In fact a ton of devices have these exact problems.\n\nThe article covers things like complicated API:s for hardware RNG:s and the possibility of silent failure, etc. Repeats, low quality outputs, and more. The whole point of a CSPRNG is that you only need ~128 bits of entropy in the pool and from then on you're secure regardless of what happens to the HWRNG after that.\n\nThis is so much more than languages problems. Especially so when half the problem lies in the documentation from the HWRNG vendor."]}
{"id": "p2ei4j", "title": "The Lasercom subreddit is currently having week dedicated to Quantum Communication", "url": "https://www.reddit.com/r/crypto/comments/p2ei4j/the_lasercom_subreddit_is_currently_having_week/", "Created (UTC)": "2021-08-11 07:46:11", "body": "This week over at /r/Lasercom will be entirely dedicated to quantum communication.\n\nLasercom is a subset of *Optical Wireless Communication* (OWC) and is particularly conducive to secure communication techniques (difficult to detect and intercept) and quantum cryptographic techniques (such as QKD networks).\n\nThe earliest forms of OWC included semaphore (flag waving) and smoke signals and such techniques were used by the ancient Greeks and Romans. Alexander Graham Bell invented the Heliophone (using sunlight to transmit a phone call without any wires). It also includes LiFi which has barely taken off yet (connecting your devices to a public network just using lightbulbs and a photodetector on your device)\n\nMore specifically it uses a near-infrared laser and so in that case is called either Free Space Optical (*FSO*) communication, or simply laser communication (*lasercom*).\n\nTo all the physicists, engineers and anyone who uses the internet really, I think there's a lot of reasons to get excited about space lasers, such as everyone in the world having access to super cheap high speed broadband, even when living in a forest. Even when travelling in a plane. And the benefits of faster, cheaper and lower latency and more secure backhaul will affect a wide range of industries.\n\n**Interplanetary internet** is just beginning, not just \"in our lifetimes\" but people are building it right now. Arguably the first major milestone signalling the start of the Interplanetary Internet will be connecting the moon (and its astronauts, landers and structures) to the internet [[1]](https://esc.gsfc.nasa.gov/news/_LunaNetConcept) [[2]](https://esc.gsfc.nasa.gov/news/_LunaNetConcept). People have written about it for decades. Expect that *within 3 years* (if they can solve the problems with the supply of space suits). \n\n**Deep space laser communications** will be delivering us data back from a distant asteriod *next year* [[3]](https://www.nasa.gov/mission_pages/tdm/dsoc/index.html). \n\nMilitary aircraft will be all connected by secure space lasers, starting with the MQ-9 Reaper and cubesats *which were deployed last month* [[4]](https://www.ga.com/general-atomics-lincs-system-launched-successfully-and-deployed) [[5]](https://www.defenseone.com/technology/2021/06/pentagon-will-try-using-lasers-send-data-space-drones/174810/). Passenger planes will soon be connected by lasers starting with Airbus, announced this year [[6]](https://www.airbus.com/newsroom/press-releases/en/2021/04/airbus-and-tno-to-develop-aircraft-laser-communication-terminal.html). \n\n**Quantum key distribution** using space lasers is already deployed creating a secure network across 4,600 km of China, including Shanghai and Beijing. We found out about it in *January this year* [[7]](https://www.nature.com/articles/s41586-020-03093-8).\n\nFor more info:\n\n- https://en.m.wikipedia.org/wiki/Free-space_optical_communication\n\n- https://en.m.wikipedia.org/wiki/Laser_communication_in_space\n\n- [\"Quantum\" posts on /r/Lasercom](https://www.reddit.com/r/lasercom/search?q=quantum&restrict_sr=on&include_over_18=on)\n\n- [\"News\" on /r/lasercom](https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Anews&restrict_sr=on&include_over_18=on&sort=relevance&t=all)\n\n- [\"Articles\" on /r/lasercom](https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Aarticle&restrict_sr=on&include_over_18=on&sort=relevance&t=all)\n\n- [\"Videos\" on /r/lasercom](https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Avideo&restrict_sr=on&include_over_18=on&sort=relevance&t=all)\n\n- [\"Research Papers\" on /r/lasercom](https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Aresearch&restrict_sr=on&include_over_18=on&sort=relevance&t=all)", "post URL info": ["https://esc.gsfc.nasa.gov/news/_LunaNetConcept)", "https://esc.gsfc.nasa.gov/news/_LunaNetConcept).", "https://www.nasa.gov/mission_pages/tdm/dsoc/index.html).", "https://www.ga.com/general-atomics-lincs-system-launched-successfully-and-deployed)", "https://www.defenseone.com/technology/2021/06/pentagon-will-try-using-lasers-send-data-space-drones/174810/).", "https://www.airbus.com/newsroom/press-releases/en/2021/04/airbus-and-tno-to-develop-aircraft-laser-communication-terminal.html).", "https://www.nature.com/articles/s41586-020-03093-8).", "https://en.m.wikipedia.org/wiki/Free-space_optical_communication", "https://en.m.wikipedia.org/wiki/Laser_communication_in_space", "https://www.reddit.com/r/lasercom/search?q=quantum&restrict_sr=on&include_over_18=on)", "https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Anews&restrict_sr=on&include_over_18=on&sort=relevance&t=all)", "https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Aarticle&restrict_sr=on&include_over_18=on&sort=relevance&t=all)", "https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Avideo&restrict_sr=on&include_over_18=on&sort=relevance&t=all)", "https://www.reddit.com/r/lasercom/search?q=quantum+flair%3Aresearch&restrict_sr=on&include_over_18=on&sort=relevance&t=all)"], "author": "Aerothermal", "ups": "24", "downs": "0", "number of comments": "51", "comments": ["Again, like last time, and as always \"Quantum key distribution\" is just a contrived, expensive, and not particularly practical solution to problems that have already been solved with cryptography.\n\nIt doesn't even provide any advantages against a quantum computing opponent, because it doesn't solve the basic problem of verifying that you are communicating with the correct person. So a generalised \"Quantum key distribution\" internet will still have to rely on old school asymmetric crypto.", "[removed]", "Quantum cryptography in particular is getting lots of funding and international consortiums. EuroQCI for example involves Airbus Defence & Space, The National Research Concil of Italy (Consiglio Nazionale delle Ricerche), The EU Commission, the Istituto Nazionale di Ricerca Metrologica, Leonardo, Orange Group, PwC France, and Telespazio. \n\nThere's also LuxQCI, an SES-driven consortium involving organisations InCert, itrust consulting, LuxConnect, LuxTrust and SnT.\n\nIf we look at US and China, the latter already implements a satellite-fed QKD network spanning 4,600 km serving both Beijing and Shanghai, and the US is developing a satellite megaconstellation DARPA Blackjack, and continues to invest millions in QKD startups via their SBIR/STTR grant process. The Army, The Navy, and the Air Force are all developing secure lasercom systems and hopes to link all the intelligence in a strategy they call Joint All-Domain Command and Control (JADC2).\n\nWhy are all these countries and companies spending so much money and effort on developing this infrastructure to include QKD?", "This type of spam is illegal under US and EU law, FYI. You should delete these comments", "> Why are all these countries and companies spending so much money and effort on developing this infrastructure to include QKD?\n\nIt has the word \"Quantum\" in it, and the point of research is to explore far-fetched ideas to see if there is any bearing to reality.  Also for the results we learn along the way.  Laser is important, no doubt, but QKD is a different beast.  It still needs millions of dollars poured into it before people are fed up with funding a dead end, or has a chance to become a realistic competitor to \"use lasers to communicate bits and classical off-the-shelf key exchange\".\n\nAlong these lines, there are interesting pieces of research in Quantum MPC (both in the quantum and classical *computing* model, in addition to quantum channels), where you have better justification because there you have different bounds when compared to classical MPC.", "Because most people, including politicians, and even a lot of STEM educated people, don't understand cryptography and the cryptographic problem space.\n\nIt sounds fancy, and most of the snake oil salesmen probably do believe that they actually have a valuable product, helps them delivering a convincing sales pitch.\n\nCan you answer me what problem beyond the capabilities of cryptography it solves?", "It is one solution to the key exchange problem. But you already knew that.\n\n>Beyond the cababilities of cryptography\n\nYou should see it as a method within the field of crytography, rather than a different field or a threat to your livelihood. \n\nOne thing it offers? It offers a new way to identify man-in-the-middle attacks.\n\nYou're right to spot one thing that could be overlooked: it doesn't do away with the need for an initial authenticated channel. But when combined with free space optics, there is not yet a technologically viable way to intercept that initial communication (the so-called pointing and acquisition) between vehicles or satellites and ground stations.", "It doesn't solve the key exchange problem - in order to use it to perform a key exchange you must first have performed a key exchange, because with no shared secret you can not authenticate the user on the other end.\n\nWith solid cryptography you don't need to detect a man in the middle.", "A: QKD!\n\nB: What is the use of QKD?\n\nA: It prevents eavesdropping on the key exchange!\n\nB: But you need to pre-share keys to use it, in which case you don't need to worry about eavesdropping?\n\nA: ...\n\nA: QKD!"]}
{"id": "p23dzw", "title": "Getting others to accept encrypted e-mails", "url": "https://www.reddit.com/r/crypto/comments/p23dzw/getting_others_to_accept_encrypted_emails/", "Created (UTC)": "2021-08-10 18:52:28", "body": "I would like to use E2EE as much as possible. For e-mail, this is proving difficult. Using PGP is obviously too complicated for general users. I have opted for a service like mailbox.org or posteo or protonmail. However, when people receive the encrypted e-mail saying they must click on the link and enter a password, I get one of 2 responses. They are either suspicious and delete it or they are too lazy and don't want to click on it. Does anyone have any (useful) advice on how to get my friends (and any general user) to utilize E2EE email?", "post URL info": [], "author": "GuTsINzRLymOw60OFPXx", "ups": "22", "downs": "0", "number of comments": "84", "comments": ["Getting people to start clicking on links in emails and entering passwords is not really something we want to encourage, so that's good to hear.\n\nHow are people even getting this password from you?  Sorry, not sure how those services work, actually curious about this", "The core problem is E2EE is an afterthought in email UX, and that problem is fundamentally unfixable.\n\nSolutions are awkward and bolt-on, rather than implemented as core \u201calways on\u201d changes to the underlying protocol, and often provide nebulous security properties.\n\nPeople have been banging on that drum for decades, expending tons of effort trying to augment a federated protocol with a litany of incompatible add-ons, attempting to make anything stick.\n\nSo far, nothing has. This has lead many people in the cryptography, infosec, and security usability communities to become rather fatalistic about the problem, given the amount of effort expended on it and discussion around it leading to a consistent track record of poorly-embraced failures.", "Email is fundamentally insecure. Doing E2EE email just isn't practical. Use Signal.", "From the crypto perspective, yer trying to get the reader to buy into\nboth encryption and signatures.  That is best (only?) done in a closed, controlled environment (eg DoD and it\u2019s CAC smartcards)\n\nYou can easily, strongly encrypt a known file type ( eg  .docx) and share out-of-band the password (eg speak on the phone). If the right password decrypts the file they pretty well know it\u2019s you.  It\u2019s not crypto-strong but it\u2019s a step fwd", "If you want people to do things you have to take the time to show them how to do those things. They have to understand *why* they are doing those things.\n\nThis is an old problem. See Why Johnny Can't Encrypt[1] for a fairly good discussion from 20 years ago.\n\nThe fundamental problem is not specific to email or OpenPGP/SMIME. People create new technology from time to time, declare success and then find that no one can or will use that new technology. ProtonMail is but a recent example.\n\nBTW, Signal also fails here[2]. It has some interesting usability ideas but in the end does not manage to create a usable conceptual model that it can impart to the user.\n\n[1] https://www.usenix.org/legacy/publications/library/proceedings/sec99/full_papers/whitten/whitten_html/index.html\n\n[2] https://eprints.cs.univie.ac.at/4799/ referenced from https://sequoia-pgp.org/blog/2021/06/28/202106-hey-signal-great-encryption-needs-great-authentication/", "If you're relying on a web service to decrypt the email, it's not E2EE", "But why though? You say you want to use E2EE as much as possible, but for what purpose?  \n\nThe reason no one is buying in is likely because they deem it a waste of time.", "OpenPGP / GPG4Win is OK if you're using full-blown desktop Outlook.  The Kleopatra client is a bit fiddly but useable.  Is this viable for your circumstances?", "Rather than waiting for someone to figure out how to bring E2EE to the masses, you are probably better off with a trusted 3rd party where you are the party. Self host a web forum. Self host a document management system. That is only as secure as TLS and the hosting environment but is better than nothing.\n\nPGP is as simple as you can make an offline E2EE messaging system in practice...", "You could have a centralized key server that handles that sort of thing.  \n\nBut if you're just communicating with your friend, it's going to take some effort on your friend's part.", "I recommend a classic from 1999 [Why Johnny can't encrypt](https://www.usenix.org/legacy/publications/library/proceedings/sec99/whitten.html) \\- it still applies.", "Google could realistically offer E2E for Gmail next month, adding a button \u201cEncrypt and Sign When Possible,\u201d asking for a password (better make it default) or even use login password if it\u2019s good enough. Similar to ProtonMail.\n\nProblem solved!\n\nOf  course, they don\u2019t want to do it for obvious reasons.\n\nSo, you can make email much more secure, but there are political hurdles.\n\nThe search and filtering experience will be worse, but that\u2019s what it is.", "It's hard to replace the inbox feature of an email. you'll have to be creative", "It\u2019s hard to wean people away from email. Basically when I send an encrypted email using the service, the recipient actually receives a professional-looking e-mail with minimal text saying \u201cyou received an encrypted e-mail from \\_\\_\\_\\_\\_\u201d and \u201cclick on this link to open the e-mail\u201d. It also contains a link with information like \u201cwhat is this and is it safe\u201d sort of stuff. Yeah, if it is unexpected I\u2019m not surprised people question it, but if you look at the hyperlink location and read up on the service you can learn it\u2019s legit. \n\nThe link goes to their website (email service) where the user would enter a password given to them and then the email would be displayed via the webpage. Ideally, the password would be provided by me via a different communication channel for the sake of security. But, for the sake of convenience, I\u2019m simply including it as the password hint (yes, not secure). What this does accomplish is it prevents gmail from gobbling up email data, intermediate spying, rogue employees with access to encryption keys, etc. The services I\u2019m talking about are E2EE. If the content was *really* sensitive, I\u2019d provide the password differently or communicate differently from the outset.", "> The core problem is E2EE is an afterthought in email UX, and that problem is fundamentally unfixable.\n\nNot just UX, but email technology as well. There's too many parts of the protocol that fundamentally cannot be E2E encrypted, so all the UX effort is just pointless, even if you somehow convince people, they end up with a technologically inferior solution that leaks data left and right.", "I agree that technically \u201cfixing\u201d email (the protocol) is not feasible in any easy scenario. However, if everyone used an email \u201dservice\u201d (like those I mentioned), the UX would be the same as e-mail, but the problems would be resolved. For example, Protonmail has an app and you can compose an email to another PM user and if feels the same as any other email app, but it\u2019s done seamlessly and easily and is E2EE. Getting people to switch from gmail to an E2EE email service is similar to getting people to switch from SMS to Signal, although possibly more cumbersome due to all of our website logins and profiles and people we\u2019ve shared our contact info with. I wouldn\u2019t say it\u2019s unfixable, but maybe harder to fix than swapping chat apps. However, there\u2019s nothing that easily replaces the experience of having an inbox.", "Yeah I figured this might be the answer. I do use Signal. But it requires having phone numbers, plus people like e-mail to \u201cstore\u201d conversations. It requires convicing people to share phone numbers (not too hard) and also downloading Signal (much harder). Although I agree that Signal is way better, adoption is not any easier\u2026", "I\u2019m not able to view reference 2, but I have to believe that Signal is better than SMS/MMS at least. I\u2019m sure people don\u2019t compare their safety numbers out-of-band (I do with my nerdy friends), but it seems much more likely in the wake of Snowden that our SMS/MMS is compromised than Signal messages. Whatsapp adoption is huge and is based on the Signal protocol and is E2EE (other than metadata and possibly if users allow backup to Google Drive). I *have* been able to convert many people to Signal actually and they like the UX as well as the call and video quality. I\u2019m an optimistic realist and genuinely hope that I/we can get the world to a more secure digital world.", "[https://tutanota.com/security](https://tutanota.com/security)\n\n[https://protonmail.com/security-details](https://protonmail.com/security-details)\n\n[https://posteo.de/en/site/encryption](https://posteo.de/en/site/encryption)\n\n[https://mailbox.org/en/security](https://mailbox.org/en/security)\n\nI don\u2019t claim to be an expert, but it seems like these companies offer such a solution\n\n(useful website if folks don\u2019t know about it: https://privacytools.io/providers/email/)", "Hmm not so. You can do e2ee using web crypto or similar and deliver the key encrypted to the end user so that only they can open the key (and the system in between has no knowledge of the key) pop it into local storage and off you go. There are also issues with uploading large files and the lack of a streaming encryption interface but that can also be worked around.\n\nIt\u2019s not elegant and I have concerns about the security of the web client but it can be done.", "I see value in preventing large corporations from logging unnecessary details about us that could be intercepted/leaked/misused/misinterpreted/etc. It\u2019s like having a peeping tom sitting in a tree outside my house. I\u2019m going to do everything possible to prevent that person from doing what they set out to do. If only for the principle of it, but I think we\u2019ll realize more what all this data tells about us later.", "These require others to use PGP as well though right? I\u2019m mainly trying to find a way to get the non-nerdy to use more secure services. If I receive an e-mail in one of those services I mention, it is supposedly stored in a way where my provider has no access. But if I\u2019m communicating back and forth to a gmail user, 1/2 of the conversation is stored on Google\u2019s servers, meaning all of my efforts are pointless.", "Eh, I\u2019m trying to do this with everyone\u2014even if my e-mail is just sending my favorite cat video. I don\u2019t want Google to know my favorite cat video! I seriously love cats vs cucumbers.", "Thanks for the explanation", "At that point you\u2019re not really using \u201cemail\u201d though, you\u2019re using a proprietary messaging service.\n\nEmail is a federated protocol, and if E2EE isn\u2019t supported in a federated scenario, you haven\u2019t actually solved the problem.", "Email can't be meaningfully encrypted and still be usable. It leaks too much of the message data. A chat system like Matrix might be easier to push than Signal, though the existence of multiple clients and homeservers is a big increase in difficulty.", "You also have the problem with something like signal that you are asking the other use to install an app just to receive a message from you., which means friction and a tendency to just forget about it.\n\nIt\u2019s easier in a b2b setting but b2c or c2c it is a nightmare. Email is a great and elegant system but it\u2019s over 40 years old and was never intended to be secure. Adding anything onto it is just a kludge and never works - what\u2019s really needed is an email 2.0 built with security first. Ain\u2019t going to happen in my lifetime.", "> deliver the key encrypted to the end user\n\nIf you can do this then you could of just delivered the content in the same way.", "I understand your desire, heck read Cryptonomicon for that exact ethos.\n\nThe problem as I see it is that the techniques these days are increasingly sophisticated; browser stenographer, Stingray cell phone interception equipment, and whatever else we don't know about and of course the power of a state apparatus turned towards a target; if you ever become a target, you're screwed regardless, so in the meantime, take reasonable precautions.", "Semantically/technically, yes you are correct. However, for a user that doesn\u2019t know the difference between a federated protocol and a service that replaces it but looks/feels/seems the same\u2026does it matter?", "Totally agree, but I want to make their life difficult just for the fun of it, hehehe!", "At that point, pick any non-federated E2EE messaging app and call it a day", "What alternatives are E2EE and can send/receive to email addresses (which is the root issue of my OP considering many times there are no other available communication methods, such as a business \u201ccontact us\u201d page listing an email address).", "If an E2EE protocol only works with a single provider, it isn't really an \"email address\". It's an e.g. ProtonMail address only. And again, that was the point I've been reiterating throughout this thread.", "These E2EE protocols can work with multiple providers: most of the E2EE email services I mentioned can send e-mails to each other and with any email that uses PGP or even when using Gmail/etc with tools like Mailvelope. I admit the latter options are not very user friendly. So it *can* be fairly inclusive and for this reason I still consider it \u201ce-mail\u201d, but agree to disagree I suppose. Your point is taken that to have E2EE and user-friendliness is to create something not email-like in implementation (even if e-mail like in UX).", "> These E2EE protocols can work with multiple providers: most of the E2EE email services I mentioned can send e-mails to each other and with any email that uses PGP or even when using Gmail/etc with tools like Mailvelope.\n\nYou're kind of talking in circles at this point. To quote you:\n\n> Using PGP is obviously too complicated for general users.\n\nI was a big fan of Mailvelope in 2014 or so, but my opinion has soured on the entire PGP mail ecosystem [as I previously expressed earlier in this thread](https://www.reddit.com/r/crypto/comments/p23dzw/getting_others_to_accept_encrypted_emails/h8hrs2p/).\n\nTo reiterate what I said earlier:\n\n> Solutions are awkward and bolt-on, rather than implemented as core \u201calways on\u201d changes to the underlying protocol, and often provide nebulous security properties."]}
{"id": "p0qjok", "title": "Encrypting pre-know text with AES and then hashing it for use as a password, overall security?", "url": "https://www.reddit.com/r/crypto/comments/p0qjok/encrypting_preknow_text_with_aes_and_then_hashing/", "Created (UTC)": "2021-08-08 17:32:28", "body": "Hello crypto community, this is my first post here so sorry if i missed anything.\n\nconfusing title i know, let me break the steps here.This is my method of generating some secure passwords mixing known algorithms already accepted as secure so no new systems here. I was wondering about best practises and possible weaknesses it might have - improvemets to be done.\n\n1rst A know text by both the \"attacker\" and me gets fed into the padding scheme.2nd the result of that is encrypted using AES with a totally random password(the best randomness i can get using secure methods for crypto and many digits)3rd the encrypted now bytes are salted and Hashed  with either PBKDF2, bcrypt or scrypt4rth The result of the hash turn into characters using base85 and i used as a password.\n\nYeah i know it is completely weird as a sytem but it provides a convinience for me and that's why i chose it.Now my questions, What would be a good padding scheme to use in the first step? obvisously i rely on the randomness of AES-256 encrypted data for security here(with a very good password), the random password is to guard against list based attacks, the hash after that is to make bruteforcing a random pass from a TB/sec to waaay less as they are slow hashes. My thinking here is that the 2nd step outputs something almost random and that fed into the 3rd step guarantee an almost random pass in the end.\n\nBetween PBKDF2, bcrypt or scrypt is there a clear choice for my case? my reasearch showed each have pros and cons.Is base85 from the pseudo-random output of the hash predictable(could be base64 i figured more digits=more combinations)?Should i change it to something else?I am not going for perfect security against hackers or something here just a good overall system to use(this one is easy to use).I know i can use password managers or 2FA which is a better solution but right now i am asking about this one, and about the theory not implementation attacks such as keyloggersmemory search etc.\n\nThank u for your time\n\n&#x200B;\n\nEdit1: As other pointed out in the comments what i am trying to achieve here is a deterministic password manager(thanks to  [jmw74](https://www.reddit.com/user/jmw74/)  and  [GibbsSamplePlatter](https://www.reddit.com/user/GibbsSamplePlatter/) for giving me the correct name for it)", "post URL info": ["https://www.reddit.com/user/jmw74/)", "https://www.reddit.com/user/GibbsSamplePlatter/)"], "author": "OmegaArmadilo", "ups": "3", "downs": "0", "number of comments": "42", "comments": ["Why would you do that? Why not just generate a random string of characters to use as password?", "You are using PBKDF2, which already creates a key from a password. Why are you adding extra steps?\n\nYour second step involves using random data as a password for AES, why not skip that and use the random data for the PBKDF?", ">Edit1: As other pointed out in the comments what i am trying to achieve here is a deterministic password manager(thanks to  [jmw74](https://www.reddit.com/user/jmw74/)  and  [GibbsSamplePlatter](https://www.reddit.com/user/GibbsSamplePlatter/) for giving me the correct name for it)\n\n[Deterministic password managers have 4 fatal flaws](https://tonyarcieri.com/4-fatal-flaws-in-deterministic-password-managers) you should be aware of.", "Yes this will provide approximately the same entropy as the key used to encrypt during the AES step.", "It has some unique convinience for me as a system as long as i have the AES random password the original text can be an identifier for where i want the password and it will generate a secure password in a deterministic way for every application i need.", "because the first know text is used as an identifier for which password it is and the random one can be considered the master password. Imagine the system having the same password for AES but generating 3-5 passwords for different uses, the difference for those would be the initial know text only", "It sounds like you're just using the original text as a salt. You could use PBKDF2/bcrypt/scrypt directly with your password and plug in the original text (or its digest) as the salt.", "Deterministic password managers already exist that solve your problem (if I understand it correctly). They use key derivation functions. \n\nGenerally encrypting a password with another password is not what you want. Tools like full disk encryption do that, because it's really expensive to change the key (re encrypt the whole disk). So instead they change the key to the key. And there's probably other reasons to do this but not for what you're doing.", "\"deterministic password manager\"", "You can use the identifier text as part of the salt value for PBKDF2", "yeah i thought of that approach but i didn't realy like the salt being a common application name, and i wouldn't be enough bits anyway for most cases", "Yeah determenistic password manager is what i am trying to achieve here, i am not really encrypting a password with another password though, the idea is the first data is the name of the application and that gets encrypted to generate random data with the master password", "They're a thing. Typically a terrible idea, but they do exist. They try to solve password management without having to keep per-account state, but that's impossible.\n\nDifferent accounts will have different password length and complexity requirements, and they WILL end up being mutually-incompatible. So no single algorithm can generate passwords from a seed for all accounts, without per-account state.\n\nSome accounts will get their passwords forcefully reset by the service provider, eg due to a breach. Without state, there's no way to change just one password.\n\nSo they end up keeping state to track the complexity requirements and the number times an account has had its password reset. At that point they have no benefits over a traditional offline password manager like KeePassXC or Bitwarden. And unlike those they can only generate passwords, and can't safely store any other secrets.\n\nAll cost, no benefit. Bad idea.", "Like LessPass (yes, Less)", "Some people use a separate \"pepper\" string that is unique to the application.", "Yes, I get it. You don't want AES. That's what key derivation functions do. They take a salt (publicly known part) as one of the inputs. That's where you put the app or website name. The other input is the original key. And it outputs a new key.", "Never said they were good.", "Ah ok, i though about AES as a first step to bring the \"salt\"(names of the applications) to the right amount of bits first, would it be secure to use 5-10 letter words(40-80 bits) with a padding scheme as a salt? I mean i though that would impact negatevely the key derivation function", "The salt doesn't need entropy, AFAIK. Knowing it doesn't help an attacker because they still need the original password.", "Technically it needs entropy, just not secret entropy. Collision resistance is all the salt value needs, so you don't accidentally let the attacker reuse work.", "ok thanks for the help!"]}
{"id": "ozv7nz", "title": "Can't find any good books on how to cryptanalyze a classical Homophonic Substitution cipher with 3 alphabet types (a-z, 0-9, and keyboard symbols)", "url": "https://www.reddit.com/r/crypto/comments/ozv7nz/cant_find_any_good_books_on_how_to_cryptanalyze_a/", "Created (UTC)": "2021-08-07 08:22:05", "body": "Hey crypto community,\n\nI'm hoping someone here can recommend a good book on solving classical ciphers of the type: Homophonic Substitution.\n\nThe books I've read have VERY little information on Homophonic Substitution ciphers, and even less on how to go about approaching a solve for them.\n\nI've read:Elementary Cryptanalysis - A Mathematical Approach (Singh)\n\nCryptanalysis - A Study of Ciphers and Their Solutions (HF Gaines)\n\nCan someone recommend a book/text to help zero in on the manual methods I can use?\n\nThe ciphertext has a total of 36 unique symbols, 3 spaces in the ciphertext (which might be red-herrings), and is only a total of 62 characters in length which adds quite a bit of ambiguity to the traditional methods I've studied in the books referenced above such as freq. analysis, etc.\n\nFurther, the cryptogram only has a single repeated bigram \"j\\\\\" and frequency analysis shows large peaks and troughs which worries me that I've misidentified this as a Homophonic Substitution.\n\nBy and large from my understanding of Homophonic Substitution (which is green to say the least), I should expect to see the frequency distribution being flatted, but the distribution is more reminiscent of a transposition cipher and not very flat. I'm not sure what to classify it as since it has n>26 symbols which to my understanding implies a homophonic substitution, yet the freq. distribution does not coincide with a flatted Homophonic substitution appearance.\n\n&#x200B;\n\nAny recommendations for reference material will be greatly appreciated, thanks for your time and consideration :)", "post URL info": [], "author": "CivilBet4806", "ups": "19", "downs": "0", "number of comments": "42", "comments": ["since you don't know for sure what the cipher used is and the ciphertext you have is so short, you're going to be fighting an uphill battle no matter what. pretty much all techniques for breaking traditional ciphers require more ciphertext, with more complex ciphers needing more ciphertext to break since it is based on statistical analysis.", "I would suggest \"Military Cryptanalytics\" by William F. Friedman and Lambros D. Callimahos. You'll need Part 1 Chapter 8 \"Multiliteral substitution with variants\"\n\nThere's a possibility your cryptogram is not homophonic, but it's hard to tell. I recommend to post it at r/codes (read rules before posting) to get more help with solving.", "I wasn\u2019t aware of how retarded I actually was until I read this. I mean I knew already but this confirmed it. I thought I was \u201cinto\u201d crypto but apparently I\u2019m just a \u201cnumber go up\u201d knuckle-dragger. Thanks for this lol.", "Hello folks,\n\nIn public key encryption,  when I send a message using a network and if the network is compromised, the hacker can know the public address I am sending the message to, right?\n\nHas there been any algorithm which tries to hide the public address while sending the message?\n\nIs it important to hide the public address? Yes. Cause sometimes I am sending a message to a certain someone could mean breach of security. Imagine wartime situations. \n\nThanks in advance.", "[removed]", "I see, I've been wondering if there is a \"minimum number of characters\" required for statistical techniques to remain valid. Do you know if that number varies based on cipher type?\n\nAlso, do you have any tips for short ciphertext analysis? I'm assuming there are no hard and fast rules because it seems like short ciphertexts are like blackholes (normal mathematics don't work inside)", "Thank you kindly for this recommendation, I'll look into that book by Friedman and Callimahos. I found some good stuff from Friedman on the WayBackMachine, will continue investigation. Cheers", "FYI this is subreddit is about cryptography, not cryptocurrency", "I'm not sure how this relates to my post, did you make a mistake?", "Yes\n\nYes - see Tor and mixer networks, also see PURB schemes (padded uniform random blob)", "???", "It does, more complex ciphers need more characters for statistical analyis to be effective. Compare basic substution where simple frequency analysis can get you pretty far vs homophonic where you would need to look at bigrams or sets of possible keys for monograms. If you add in key rotation, it gets even more complex meaning you need more ciphertext to decipher it, ect.", "You can also try to solve it with CrypTool or AZdecrypt, both have homophonic substitution solvers. The length of the ciphertext may be a limiting factor though.", "I am extremely sorry. I couldn't post it (not a verified user of the community). So just commented here, iI am extremely sorry. I couldn't post it (not a verified user of the community). So just commented here, I", "Thanks a bunch. Will take a look into those.", "Hey good call, I'm actually using those exact tools for the past 2 weeks. Was researching tools and found that the Zodiac Cipher's were/are homophonic substitution in nature and found the project team who cracked it leading to AZdecrypt and ZKdecrypt. Great tools, look like they both use MCMC hill-climbing and have simulated annealing options but havent had much luck on deciphering. I feel like there are a lot of assumptions/knowledge behind those tools that I'm not educated enough on yet to make minor manipulations to the configs and know the implications.  \nGreat callout, thanks.", "You could make a request to get approved", ">You could make a request to get approved\n\nThanks. Will do that. However, my question was sort of naive and got the primary answer I was looking for."]}
{"id": "ozkf3b", "title": "Seeking advice on learning math behind cryptography", "url": "https://www.reddit.com/r/crypto/comments/ozkf3b/seeking_advice_on_learning_math_behind/", "Created (UTC)": "2021-08-06 18:57:03", "body": "TL;DR - what is the best way to learn the math behind cryptography? Grad school, or self-study?\n\nI've got a bachelors in EE and am in the US, and am looking to go back to grad school. For US-based programs I really don't see much in the way of cryptography, at least at a Masters level (what I have time for).\n\nI know about cryptographic primitives, implementations, common protocols. In crypto coursework I learned some basic number theory (for stuff like RSA, El Gamal) and then some more complicated PQC stuff like basics of lattices, and linear & differential cryptanalysis.\n\nI realized I really like the math side of crypto, despite spending a lot of time in the implementation and practical side of it. I want to learn more about this, particularly with the onset of PQC. What I find really cool is when people mathematically evaluate crypto. I see people write papers that evaluate some hashing algorithm or block cipher, and I want to be able to do that.\n\nDoes anyone have any advice on how to get to this point? I am considering graduate school, but I don't know if an EE or mathematics degree makes more sense. At the same time I don't really know where to start for studying the math, and if self-study is best here (math in crypto seems like various smatterings of topics).", "post URL info": [], "author": "brebboard", "ups": "23", "downs": "0", "number of comments": "53", "comments": ["Since you're interested in post-quantum cryptography and lattices, one approach is to look at the Simon Institute's program on [Lattices: Algorithms, Complexity, and Cryptography](https://simons.berkeley.edu/programs/lattices2020) and investigate the people presenting as potential academic advisors and also watch the videos, in particular the [boot camp](https://simons.berkeley.edu/workshops/lattices-2020-boot-camp), to learn a flavor of what they're doing.", "This is pretty good https://www.coursera.org/learn/crypto, there's a cryptography II class there as well\n\nI think if you log in you can still get the materials for free without \"enrolling\" which is just getting on the schedule and getting a digital certificate at the end.\n\nKeep in mind though that the math isn't sufficient for implementing a production quality library. There are concerns like timing attacks where different code paths taking different amounts of time can leak your keys and other things like that.", "Try [*An Introduction to Mathematical Cryptography*](https://www.springer.com/gp/book/9781441926746). It doesn't deal with post-quantum crypto, but that's unlikely to be relevant any time soon. It's a solid introduction to crypto as it's used today.", "You should do a PhD and importantly find an advisor whose work primarily gets into the nitty gritty of actual protocols or assumptions like LWE. That seems much more concrete than a math degree. There is a general sense in the field right now that not enough work is being done to realize actual efficient protocols from actual mathematical assumptions (ie quantum digital signatures right now are an order of magnitude too large, too big to be widespread, but there\u2019s like only one or two people working on it; it\u2019s very much a math/theoretical problem, but more concrete than what most cryptographers work on. That sounds like to me the type of thing you are looking for. Cryptography can be very abstract imo\u2026 it\u2019s very easy never to touch number theory, lattices, or algebra\u2026).\n\nOff the top of my head I know a few folk at Stanford and UCSD working on this stuff, for instance. There should be an opportunity for you somewhere", "This course is great as an intro to the math:\nhttps://youtube.com/playlist?list=PL6N5qY2nvvJE8X75VkXglSrVhLv1tVcfy\n\nThe professor is absolutely fantastic.", "[removed]", "I'll definitely check that out. That's a good idea for finding advisors, too. It's been tricky looking for schools that focus on crypto, this helps", "I went through that course during the winter and really enjoyed it. Warmly recommended, but it's more of a starting point to the math side of crypto. But it's a very good starting point, then you can move on further. He really starts from the basics with PRFs, PRPs and builds to AES etc from on top of that.\n\nHoewever I would not wait for Crypto II, afaik it's been \"coming soon\" for a while now.", "Thanks! I think my college crypto class actually used his book, so went through a similar progression, that's a funny coincidence :)", "Thanks! I'll take a look - any other books you recommend?", "Yeah real efficient protocols are not really being focused on, though it may not be possible in some instances depending on what you mean by efficient. Like I'm working with a group on doing communication lower bounds in secure group messaging, and we found that while there are absolute lower bounds, there's no efficient optimal protocol in the general case.", "Oops just saw you only had time for a masters. I don\u2019t think a Masters will teach you much; self study is probably the way.", "This subreddit is about cryptography, not cryptocurrency, FYI", "Coming soon for almost a decade, now.", "Yeah I was thinking the same about the Masters. I might get my MS in EE and take some helpful courses for crypto along the way.  \nThat's interesting what you say about creating realizable protocols - that seems like really relevant work - IIRC pqc key sizes can be gigantic (I may be wrong). I'm going to take a look into that, thanks.\n\nAnd who knows, maybe I'll find a way to finagle a PhD - it's just *many* years.", "~~Really? Says starting October 20th?~~ [~~https://www.coursera.org/learn/crypt~~](https://www.coursera.org/learn/crypto2)\n\nNow I see the content says \"The description goes here\".  Assuming it's been like this for a while.", "Yeah I took Crypto 1 what... 7 years ago at least.  Got a certificate, before Coursera started charging money.  Dan Boneh was talking about crypto 2 then.\n\nI do feel like I need to take a class in elliptic curve crypto, but I don't know where to go for that."]}
{"id": "ozbw8i", "title": "SAML is insecure by design", "url": "https://joonas.fi/2021/08/saml-is-insecure-by-design/", "Created (UTC)": "2021-08-06 10:56:24", "body": "", "post URL info": [], "author": "lpsmith", "ups": "41", "downs": "0", "number of comments": "48", "comments": ["https://latacora.micro.blog/2019/07/24/how-not-to.html is a really good blog post about this style of issue.\n\n  \nThe post you linked rambles a bit but ultimately the points are good, and similar to the Latacora article I link:  \n\\- Do not use request signing as your main API security mechanism, where possible. It's OK as an extra paranoia level in addition to something harder to screw up (bearer tokens over HTTPS, etc.) but on its own, it's too easy to get wrong. With HTTPS, you aren't really that worried about tampering to start with, so signing mostly offers an indirect and easy-to-screw-up way to prove the client is in possession of a secret (key), vs. a bearer token.   \n\\- Always prefer signing serialized bytes, not values. This way you aren't vulnerable to nearly as many canonicalization or parser-confusion bugs. You not only avoid signing attacks on the serializer, but you also move the parser attack surface area to after the tamper check, which is great.  \n\\- Always sign an entire payload. This way you aren't nearly as vulnerable to the same types of early-termination, duplicate-payload, reuse, and padding shiv attacks.  \n\\- Going with the above: this means you should prefer out of payload signing. Again, reduce canonicalization and parser-confusion issues. Of course, this is very hard with JSON over REST, because the payload headers affect the operation context. But if you control your payload shape, a signature in a header is much better than a signature in the payload where, again, it needs to go through a more-complex deserialization mechanism.", ">SAML uses signatures based on computed values. The practice is inherently insecure and thus SAML as a design is insecure.\n\n\u0ca0_\u0ca0", "i have yet to see a XML based thing that is any good, so no surprises there\n\nHowever, I believe that the article's main thesis (\"something something malleability\") is fundamentally misguided. The problem here seems to be in _canonicalization_ of data to be signed -- plus the brain-dead choice of XML, of all things, to try to solve this generally difficult problem.", "I've implemented a portion of SAML for a company. I'm no fan of SAML. \n\nBut the article has missed the mark. There is some danger associated with canonicalized signatures, but it's not the main problem of SAML and definitely doesn't make it insecure by design.\n\nThere's a [whole document](http://docs.oasis-open.org/xacml/3.0/dsig/v1.0/cs02/xacml-3.0-dsig-v1.0-cs02.html) which details precisely how to do the canonicalization of the XML. It's surprisingly short for an OASIS SAML standard. That's because it's mostly a reference to a HUGE standard called the XML Digital Signature profile of XACML and the particular choices/restrictions that SAML layers on top.\n\nAnd that's the real problem. SAML, including the transitive dependencies, is a huge spec with a dizzying array of options. About a decade ago a concerted effort was made in the identity community to start doing interoperability testing between everyone's implementations. It was pretty bad.\n\nComplexity and leaving choices to the implementation. That's what makes SAML hard to do right, by design. Still doesn't make the protocol insecure by design. Protocol level mistakes can't be fixed by improving a particular implementation, they're present in all implementations. So the example in the article outs itself as an implementation mistake right out of the gate. They're annoyingly common among SAML implementations due to the complexity, but if you only implement the slice of the stand you intend to support and hire a reputable external pen tester to test the security of your product (you are doing that, right?) then you should catch most of these issues.\n\nAlso, because it annoys me to no end, OAUTH is NOT AN AUTHENTICATION PROTOCOL. Stop mentioning it in the context of authentication protocols. OpenID Connect is and was designed to be from the start.", "That was excellent. Thanks!", "I am sure this isn't news to some people here, but I hadn't taken a close look at SAML yet.\n\nSo, I can't say I am super enthusiastic about OAuth2, especially JWT, but I didn't realize how bad SAML is.", "[deleted]", "What about PDF signatures which are embedded in the PDF itself? Do they also suffer from a similar kind of vulnerability? Or does that handle this the right way?", "The json counterpart is not much better either. Very same problems with non-spec'd corner cases, such as key ordering and duplicate keys. They even copied the SAML spec to json without fixing the problems.", "SAML came from an era when many languages did not have built-in or industry-accepted JSON serialization libraries, so XML seems as logical a choice as anything.\n\nTo your point, the issue is a simple one of canonicalization (as a matter of fact, I almost think the blog post author just used the word \"malleability\" where they wanted \"canonicalization\" anyway) - which can be a problem with \\_any\\_ serialization format. This is also a mega-bad issue with JWT, even: https://latacora.micro.blog/2019/07/24/how-not-to.html\n\nI do agree that I look rather askance at any modern interchange format preferring XML, and immediately go looking for \"why\" - simply because the decision tree required to reach \"XML\" in 2021 requires a lot of questionable decision making.", "I disagree with the original author's degree of absolutism, but I am not so sure the main thesis is all that far off.  I am not against malleability in all circumstances, but certainly malleability should be adopted very carefully, minimally, and for good reasons. \n\nFor example, years ago I was involved in a discussion about a software source code repository, and I suggested that for signatures, that packages come with a signed manifest of the filenames and hashes of every file in a given release, and not a signed .tar.gz, because there's often a large degree of similarity between releases of a single package.  If an archive were to exploit that similarity, it could store the entire repo history in order(s)-of-magnitude less space than storing individual .tar.gz files would take.\n\nHowever, reconstructing the original gzip encoding exactly byte-for-byte would be a major (perhaps insurmountable) impediment to such an implementation.  Reconstructing the original tar format is inconvenient, but not the same kind of impediment.  Whereas a signed manifest allows one to validate that you have the correct set of files that are each identical to the released version, without having to reconstruct original tar.gz files just to validate a signature.\n\nSomebody jumped on me for practicing cryptography without a license, apparently. \n Ugh, that conversation didn't go well.  I am sure we could have both been a bit more eloquent on the actual technical issues.\n\nBut unlike that case, I am not seeing the value of SAML's approach to signatures.  What value is there, really, of SAML using any signature scheme other than one that locks down the exact byte sequence of the XML document?", "> i have yet to see a XML based thing that is any good, so no surprises there\n\nIs XML responsible for this vulnerability which other data exchange formats avoid? The author also gives the jq example of how computed values can be signed with JSON also. JSON is less verbose & hence preferred but there doesn't seem to be something inherent in XML which causes the issue being discussed. This seems to be more about the SAML spec rather than XML itself.", "How so? The external provider is supposed to be trusted.", "I read the PDF DocSig spec quickly. I will say that `The hash of the entire file is computed, using the bytes specified by the real ByteRange value using a hash algorithm such as SHA-256. Acrobat always computes the hash for a document signature over the entire PDF file, starting from byte 0 and ending with the last byte in the physical file, but excluding the signature value bytes.` is extremely promising, but the provision for other signatures and the complex header format is not. This would require an in-depth audit.\n\nCompared to SAML, it is much better on first read, though - the Acrobat PDF approach doesn't try to cherry-pick specific parsed fields or values to hash (which allows for object key-reuse/collision, padding, serialization ordering, etc. etc.), it just hashes the whole file.  Reading the signature in order to compare it, however, kind of sucks - it requires parsing at least the header to find the signature, which is a huge attack surface for parser vulnerabilities that would be avoided by a simpler scheme that probably wasn't possible in PDF, like locating the signature at a fixed offset. But, the hashing scheme isn't nearly as bad as the SAML approach.\n\nTo be clear, there's no \"right\" way here, just an \"easy\" way and a \"hard\" way. One absolutely _can_ implement a signature scheme which operates on values (rather than serialized bytes), is serialized within a document itself, and allows for \"controlled malleability\" of the source document, all while still remaining secure. It's just a _whole lot_, like _many dimensions_ harder than implementing a signature scheme which simply operates on pre-serialized payload bytes and stores a signature. The attack surface of one approach is\\_much_ larger than the other. The SAML approach is the hardest kind while the PDF approach is somewhere closer to the middle.", "Incorrect parsing of PDF signatures has happened a few times\n\nhttps://www.pdfa.org/recently-identified-pdf-digital-signature-vulnerabilities/", "are there any great solutions?", "The problem with XML in particular is that it's way more complex than it needs to be, and specifically in a way that makes it difficult to avoid bugs like these.\n\nAs pointed out in another comment, just taking all mentions of XML in the spec and replacing them with JSON would not solve the issue -- but it would at least make the problem tractable. \"Using JSON very carefully\" is a something that can realistically be achieved. Not so much with XML.\n\nA good comparison would be DER - also an extremely complex format, but a bug of this kind would be pretty much impossible in DER because it's designed specifically so that only the canonical encoding is the correct encoding.\n\n(of course DER has an amazing track record for a very different kind of vulnerability so not a great choice either)", "[deleted]", "Well, from a practical engineering perspective,  choosing the \"hard\" way is certainly wrong unless you have a good reason to do so.   There needs to be a potential advantage at the end of the hard path to justify the extra effort (and especially the extra attack surface, in this case.)\n\nI do heartily agree with your comment.  Your last paragraph is from a perspective of theoretical correctness, which is an important perspective to be able to take.  I am just further elucidating another important perspective that you hint at in your post.", "Sure. Write a proper spec, where the ambiguous omissions are all clarified. Like three sentences. Needed for json, the jsonsec and the xmlsec specs. All these issues are known for years, and deliberately ignored.", "Uhh, it's ultimately up to the customer to decide who they trust or not.\n\nI have given many of these issues a fair bit of thought over the years.  My take is:\n\n1.  SSO is really aimed at organizations.\n\n2.  Whether an org self-hosts or uses a hosted SSO solution, they will face certain insider threats to their AAA infrastructure.\n\n3.  In some cases, parts of those threats can be mitigated by outsourcing. For example, it's likely going to be a lot more difficult for your inside threats to manipulate your AAA logs if you are paying for hosted AAA.   Of course, you are also making it easier for your service provider's inside threats to manipulate your logs.\n\n4. That can be a win, especially if your service provider has a better plan for mitigating insider threats than you do. \n\nIt's a tricky tradeoff that doesn't have a one-size-fits-all solution.\n\nOf course, I do wish it were more feasible for organizations of many kinds to self-host their AAA infrastructure.", "This is not a weakness of the SSO mechanic then.", "[deleted]", "From the user's stand point, with SSO you don't need to create new accounts, you just have one. There is no need to trust anything apart from the SSO provider. What you actually are doing when using SSO, you share your information with other websites, you don't have to trust them, you just have to agree that a number of information regarding your account (e.g email) will be shared. This is not trust. This is just information sharing.\n\nFrom the application stand point, you have to trust the SSO provider. If you don't trust the SSO provider, you should not use it. It is like when you use a passport, if the country you are heading to does not trust your legal documents, they should not allow you to enter the country.\n\nIf there is a way to forge 1 country's passport, this is a problem with this country's passport not with the whole passport system. If SAML is insecure, don't use it, use OIDC."]}
{"id": "oz644w", "title": "Google's C++ to FHE compiler | FHE.org meetup", "url": "https://www.reddit.com/r/crypto/comments/oz644w/googles_c_to_fhe_compiler_fheorg_meetup/", "Created (UTC)": "2021-08-06 05:58:00", "body": "Hi everyone,\n\nThe team at Google will present their work on compiling C++ to FHE at the next [FHE.org](https://FHE.org) meetup, on august 26th. Link to event: [https://www.meetup.com/fhe-org/events/279950583](https://www.meetup.com/fhe-org/events/279950583)\n\nSee you there!", "post URL info": ["https://FHE.org)", "https://www.meetup.com/fhe-org/events/279950583](https://www.meetup.com/fhe-org/events/279950583)"], "author": "randhindi", "ups": "24", "downs": "0", "number of comments": "29", "comments": ["It'll be interesting to see if they can bring the speed down to earth. Right now it is by far the biggest barrier, on top of a bunch of unknown security properties.", "Well you should definitely attend our monthly meetups, you\u2019ll be surprised how fast FHE has gotten in the last couple years! Still quite slow but nowhere as slow as it used to be", "Is it at all useful for doing anything real time?\nAs in no less usable then connecting to a server  with bad internet", "Yes it is now. Id say its about the same computational power as a gameboy today, and will be like a snes by next year. Thats enough for most data science inference, like medium size neural nets, analytics, simple db queries etc.. Still 3-5 years away from running gpt-3 homomorphically however ;)"]}
{"id": "oz2pcn", "title": "Published an implementation of CL Signature schemes and anonymous credentials on github", "url": "https://www.reddit.com/r/crypto/comments/oz2pcn/published_an_implementation_of_cl_signature/", "Created (UTC)": "2021-08-06 01:40:17", "body": "I have published an [implementation](https://github.com/ahasikos/CL_Signatures) of the signatures and anonymous credentials schemes of the paper \"[Signature Schemes and Anonymous Credentials from Bilinear Maps](https://link.springer.com/chapter/10.1007/978-3-540-28628-8_4)\".\n\nThe code in written in C and it built on top of the [miracl-core](https://github.com/bryk-io/miracl-core) library. There is *some work pending* but for those who are familiar with the scheme it should be straightforward to follow.\n\nAny comments or feedback is appreciated. If anyone wants to contribute feel free to ping me.", "post URL info": ["https://github.com/ahasikos/CL_Signatures)", "https://link.springer.com/chapter/10.1007/978-3-540-28628-8_4)\".", "https://github.com/bryk-io/miracl-core)"], "author": "elaroc", "ups": "8", "downs": "0", "number of comments": "22", "comments": ["[deleted]"]}
{"id": "oyluta", "title": "Ristretto & Curve25519", "url": "https://www.reddit.com/r/crypto/comments/oyluta/ristretto_curve25519/", "Created (UTC)": "2021-08-05 09:20:55", "body": "I've been looking at ristretto.group, and its really cool.\n\nI understand for some protocols we need curve points to behave as if they were from a prime order curve.\n\nI have a few questions on this,\n\n* Do we call curves without prime order \"composite\"?\n\n* Why do some protocols demand prime order from the underlying curve?\n\n* Why isn't the fact that we work inside a prime order subgroup anyway good enough in the first place, is it that the curve arithmetic is done over the entire curve? I ask as we are using G which only generates points inside the subgroup anyway right?", "post URL info": [], "author": "john_alan", "ups": "20", "downs": "0", "number of comments": "34", "comments": ["> Do we call curves without prime order \"composite\"?\n\nI've certainly seen \"composite order\" used. I wouldn't necessarily say just \"composite elliptic curve\", since we're only talking about the order.\n\n> Why do some protocols demand prime order from the underlying curve?\n\n> Why isn't the fact that we work inside a prime order subgroup anyway good enough in the first place, is it that the curve arithmetic is done over the entire curve? I ask as we are using G which only generates points inside the subgroup anyway right?\n\nThese two vary from protocol to protocol. For example, [Elligator](https://elligator.cr.yp.to/) tries to make elliptic curve public keys indistinguishable from random bit strings. X25519 (the ECDH protocol using Curve25519) works over the prime-order subgroup of Curve25519, which is about 1/8 of the total curve points (cofactor 8 implies this). So the resulting curve points will look decidedly non-random, since they can't be uniform over the entire curve. Elligator needs to work on the whole curve, but it's easy to break ECC security on a composite-order curve if you're not in a prime-order subgroup. So you'd be stuck: either have an insecure system or reveal that you're using cryptography in exactly the way Elligator tries to hide it. Ristretto provides an efficient mapping between the subgroup and the whole curve in a way that preserves security, and can work with things like Elligator.\n\n/u/loup-vaillant has written a good [article on Elligator with Curve25519](https://loup-vaillant.fr/articles/implementing-elligator), and understands this better than I do. I'm sure there are other examples of *why* just using the subgroup isn't always possible.", ">Why do some protocols demand prime order from the underlying curve?\n\nResearchers often assume a prime-order group because it's easier to analyze.  For example, there are no small subgroups of a prime-order group except for {identity}; everything except the identity is a generator (and therefore a random point is a generator with overwhelming probability); a random multiple of a generator is equivalent to a random point on the curve, and adding it to something perfectly masks that value; etc.  So there are fewer cases to deal with.  Often the protocol can be adapted to a composite-order group, but like many tasks in crypto, this has to be done *just so*, which takes a lot of work and expertise.\n\nA major goal of Ristretto/Decaf is to make the exercise of implementing academic crypto designs easier, because you can have simple, fast, constant-time formulas on a prime-order group, and all points have exactly one encoding.\n\n>Why isn't the fact that we work inside a prime order subgroup anyway   \ngood enough in the first place, is it that the curve arithmetic is done   \nover the entire curve? I ask as we are using G which only generates   \npoints inside the subgroup anyway right?\n\nIt does work.  But then if someone sends you a point, you have to check whether it's in the prime-order subgroup, which is kind of annoying and/or slow.  IIRC for Ed25519 you have to either scalarmul by q and see if you get the identity, or else take two square roots and a Jacobi symbol or two.", "Naively using an elliptic curve group with a cofactor to implement a protocol that requires a prime order group can lead to small subgroup attacks.\n\nA good practical example of such an attack with a nice writeup is \u201cExploiting Low Order Generators in One-Time Ring Signatures\u201d which describes an attack against Monero: https://jonasnick.github.io/blog/2017/05/23/exploiting-low-order-generators-in-one-time-ring-signatures/\n\n(there are at least two such attacks against Monero. The other was in their implementation of Bulletproofs)", "> IIRC for Ed25519 you have to either scalarmul by q and see if you get the identity, or else take two square roots and a Jacobi symbol or two.\n\nApart from checking that the public key is on the curve (and not on its twist), while decompressing it, I've noticed no special check on TweetNaCl and Ref10. And even then, if we assume (as I do) that the public key must be vetted in the first place (certificate, trust on first use, manual check\u2026), then legitimate public keys are always on the prime order subgroup.\n\n_(Now, if I'm starting to get dreams of crypto currencies and start asking more exotic properties from Ed25519 than being a signature, I'm going to get into trouble the second I start using a library that doesn't reject points outside the prime order subgroup, and could fall prey to the fact that 8 different public keys are equivalent or something)_", "I forgot to say thank you!", ">Apart from checking that the public key is on the curve (and not on its   \ntwist), while decompressing it, I've noticed no special check on   \nTweetNaCl and Ref10.\n\nThat's right.  I meant that if you're trying to implement some protocol that really requires a prime-order group, and you decide to use the prime-order subgroup of ed25519, then you have to put in this extra work.", "Oh yes, definitely (and in this case, I'm a big fan of your  Decaf/Ristretto)."]}
{"id": "oxsunb", "title": "Newbie's cryptanalysis?", "url": "https://www.reddit.com/r/crypto/comments/oxsunb/newbies_cryptanalysis/", "Created (UTC)": "2021-08-04 06:37:29", "body": "I have a information security background but I'm new to crypto..\n\n(I've done some basic cryptohack and cryptopals challenges)\n\nI'd like to try real world cryptanalysis and learn by the process!!\n\n&#x200B;\n\nCould you recommend some targets where they 'roll their own crypto' to start fiddling on?\n\nThanks in advance and sorry for poor english..!\ud83d\ude2d", "post URL info": [], "author": "romano31415", "ups": "28", "downs": "0", "number of comments": "47", "comments": ["One way to start is to go historical, rather than \"own-rolled\". At university we went all the way van to Caesar ciphers and Vignere ciphers, and worked up to finding flaws in DES. Plenty of open targets in the history books!", "One way that might help is to go through crypto CTF's. They are good way to understand the weakness that are inherit to certain ciphers or in some cases, issues that appear due to implementation flaws/assumptions.\n\nOther way that has kinda of \\`roll their own crypto\\` and you try to break is the famous CHES whitebox challenge \\[1\\]  \n\n\\[1\\] https://whibox.io/contests/2021/", "how about this one?\n\nhttps://www.schneier.com/academic/archives/2000/01/self-study_course_in.html", "You could try to [break HighwayHash](https://www.reddit.com/r/crypto/comments/frgeat/hash_anyone_looked_at_highwayhash/).  \n\nYou can also look at some [simple, roll-your-own crypto functions that I broke long ago](https://littlemaninmyhead.wordpress.com/2015/09/28/so-you-want-to-learn-to-break-ciphers/).", "https://cryptopals.com", "Here's a good place to start: http://www.theamazingking.com/crypto-feal.php", "If you are interested in linear and differential crypt-analysis, check out this paper: [http://www.cs.bc.edu/\\~straubin/crypto2017/heys.pdf](http://www.cs.bc.edu/~straubin/crypto2017/heys.pdf)", "[removed]", "[removed]", "[removed]", "Did those! I've studied basic LC DC and pke stuffs but I'm a bit tired of bottom-up studying..\ud83d\ude25 so was trying a new approach by diving into cryptanalysis rightaway!\n\nI learned a lot from actual pen-testing and thought I could do the same with crypto..!\n\nIn short i wanna try something like this!\nhttps://peter.website/meow-hash-cryptanalysis\n\nCould you recommend any targets?\nThanks for the reply!!", "It's quite a bit old by now, so it won't cover new techniques, but as a starting point it might work", "I read your blog and it gave me deeper insight about this field, thanks for all the articles and replying!", "doing it already..\ud83d\ude05", "Oh thanks I'll check out!!\ud83d\ude06", "This subreddit is about cryptography, not cryptocurrency", "This subreddit is about cryptography, not cryptocurrency", "Just delete your account and all the spam.", "You can try my little (or not depends on your knowledge) challenge : https://github.com/Pro7ech/CryptoChallenge (full solution with code included).", "Then you\u2019re in great hands.", "Ow whoops haha, my mistake"]}
{"id": "oxo6x5", "title": "Memory-bound trapdoor proof of work", "url": "https://www.reddit.com/r/crypto/comments/oxo6x5/memorybound_trapdoor_proof_of_work/", "Created (UTC)": "2021-08-04 01:26:08", "body": "The problem:\nI run a server, and want to supply an API call, without CAPTCHA, unauthenticated, which causes load on the server.\nPotential: DoS by just calling the API endlessly\nGoal: Make DoS expensive / uninteresting\n\nNon-Solution #1: \"Just use any PoW scheme, like SHA256 or Hashcash or whatever\"\nWhy not: Some users have shitty mobile phones, so the PoW scheme can't be too hard. Meanwhile, attackers have graphics cards, so the PoW scheme must be quite hard.\nTherefore: CPU-bound PoW is not ideal. As Wikipedia states, memory-bound hash functions seem to be more \"egalitarian\".\nhttps://en.wikipedia.org/wiki/Memory-hard_function#Motivation\n\nNon-Solution #2: \"Just use a memory-hard hash like argon2 or scrypt for your PoW scheme, like H(nonce) < threshold\"\nWhy not: A single invocation of Argon2/scrypt requires the same resources during \"proving\" and verification. An attacker can just send millions of invalid proofs, overloading the server.\nTherefore: The verification step shouldn't be too difficult for the server. \n(Also, I'm not entirely sure whether Argon2/scrypt hashes can be used like that. Maybe the attacker has an easier way to influence the first few bits than brute-force. Also, both methods really aren't meant to be used like this.)\nHence my slightly-incorrect use of the word \"trapdoor\": I don't actually require that the server-side is trivial, just that it is simple enough.\n\nNon-Solution #3: \"Just roll your own crypto!\"\nWhy not: I would be rolling my own crypto.\n\nNon-Solution #4: Hokkaido https://eprint.iacr.org/2005/356.pdf\nWhy not: Seems informal, contains significantly many typos, not peer-reviewed, searching \"hokkaido hash\" or \"hokkaido proof of work\" or \"hokkaido scheme\" basically only yields the paper as a result.\n\nNon-Solution #5: What Hokkaido cites as [1]\nWhy not: Just O(l^2) for attacker and O(l) for server. However, this is going the right direction.\n\nNon-Solution #6: What Hokkaido cites as [5]\nWhy not: Only linear(!) blowup, depends on rather old primitives (RC4 and SHA1)\n\nNon-Solution #7: kaPow\nWhy not: Only mentioned in a single Stack-Overflow post, seems to rely on hash inversion anyway, so not really memory-bound\nhttps://stackoverflow.com/questions/26821310/is-there-a-memory-bound-proof-of-work-concept-for-use-in-javascript\n\nNon-Solution #8: Cuckoo Cycle https://github.com/tromp/cuckoo\nWhy: At least a few people have looked at it, and any attacker is far more likely to directly attack the blockchain itself, than my server (which doesn't get involved with the blockchain)\nWhy not: The \"mathematical specification\" https://github.com/tromp/cuckoo/blob/master/doc/mathspec is woefully inadequate, their \"C spec\" focuses more on ASCII art than actual readability https://github.com/tromp/cuckoo/blob/master/doc/spec and as https://handshake.org/files/handshake.txt points out, cannot be easily adjusted in difficulty. Also, I would need to implement it from scratch, but I guess I'll have to do that anyway.\n\nNon-Solution #9: \"Just use the search function!\"\nWhy not: Only yields https://www.reddit.com/r/crypto/comments/7n2exi/what_are_the_current_viable_options_for_a_good/ , all of which I handle here.\n\nNon-Solution #10: Busy Beaver (64kb random instructions) https://denisbider.blogspot.com/2015/05/busybeaver-key-derivation-function.html\nWhy: Has a public JS implementation, neat!\nWhy not: Not well-documented, only available as a zip, or I could rip it out of this (abandoned?) repo https://github.com/denisbider/Atomic , apparently hasn't really been cross-checked by anyone it seems.\n\nNon-Solution #11: \"Egalitarian computing based on Argon2\" https://www.usenix.org/sites/default/files/conference/protected-files/security16_slides_biryukov.pdf\nWhy not: I really don't want to use 2 GB of RAM on the server to verify it. See above: The attacker can just spam me with invalid \"proofs\". Also, the \"specification\" is a single powerpoint slide, and not what I would call \"well-defined\".\n\nNon-Solution #12: https://www.cs.utexas.edu/%7Ebwaters/publications/papers/outsource_paper.pdf\nWhy: Acknowledges that the puzzle itself is also attack surface.\nWhy not: \"Just put it on a different server\" just moves the problem, instead of solving it.\n\nSo, can someone suggest a memory-bound \"trapdoor-ish\" proof of work?", "post URL info": ["https://en.wikipedia.org/wiki/Memory-hard_function#Motivation", "https://eprint.iacr.org/2005/356.pdf", "https://stackoverflow.com/questions/26821310/is-there-a-memory-bound-proof-of-work-concept-for-use-in-javascript", "https://github.com/tromp/cuckoo", "https://github.com/tromp/cuckoo/blob/master/doc/mathspec", "https://github.com/tromp/cuckoo/blob/master/doc/spec", "https://handshake.org/files/handshake.txt", "https://www.reddit.com/r/crypto/comments/7n2exi/what_are_the_current_viable_options_for_a_good/", "https://denisbider.blogspot.com/2015/05/busybeaver-key-derivation-function.html", "https://github.com/denisbider/Atomic", "https://www.usenix.org/sites/default/files/conference/protected-files/security16_slides_biryukov.pdf", "https://www.cs.utexas.edu/%7Ebwaters/publications/papers/outsource_paper.pdf"], "author": "raelepei", "ups": "19", "downs": "0", "number of comments": "60", "comments": ["How about you circle back to the need of being unauthenticated?\n\nYou're setting yourself up for some pain using an overly complex scheme here. A cannon to kill a fly.", "That's a different option I've seen, called network puzzles. Use round-robin servers whose only purpose is to direct the client to the next server in a sequence, they can only connect to the final server if they have followed the sequence (the redirects would supply the client with single use tokens).\n\nThis puts a latency bound and a bound on simultaneous connections on the end user and/or attacker.\n\nhttps://en.m.wikipedia.org/wiki/Guided_tour_puzzle_protocol\n\nFor \"trapdoor PoW\" the closest thing is VDF:s, verifiable delay functions. Many different constructions exist, not all have well defined security analysis. You have to search the term and see what each variant offers. In general, they're slow to solve and quick to verify.", "Do you actually have a problem that you're trying to solve? Like you actually have an API that for some reason needs to be unauthenticated and serve a lot of users with shitty smartphones? Or are you just asking a pseudo-academically?\n\nThe vast majority of the time, it's best to find a solution that works in practice (for the specifics of your actual problem) then to find an abstract solution to the whole class of 'similar' problems.", "How about an [RSA time-lock puzzle](https://people.csail.mit.edu/rivest/pubs/RSW96.pdf) with a small-ish number of squarings? It's not memory-bound, but it also can't be done in parallel.", "A bit late, but here's an idea:\n\n1. Get the prover to set aside some amount of memory (1 gigabyte for example)\n2. Get them to split it into chunks, then construct a merkle tree from it, then send you the merkle root\n3. Request 40 random chunks, along with merkle proofs for them.\n\nIf they store only 90% of the data, there is only a 1.5% chance you won't select a chunk belonging to the 10% they didn't store (0.9^40 \u2022 100), and a 0.01% chance you won't detect of if they only store 80%.\n\nMight want it to be smaller than 1 gigabytes come to think of it. At 256 megabytes, they'd only be able to have 64 connections if they had 16 gigs of ram.\n\nEdit:\n\nCould also force them to store for a period of time, say 10 seconds, by requesting new chunks every so often (maybe every couple seconds) to prove they still store it. This way, that 256 megabytes of their ram can only be dedicated to one connection at once.", "Add lightning payments. The user is putting load on your server. They need to pay for what they use. Works on mobile, etc. You don't need a payment for every API call. Can just issue a token with however much credit they purchased and consider it valid until they run out of credit.", "Maybe something inspired from proof of erasure might help?", "The entire goal is rate limiting, so why not just skip all the complicated solutions and... implement rate limiting?\n\nWhen you receive a request, throw the requester's IP address into a db with a timestamp. If it already exists with a timestamp that is too recent, deny the request. If you want to get fancy, you can add some kind of counter so they can make a small number of requests in quick succession but then need to hold off a bit. If you need to reclaim some memory, pruning the db is super easy.\n\nNo authentication, no hashing.\n\nIf an attacker is willing to spin up a large enough number of ip addresses to hit you, they can just as easily get that many machines doing hashes and hit you.", "[deleted]", "And/or use some DoS protection service like cloudflare in front of the API.", "Because that only moves the problem: The rest of the service is unauthenticated, so I would add on an entire signup, login, and account management service. And that's only the beginning! So now I have authenticated users that might DoS the service. Then I'd need to implement rate-limiting, automatic bans, cross-account association, and something to prevent mass-signup.\n\nHow is this *not* a cannon to kill a fly? Nah, I'll stick with PoW.", "Guided tour puzzle: Nice idea, but sadly I don't have a geographically-distributed system of servers. I only have a single server, and just want to make it significantly more difficult to overload it.\n\nVDFs: Awesome! I'm now reading up on it, thanks :D", "Yep! I want to write a free service thing. Admittedly, the \"shitty smartphone\" might be an overstatement, but there's still the issue of tuning the PoW hardness. So originally I was about to go with CPU-bound PoW, and some kind of attempt to detect how much load the server is on, and automatically adjust the PoW hardness based on that.\n\nHowever, I wanted to explore what other PoW-options there are, and after a while noticed that I can't find any \"good\". And thus this post was born.\n\nIn case you're curious: I'm currently reading up on VDF, RSA puzzles, and all the other great suggestions. Admittedly, yes, I'm a bit of an academic at heart, and was originally hoping for a one-size-fits-all solution, and created this post when I realized that doesn't exist. :D", "+1 for this, you also get a trapdoor feature baked in with Euler's phi function if I recall correctly", "Awesome! That looks very useful!\n\nThis is still CPU-bound, but as you said it can't be solved in parallel. I'm still trying to wrap my head around other VDFs, but these time-lock puzzles are so simple even I understand them. (So there's a chance that the bugs I'll introduce aren't too bad.)", "Sure, I'll just add an authentication mechanism to this *unauthenticated* API call, and also ask users to trust me with their money. Excellent suggestion, not.", "Doesn't proof of erasure require exact knowledge of the client hardware?", "Great idea! If only I had some form of user ID to bunch all requests together and ratelimit the right user \u2026 ;)\n\nDepending on the PoW, the verification can be less load than querying/updating stuff in a database. Hence why I'm really trying to figure out whether such a PoW scheme already exists.\n\nUsing IPs for that purpose is a known-bad idea. Proxies exist, so attackers can just switch routes every few seconds. At the same time, this hurts legitimate users who happen to get the same IP after a reconnect (some ISPs reuse IPv4 addresses quite quickly).\n\nFinally, where I live, IPs are considered PII, and thus I would need to read up on all the legal stuff surrounding that topic. (Personally, I don't consider this a breach of privacy; but I can see that this comes close.)", "Thanks for the link! It appears that he discusses partial hash inversion (see \"Non-Solution #1\"); and later Guided-Tour Puzzles (which are nice, but I don't have that kind of resources available).", "How is \"just use a third-party that logs all your traffic and invades the users privacy\" better than \"use a simple PoW, similar to partial hash inversion\"?", "My advice would be write the service and then spam proof it when it actually starts getting spammed. IP blacklisting will take you pretty far.", "\"I want to give away stuff for free but prevent people from abusing it\"\n\nYOU CAN'T, THAT IS WHAT MONEY IS FOR. All this \"proof of work\" gymnastics isn't going to cut it. You've already discovered this but you think there's some magic crypto solution. There isn't!\n\n> I'll just add an authentication mechanism to this unauthenticated API call\n\nHow is what I suggested \"authentication\" in any way? It's just payment. No usernames or passwords or registration. Having to include a payment is no more a hurdle than including proof of work.\n\n> also ask users to trust me with their money.\n\nI don't think anyone is going to worry about losing a whole five cents.", "It does if your end goal is to erase the clients storage. In this case i think it could be adapted to consume (say 1GB of) the clients ram. Exact specs wouldnt be needed", "You just have to assess the likelihood of each type of attack and act accordingly. If the chance that someone will spoof IP's just to attack you is low, then my solution should be fine. If there's a high chance they will spoof IP's but a low chance they will purchase PoW power, then just use hashcash.\n\nIf there's a high chance they will do both types of attacks, then you have no choice but to do the extra work to implement an authentication system. Sometimes it's simply not possible to be lazy and also provide the perfect solution you want.", "There's other services ***like*** Cloudflare; and if PoW actually *was* simple we wouldn't have this discussion, would we? It's been proposed for longer than blockchain exists (e.g. PoW for emails to prevent spam in the early 00s), and always failed because it's more complicated than it looks like at first glance.", "Literally all solutions like time-lock puzzles or PoW or cloudflare require quite a while to set up, and I don't like the idea of giving TheInternet\u2122 such a huge headstart.\n\nEDIT: This feels a bit like \"write the service and then implement password verification when you notice accounts are getting 'hacked' in practice\". Well, no, it's too late by then.", "All proof of erasure schemes I've seen relies on the client filing ALL available storage space, and proving it's been filled by proving it stores all X bytes of pseudorandom data, where X must match storage space. Erasure is then inferred from it being impossible for the client device to still have the original data stored when all storage is ~~probably~~ provably filled by something else. This requires knowing how much storage space the client has.", "Other services **like** Cloudflare have the same disadvantage of being a service like Cloudflare: Invade the user's privacy, involve a third party, instead of solving the problem locally.\n\nAnd I already argued why Hashcash is a good idea, and nearly fits the bill here. (Because I don't have the same problems that mailing lists do.)", "For almost any product, if you're working on your 2-factor system before launch, you're putting you energy in the wrong place. By the same token, if you're product has traction and has been in market for a year and your still using the auth/auth system you launched with we either over-built before launch or need to revisit it. \n\nBut by all means, don't let me stop you from building an elegant masterpiece before verifying that it's something people want.", "That's an academically interesting idea! However, I don't quite see how this is a proof of work? :P", "I think they meant using the proof of storage part. It does require temporarily spending RAM or disk space (X bytes of proven storage) once per connection / client."]}
{"id": "oxtr9b", "title": "Invertible Discrete Functions", "url": "https://www.reddit.com/r/crypto/comments/oxtr9b/invertible_discrete_functions/", "Created (UTC)": "2021-08-04 07:23:44", "body": "I am interested in studying *Invertible Discrete Functions*, i.e. I am interested in functions which compute discrete outputs given discrete inputs **and** are (*easily*) invertible. E.g.\n\ny = (a + b \\* x ) mod K\n\nif b and K are coprime and x is a natural number.\n\nThis is a very simple example. Therefore, I am curious if you know other functions/algorithms or can point me to source where I can continue searching?\n\nThanks in advance!", "post URL info": [], "author": "arcxtriy", "ups": "7", "downs": "0", "number of comments": "40", "comments": ["You could also check with math subreddits.", "some ideas:\n\n* any block ciphers are invertible\n* chacha core is invertible if you omit the addition\n* aes s-boxes are invertible\n* keccak-p is invertible, although the inverse is more expensive to calculate", "A keyword to search for would be \"permutation polynomials\"", "a^x mod p   for prime  p .\nTo invert, we just need y such that x*y = 1 mod p-1 .\nSimple modular inverse.  \nIf we call b = a^x mod p, then b^y = a mod p .", "Thanks, will do that!", "Maybe have a look at the symmetric group of a finite set, which is the set of all permutations that can be done over the elements in the set"]}
{"id": "oxz94p", "title": "Keepass refuses to let me input manual input for additional entropy", "url": "https://www.reddit.com/r/crypto/comments/oxz94p/keepass_refuses_to_let_me_input_manual_input_for/", "Created (UTC)": "2021-08-04 11:39:26", "body": "Hi, I have downloaded this software called Keepass version 2.48.1, to store passwords in an encrypted master file, but it also has a nice feature of generating supposedly random passwords where you can customize how long, which characters appear, and so on.\n\nThe problem is I want to use additional entropy by moving the mouse manually so im not trusting 100% the CPU RNG capabilities. It all adds up so why not use it. Problem is it is greyed out.\n\nPlease try opening Keepass and in \"Tools -> Generate Password\", there is at the bottom an option that says \"Show additional dialog for collecting user input as additional entropy\" but it shows up as greyed out for me. Can someone tell me why is that?", "post URL info": [], "author": "cryptomann1", "ups": "0", "downs": "0", "number of comments": "29", "comments": ["[deleted]", "Shameless plug, but my web-based and CLI-based password generators both ship with entropy collectors. You *should use your password manager for password generation*, but this might be an acceptable alternative.\n\n* https://github.com/atoponce/webpassgen (open in your browser)\n* https://github.com/atoponce/nodepassgen (run in your terminal)", "works for me on 2.48.1 (64-bit)", "If you are running Keepass on Linux, you could add your entropy by writing it to /dev/random directly.", "How do I enable it?", "Hello downvotes. Heh.", "Im using the same version. Are you on linux or windows?", "I would really like to use the mouse thing, it's just cooler. But why it wouldn't work? it works for veracrypt. Also uses this system.", "Something something cryptography in a browser", "Anything on Linux that uses the kernel to get randomness (i.e. basically everything) gets randomness from the mouse already. When you open Keepass, all the entropy you could ever need is already available.", "The command line version doesn't run in the browser, and the browser version should be executed in file:// not https://", "But I would like to know why its greyed out for me and not for other people."]}
{"id": "ox0sll", "title": "Demystifying recursive zero-knowledge proofs", "url": "https://anoma.network/blog/demystifying-recursive-zkp/", "Created (UTC)": "2021-08-03 03:40:53", "body": "", "post URL info": [], "author": "minbunny", "ups": "36", "downs": "0", "number of comments": "43", "comments": ["Recursive zero-knowledge proofs are new cryptographic primitives relevant to the Anoma blockchain use case. In this article from our R&D team, Simon investigates the possible alternatives for verifying blockchain circuits efficiently. Our main interest is in estimating the efficiency of pairing-based constructions.\n\nIf you'd like to stay updated with Anoma, we will let you know as soon as anything new comes out on our [Twitter](https://twitter.com/anomanetwork), [Discord](https://discord.gg/RzN98vXbFt), or [Telegram](https://t.me/anomanetwork). Feel free to ask our team questions about their research too!", "Blockchains based on zk-proofs are very interesting to me because they allow you to verify an entire blockchain history by just downloading the latest block, and without re-doing all the work. That is pretty impressive. But they're not that useful when it comes to storage, right? Right now, the most expensive opcode in Ethereum is SSTORE, so an hypothetical blockchain based on zk-proofs would have comparable costs for permanent storage. Correct?", "I was good up until they got into the arithmetic.", "are there academic papers who look at the security of the recursive ZKProofs? \n\nthis sounds like some cooked up *coin-stuff...", "Why not make a subreddit too??", "While that's true, succinct blockchains work nicely with stateless storage schemes. We wrote about this [here](https://mirprotocol.org/blog/Reducing-state-size-on-Mir).\n\n(As we mention near the end, traditional chains can also use stateless storage, but it doesn't work as well. Validators need account data in order to re-execute transactions, so either they need to store it or it needs to be gossiped as part of a transaction. With succinct chains, validators simply don't need to access account data.)", "That's because this isn't a shitcoin subreddit and you're an anti-vax piece of shit", "Hey! I get it. \nI've asked the author, Simon, and he suggested this article here as \"state of the art\" for this topic: https://eprint.iacr.org/2020/499.pdf", "We actually do have one, I think it's /r/Anoma, but it's still quite early in the project and we haven't seen the need for reddit just yet. We're mostly on Discord, Twitter and Telegram for now for pre-launch community building.", "[removed]", "Please mind the tone", "You gotta love the guy who blocks you to insulate themselves for their own willful ignorance.", "In this sub the members are supposed to both act friendly and to follow science, FYI.", "I tried, but anti-vax covid hoaxer happened", "sure. Not sure what \"science\" you are referring to. The post is about zero-knowledge proofs. I hope you are talking about that science.", "All kinds of science. If you want math to be correct here for people's safety, you should want the math to be correct for people's safety in other fields too", "> All kinds of science.\n\nThis sub is about crypto, correct? This post was about crypto. What does \"all science\" have to do with people's safety? What does this post have to do with \"people's safety\"??? WTF?? It's math. This sub is about cryptography news and discussions. \n\nWhere does \"people's safety\" fit in to cryptography? I'm so lost right now.", "Cryptography is a scientific field for the purpose of safety (of information, in extension of people).\n\n(in response to the comments about medical science)", "[Cryptography is a method of protecting information and communications through the use of codes, so that only those for whom the information is intended can read and process it. The prefix \"crypt-\" means \"hidden\" or \"vault\" -- and the suffix \"-graphy\" stands for \"writing.\"](https://searchsecurity.techtarget.com/definition/cryptography)\n\n[In *computer science*, cryptography refers to **secure information and communication techniques derived from mathematical concepts and a set of rule-based calculations called algorithms, to transform messages in ways that are hard to decipher**.](https://searchsecurity.techtarget.com/definition/cryptography)"]}
{"id": "owvayf", "title": "PASETO Reference Implementation Release Notes (new protocol versions)", "url": "https://github.com/paragonie/paseto/releases/tag/v2.0.0", "Created (UTC)": "2021-08-02 20:52:11", "body": "", "post URL info": [], "author": "sarciszewski", "ups": "18", "downs": "0", "number of comments": "27", "comments": ["This is the release notes for version 2.0.0 of the PASETO reference implementation.\n\nThe [rationale for V3/V4](https://github.com/paseto-standard/paseto-spec/blob/master/docs/Rationale-V3-V4.md) may be of particular interest for this forum.", "Has anyone questioned the situation around using Blake2b, which is based on Chacha20, as a hash for data encrypted with (X)Chacha20? I appreciate it ticks the boxes but I can't shake a feeling too much Chacha in one picture.\n\n(There's probably nothing in this question.)", "That's a good question.\n\nI think the security record of ChaCha8 against all known attacks is pretty damn good, let alone ChaCha20. It has sufficient diffusion even in reduced rounds that its PRF security should not be implicated.\n\nA BLAKE round is analogous to two ChaCha rounds. BLAKE2b is 12 rounds, which is analogous to a hypothetical ChaCha24.\n\nIf we ever discovered some spooky interaction between ChaCha20 and BLAKE2s (which uses 10 rounds and is analogous to ChaCha20), that would be a very interesting result, but it wouldn't directly apply to BLAKE2b.\n\nFinally, how the quarter round function is used in ChaCha versus [BLAKE2b](https://en.wikipedia.org/wiki/BLAKE_(hash_function)#Mix) is subtly different: BLAKE2b has an additional message mixing permutation called [SIGMA](https://datatracker.ietf.org/doc/html/rfc7693#section-2.7).\n\nThe round disparity and the additional tweaks inside BLAKE2b's construction makes it unlikely that an interesting interaction caused by \"too much ChaCha\" would result in any real-world breaks. (Unlikely, but not impossible.)"]}
{"id": "ovvlbm", "title": "Signing HTTP Messages (Internet Draft)", "url": "https://datatracker.ietf.org/doc/html/draft-ietf-httpbis-message-signatures-05", "Created (UTC)": "2021-08-01 09:46:50", "body": "", "post URL info": [], "author": "rgneainrnevo", "ups": "25", "downs": "0", "number of comments": "41", "comments": ["Interesting. At a previous job we made heavy of use client-certificate authentication. Our code would programmatically grab the client cert to do further security checks (e.g., lookup user, perform authorization, etc). This all worked really well for our needs. \n\nThen, when AWS started giving out free publicly trusted TLS certificates on their load balancers (and doing all the cert management like renewal on our behalf) we really liked that. Problem was, if we terminated TLS at the load balancer we couldn't see the client-certificate in our code anymore and all the authorization checks would fail. Unfortunately, the [proxy protocol](https://www.haproxy.com/blog/haproxy/proxy-protocol/) didn't have much that could help us here either (I have read somewhere that it supports a way to send the client cert's CN, but AWS doesn't support it). \n\nIn order to get the best of both worlds, we wrote our own form of HTTP signatures which allowed us to send the client cert and signature info as part of the HTTP payload but still get the benefit of AWS' free TLS (we were able to do this because we had custom clients and weren't reliant on a standard web browser). A standard like this would have helped back then. Who knows how many implementation (or, even worse, design) mistakes we made.", "i truly don't understand why this is being done at the HTTP layer instead of at the application layer. http layer authentication has an extremely poor record of deployment and for good reason: it takes UI decisions out of the hands of the app and gives it to the browser. i get that it allows http headers to be signed too, but to what end? if you can't trust your infrastructure beyond where TLS is terminated you are already in a world of hurt. \n\nthe analog here is email/DKIM. there are very good reasons that it makes sense to authenticate at the domain level and email message layer, namely that email can transit multiple different domains before arriving that at the receiving domain. http doesn't have that property.\n\nas one of the authors of RFC 7486, we explored this about a decade ago. that (experimental) RFC was really two approaches: one at the HTTP layer and one at the application layer. my part was the application layer approach but i always found the HTTP layer approach implausible. the reason we came together was to highlight the problem space though which is that passwords are a completely mess.", "Posting this here because I've recently stumbled across this and found it interesting.\n\n(If anyone else's first instinct was to question RSA and ECDSA in a spec but no Ed25519, see https://github.com/httpwg/http-extensions/issues/1509)", "i wish people weren't so slavishly indoctrinated about certificates. you can use TLS with naked public keys and just enroll them. logging in with a name and public key completely gets rid of the need to deal with certificates at all and the there is no need at all that it be at the TLS layer which is poorly supported.", "HTTP just IS an app layer protocol these days. See all the REST APIs that proliferate.\n\nTurtles all the way down.", "What do you mean \"HTTP layer\" and \"Application Layer\"? Are you thinking about the internet in terms of the OSI model with some extra layer tacked on for HTTP? The 4-layer TCP/IP model pre-dates the OSI model by about 10 years, and the OSI model was an attempt by ISO to standardize how networks should work, not how they actually do work (in 1984). The IETF went happily along using the TCP/IP model, and everyone except universities ignored ISO's crappy model. The only real issue with the TCP/IP model is that it includes TCP in the name, even though that can be replaced by UDP and the model still works.\n\nLayers:\n4: Application Layer (Application/Session/Presentation layers from OSI, includes HTTP, NTP, DNS, etc)  \n3: Host-To-Host layer (TCP/UDP here)  \n2: Internet Layer (roughly the Network layer from the OSI model, IP, ARP, ICMP, etc)  \n1: Network Access Layer (Data-Link/Physical layers from OSI)", "> you can use TLS with naked public keys and just enroll them\n\nWe discussed this but the enrollment process was the challenge. If we only had a mostly static set of users then this would be fine. But with new users joining relatively frequently and assuming users would lose their keys from time to time, we wanted something more scalable. Using certificates allowed us to piggyback off our CA's existing enrollment process. \n\n> logging in with a name and public key completely gets rid of the need to deal with certificates at all \n\nI see what you mean but then we have to implement our own revocation process and handle revocation checks ourselves. By using certificates, we can piggyback off the revocation capabilities of our CA and the checking provided by the web server stack. \n\n> there is no need at all that it be at the TLS layer which is poorly supported\n\nInteresting perspective but we had a different opinion. Mutual TLS is pretty well supported amongst the various web servers and load balancers (proxy protocol issue aside) and so if we had to change our tech stack we could do so without impacting the authentication method. Also, by doing it at the transport layer we didn't have to do much in our code from an authentication perspective. Lastly, TLS already handles replay attacks which we didn't want to deal with ourselves. \n\n**Edit** Added replay attack comment.", "i don 't mean it in the OSI sense. i meant that apps want to control the UI experience of logging in, etc. for a browser that happens with html, etc", "i'm talking about at the html layer for websites . sites want to have control over the UI of their login mechanisms and for good reason. Basic Auth is a clunky and unacceptable UI experience. i'm not sure of the actual details of how this draft would work UI'wise but there's it's a good reason to be suspicious of how the app would interact with the browser (with Basic the answer is simple: it doesn't). \n\nit also seems to me to overkill to sign every client message. secure session cookies are used and don't seem to be a major source risk from anything i've heard.", "the problem as always is the client side. because vanishingly few people do it, browsers don't care. plus it's at the wrong layer manifestly because nobody wants to allow the browser to control the UI experience, or lack thereof. i mean, browsers have Basic and Digest which is used almost nowhere.\n\nit's really easy to just enroll naked public keys the same way that you enroll new devices these days: require that users enter an otp or click on a url to permit a new device with its own unique public key that it self-generates. revocation is as simple as finding the public key in the server database and deleting it. you don't complicated CRL's or OCSP or anything like that. it's completely analogous to revoking a password that has been compromised requiring a new one.\n\nlike i said, people get wrapped around the axle trying to make it work with a certificate model when certificates are not needed except in microscopic set of problems where offline verification is required.\n\nyou can see what i mean here about certs:\n\n[https://rip-van-webble.blogspot.com/2021/03/certificates-confuse-everything.html](https://rip-van-webble.blogspot.com/2021/03/certificates-confuse-everything.html)\n\nand here about how to build a login mechanism with WebCrypto:\n\n[https://rip-van-webble.blogspot.com/2020/05/hoba-revisted-with-webcrypto.html](https://rip-van-webble.blogspot.com/2020/05/hoba-revisted-with-webcrypto.html)", "i'm not sure how they are handling replays but i assume it's time based because you wouldn't want to have a round trip for a nonce. there may be ways to feed it a stream of nonces though but with ntp all over the place, that seems like a lot of work for little gain."]}
{"id": "ovmso8", "title": "You Really Shouldn't Roll Your Own Crypto: An Empirical Study of Vulnerabilities in Cryptographic Libraries", "url": "https://arxiv.org/pdf/2107.04940.pdf", "Created (UTC)": "2021-07-31 22:57:51", "body": "", "post URL info": [], "author": "ScottContini", "ups": "52", "downs": "0", "number of comments": "45", "comments": ["tl;dr: lots of stats on CVEs present in the 8 biggest crypto libraries that are opensource and written in C or C++. Notable results include the fact that more issues are due to C/C++ bugs (37%) than crypto bugs (27%).\n\nI really dislike the title of this study. Using one of the biggest libraries is the exact opposite of \"rolling your own crypto\". Given the title I would have exepected a study on the large number of people that do roll their own crypto rather than use a well-maintained and well-studied library, but it's specifically not about these. \n\nThe results are interesting to an extent, but I also find that it stoped too short: if you select *only* C/C++ libraries and find that most issues come from C/C++ (which we all know are difficult languages to get right) then I'm really interested in cryptography libraries written in other languages: how many vulnerabilities are cryptographic then? And what type of cryptographic errors are the most prevalent? Just knowing a proportion isn't that helpful.\n\nFurthermore the title suggests that writting cryptographic code is hard but the conclusion is that many more vulnerabilities in C/C++ code come from C/C++? Then, given that these are cryptographic libraries, it sounds like the maintainers were actually pretty good at writting cryptographic code. Which I\u00a0realize is a very debatable statement given that there's still 27% but I'm trying to emphasize how seemingly unrelated to the title the main conclusion is.\n\nNow I'm not saying that the study is bad, things like the study of the impact of code removal and exploitability lifetime are great, but the title doesn't adequately reflect the study IMHO and by focusing only on C/C++ libraries it sometimes turns into another C/C++ vulnerability study rather than a cryptographic one and we've had plenty of those. Confirming those results in the case of a cryptographic library is interesting, but it's not really what they seem to have set to do at first.", "This isn't \"rolling your own crypto\" though...? Rolling your own crypto is like coming up with an idea for a cipher or a construction with little education or experience in the area. Don't build your own bridge either, unless you're a bridge engineer.\n\n\nThe notion is that you \"shouldn't roll your own crypto\" by implementing anything yourself, and, instead, use complex libraries with features you will never need or even know to guard against misuse.  \n\n\nThe issue is large, complex code bases (>30k LoC), with a small base of largely unpaid developers, with every algorithm and interoperability option thrown together.  This is why the Internet of Things lacks security. Try putting OpenSSL on a 50 MHz Cortex-M0.  Doesn't fit? Well let's just leave all communications in the clear because you shouldn't \"roll your own.\" This is a toxic gatekeeping mindset that is holding security and privacy back.", "This is a pdf link.  More info here: https://arxiv.org/abs/2107.04940", "Hang out on r/codes and see the cheese that gets posted, day in, day out.", "[removed]", "Happy cake day!", "[removed]", "[removed]", "[removed]", "Agree with this.\n\nThere's vulnerability in crypto, there's vulnerability in implementation.", "Agreed, it would be worth having a full picture of cryptographic vulnerabilities in all languages, especially now with many companies using Rust for security based implementations.\n\nOne conclusion in the paper is bit unsettling: \\`Our findings support the common intuition that it is dangerous to maintain excess amounts of C or C++ source code, and particularly so in cryptographic software\\`. As using less-excess amount of C, CPP code might lead to use of underhand libraries/snippets...", "This subreddit is about cryptography, not cryptocurrency", "Stop spamming", "This subreddit is about cryptography, not cryptocurrency", "This type of spam is illegal under US and EU law, you should delete these posts.", "[removed]", "Don't beg"]}
{"id": "ouh4mb", "title": "Canonicalization Attacks Against MACs and Signatures", "url": "https://soatok.blog/2021/07/30/canonicalization-attacks-against-macs-and-signatures/", "Created (UTC)": "2021-07-30 02:08:52", "body": "", "post URL info": [], "author": "Soatok", "ups": "31", "downs": "0", "number of comments": "45", "comments": ["This is yet another case where C-style null-terminated strings are worse than Pascal-style length-prefixed strings. It's also one of the few things ASN.1 gets right.", "Nice write-up! If I could offer a bit of constructive criticism, I personally would've enjoyed a graphical representation of the example you gave (with the HTTP request) as well as of the PASETO/DSSE definitions of PAE. But that could just be me. But aside from that, I very much appreciate the write-up for covering something which I've always had some trouble spotting in the wild.", "One of the nice things about SIV is that it defines a very efficient general way of converting a MAC that takes a single input into one that takes an arbitrary number of inputs (up to some limit): https://datatracker.ietf.org/doc/html/rfc5297#section-2.4\n\nThis is more efficient than adding length prefixes. Some time ago I wrote a draft describing how to extend this to MACs with tags greater or lesser than 128 bits: https://datatracker.ietf.org/doc/html/draft-madden-generalised-siv-00#section-2.3\n\nYou can do something similar by adapting ECBC or NMAC designs. These are typically used to adapt a fixed-input PRF to variable-input, but if you apply them to a PRF that is already variable-input then you get a PRF over a vector of inputs. Neat.", "I'm not sure I would have called it canonicalization attack though... I get what you're going for with the idea that different inputs give the same end result but you lack an actual canonicalization step.\n\nNow, as what name would be better... Input confusion attack maybe? I'm not satisfied with that either.", "I've never heard this called a canonicalization attack before, and it's\nnice to have a name for the concept. At first I couldn't see how the term\napplied. The other context where I see the term has to do with canonical\npaths or Unicode normalization. Taking a broader view: a *canonical form*\nis \"unique representation\" (i.e. no collisions), so it's easy to see how\nit applies here. Thanks!", "If I understand correctly, you could also encode IV, ciphertext, and additional authenticated data as e.g. JSON to mitigate this issue right (as long as the JSON output is stable)? Even if it may not be as efficient.\n\nFundamentally, looks like this is about being able to safely deconstruct a combined output value into its individual input components, without allowing the (untrusted, potentially malicious) input components to \"break out\" of the encoding scheme. Same principle as with SQL injection, XSS or why quotes are escaped in JSON, so clearly very relevant outside of cryptography :)", "[removed]", "[removed]", "Maybe comes from xml c14n?", "Not just decoding them individually, but doing it unambiguously (deterministically) as well.", "On every single post?", "This type of spam is illegal under US and EU law, FYI.", "i imagine i've missed a few, but who knows"]}
{"id": "ou9j8h", "title": "Nick Szabo's Essays, Papers, and Concise Tutorials - A Modern Crypto OG", "url": "https://archive.ph/20150812055200/http://szabo.best.vwh.net/", "Created (UTC)": "2021-07-29 17:02:26", "body": "", "post URL info": [], "author": "None", "ups": "8", "downs": "0", "number of comments": "23", "comments": ["Wrong crypto bRozo", "While Nick Szabo is very involved with cryptocurrency, he approaches it with from the fundamentals of cryptography and has compiled some resources regarding both. I thought it was a great resource that should be included here. Here are a few of his works to show the value that I saw:\n\n[https://archive.ph/Li94y](https://archive.ph/Li94y)\n\n[https://archive.ph/e68wG](https://archive.ph/e68wG)\n\n[https://archive.ph/i0OYc](https://archive.ph/i0OYc)"]}
{"id": "ouk28q", "title": "The last refuge of the criminal: Encrypted smartphones", "url": "https://www.politico.eu/article/the-last-refuge-of-the-criminal-encrypted-smartphones-data-privacy/", "Created (UTC)": "2021-07-30 05:55:46", "body": "", "post URL info": [], "author": "a_titkov", "ups": "0", "downs": "0", "number of comments": "40", "comments": ["I don't think regulating encryption is a good idea.", "I heard they're working on a follow-up article, working title: \"The last refuge of the criminal: The laws of physics.\" Abolish them now!", "Criminals: Oh no, we can no longer commit crimes involving encryption because we'd have to break the law to do so.", "Posting this opinion piece by the executive director of Europol to raise a discussion about the topic of cryptography regulation", "Let's presume (for the sake of argument) that this comes to life. The contents of devices, messaging services etc become accessible to the law enforcement.\nWhat stops criminals from layering extra encryption on top of that? It feels like this change will only affect law-abiding citizens.", "Wow what nonsense. In these cases it's not tech industry that's dictating access to data, it's the user dictating their access to their data. That's just the reality.", "Honest opinion? Fuck this and the horse it rode in on. Never listen to or respect anyone who says shit like this.", "The last refuge of criminals after this \"last refuge\" will be meeting up in person and having quiet conversations. Better put a microphone on every street corner and in every pub, it'll help solve crimes.", "LEO has been skirting privacy laws for decades and now they want to edge in on encrypted phones?  FUk 'em.", "What about encrypted computers? Are they saying they can get into those? Because I can encrypt my computer if I wanted to, and send encrypted messages from there.", "It's a horrible idea that will backfire completely. Unless they want foreign actors to have free access to all EU data.", "Notice he doesn't even suggest anything. Just that encryption needs to be \"regulated\" whatever that means, while somehow retaining \"privacy\". These people don't have any ideas that aren't just key escrow or \"hidden\" backdoors.", "> I don't think regulating encryption is a good idea.\n\nLike hell how do you \"regulate\" research crypto is one of those area's where one can make advancements without direct funding or support", "Governments are often bigger criminals than ordinary citizens.", "The answer to your question is, convenience. It is harder to layer your own encryption on top of an existing messaging app. How are you going to encrypt on your smartphone without the help of an app anyway?\n\n(Note that I still hate the message of this article and support free encryption for all. But your argument is the same one that opponents of gun control make, that \"then only criminals will have guns\", ignoring the proven fact that gun control laws work by making it harder to obtain weapons, and thus raising the price and reducing the supply.)", "> It's a horrible idea that will backfire completely. Unless they want foreign actors to have free access to all EU data.\n\nThis tbh"]}
{"id": "otruqd", "title": "Considerations and Implications of Publicly Available Ciphertext at-rest", "url": "https://www.reddit.com/r/crypto/comments/otruqd/considerations_and_implications_of_publicly/", "Created (UTC)": "2021-07-28 23:14:12", "body": "This is partially related to the _application_ of cryptography, which calls into question whether or not this post breaks the last rule of posts not being related to Systems that _use_ cryptography. If it does, I apologize.\n\nIn a system I'm developing, the database is publicly accessible by design. Aside from using strong encryption and hashing algorithms, like SHA3-512 and AES-128, are there other implications/considerations to making this ciphertext publicly available?\n\nMost systems have layers of security that include things like access-control that help ensure that the ciphertext isn't available publicly, outside of maybe a breach of some sort. However, I'm also fully aware that ciphertext is often readily available during transportation, like over VPNs, Secure Tunnels (TLS), etc. But this isn't the same as data at-rest being publicly available.\n\nCurrent considerations include:\n\n- Generating AES IVs each time the data is encrypted and storing it alongside the encrypted data (I've been told storing the IV in plaintext is not an issue, even for KPA)\n- Ensuring keys are strong and stored securely themselves (incl. ensuring that encrypted Master Keys have strong passphrases if their ciphertext is publicly available, or securing the encrypted Master Keys privately)\n\nObviously, this has nothing to do with the End User application or good/bad implementations of algorithms in libraries. This is mainly related to the security implications of making available and distributing publicly ciphertext at-rest. Are there serious concerns here that would make this a particularly unwise thing to do? My gut tells me yes, but I haven't yet explored all possible scenarios.", "post URL info": [], "author": "Norpyx", "ups": "13", "downs": "0", "number of comments": "47", "comments": ["Since we're discussing the practicalities and not technical then lets review the ecosystem. At present this is a big question within the blockchain/dApp space. One that has, in my option, not been fully addressed.\n\nNow that said; the DNS space has a effort already to address this same question since the introduction of dkim and dnssec. Thier answer, as one can see in implementation and rfcs, is the hash is safe for transport and at rest while the keys are a protected item.  \nTherefore  one can infer the general consensus seems to come down to one thought; \"SHA\\* is for hashing, not encryption. No one can 'decrypt' something from a hash.\".  \n\n\nThere is a larger discussion about this at the technical level over at [https://github.com/ipfs/notes/issues/270](https://github.com/ipfs/notes/issues/270).   \n\n\nBut yes, generally in the high level a hash is a hash and any risk really is at the implementation algorithm (e.g. timing, key size, metadata inference, padding, etc.) than the hash itself.", "> ... are there other implications/considerations to making this ciphertext publicly available?\n\n\nHaving the ciphertext available to an attacker (e.g. publicly available) is a basic assumption in most crypto systems. So that isn't new or novel. Make sure to look at existing crypto systems for ideas.\n\n\nHowever cryptography is hard. You will want to make sure your system is [semantically secure] (https://en.wikipedia.org/wiki/Semantic_security). One thing to watch out for is the amount of entropy in the plaintexts being encrypted. This is often how password hashes are cracked and how [Skype can be listened in on](https://www.securityweek.com/defeating-skype-encryption-without-key). I imagine a database's changes to an index would be tricky.\n\n\nAnother thing to consider is what happens when a key is compromised. You should consider if you want [forward secrecy](https://en.wikipedia.org/wiki/Forward_secrecy), backward secrecy, repudiation, etc. Checkout [double ratchet algorithm](https://en.wikipedia.org/wiki/Double_Ratchet_Algorithm) and especially the design and considerations of [megolm](https://gitlab.matrix.org/matrix-org/olm/blob/master/docs/megolm.md).", "One thing I'm aware of as it relates to things like TLS and others that use asymmetric encryption like RSA and Diffie-Hellman is that the data that these technologies Guard are pretty ephemeral, and so there's not as much necessity to replace them sooner rather than later. With symmetric encryption, I've been told that AES-128 _should_ hold up OK to quantum computers so it's alright to continue to use them for now.\n\nOn that note, another question I had was that, given a potentially long-living public database that could grow to a size large enough to threaten the feasibility of re-encrypting all the different datasets with whatever newer algorithm is designed to be sufficient against quantum-based attacks, are there considerations for alternatives to things like AES-128 that could be employed earlier on (now) that might protect the data in the longer term?\n\nI realize that entire paragraph was a single run-on question, so forgive my lack of brevity and grammatical etiquette.", "You should be using 256 bits key, choose a suitable \u201cmode\u201d and authenticate your ciphertext.\n\nUse well known libraries and let them handle AEAD for you.", "Indeed! :) This is why I referenced AES-* as an example for encryption and SHA as an example for hashing. Both of which, I would assume, may be open to attacks from QC. Encryption algorithms by either Brute-Force or some other circumvention attack, and Hashing algorithms by collisions or other exploits. My question is around optimal quantum resistance, asking specifically which algorithms are known to be the most resistant, and what modes/configurations are considered to be the most quantum resistant.\n\nHowever, my question is a bit broader, also asking for input into the implications of storing ciphertext in a publicly accessible database (similar to blockchain/dApp), and considerations for how to do so safely.\n\nThings like:\n- Do/don't store IV/nonce/seed alongside ciphertext/hash when using X algorithm\n- Use at least X for key-generation\n- etc...", "Another thing I've been looking into is how to ensure that the source of entropy is secure. Given issues with things like `RDRAND` and others, I know that finding a secure source of entropy for CSPRNGs is vital and can effectively make any algorithm, no matter how secure, irrelevant.\n\nI'm currently reviewing `megolm`, and diving into the other items you listed. Thank you very much for all the info!", "AES-256 should be resistant against QC because even if they could apply Grover\u2019s algorithm against it, it still only reduces it by a square root so leaving it at AES-128 strength.\n\nAES-128 is still sufficient for now but if you can go with AES-256, why would you not?\n\nModern CPUs can do AES really, really fast because the AES steps are implemented in hardware.", "Grover's algorithm would square-root the keyspace of AES128, on average finding the solution in 2^64 cycles, same difficulty as cracking a 64 bit key by classical means.\n\nThis would be easy to crack if it was a classical computer solving it, but quantum computers do not parallelize easily for many algorithms (you don't get a linear speedup from running several of them in parallel), and each computation cycle will likely be much much slower than a classical CPU cycle (the overhead of programming, stabilizing, reading and correcting the qubits will take some time).\n\nSo you could make the assumption that each cycle would be slower by a factor of many millions or far more, and that the total speed will have some upper limit bounded by sheer cost of operating the quantum computer. Assuming a billion times slowdown (one QC cycle per second vs a 1 GHz classical CPU) would likely put the cost and runtime of running those 2^64 quantum computer cycles on par with running something like maybe 2^100 classical CPU cycles (a factor of 1 billion times slowdown is roughly equivalent to adding 30 bits worth of computational difficulty).", "Oh greater mind than I have made careers out of these sort of theoretical questions and as pointed out some of your very own question have yet to be thought out. Thus one is free to experiment.\n\nMy daft mind though would think that the implications of storing ciphertext in a publicly accessible database would be as long as its prehash and takes into account that the following types of cryptosystems are not completely broken by quantum algorithms:  \n\\* Hash-based digital signatures  \n\\* Code-based systems (e.g. McEliece)  \n\\* Lattice-based schemes  \n\\* Multivariate schemes\n\nThen one should be good. \n\n&#x200B;\n\nAs for storage schemas nounce/IV/Seed and the like.. then one has security though obfustication or removing the risk though other means.", "I'd also mention that this post doesn't say what mode of operation is being used. That makes a huge difference.", "I have a few misconceptions of AES-256, unfortunately. One of which might be that AES-256 is actually open to Related-Key Attacks, while AES-128 is not? _Could_ that reduce the resistance against QC enough to favor AES-128?", "I think one of the other common misconceptions I've heard of AES-256 is that it's not exactly any stronger than AES-128 and just _sounds_ more secure. This could be due to the fact that the block size for both is still 128-bits, and the only difference is the size of the key. Although, key-size certainly does dramatically improve against bruteforce attacks, and the only thing capable of dismantling both would be a vulnerability/circumvention found in the AES block cipher itself. Am I correct on this assumption?", "> Grover's algorithm would square the keyspace of AES128\n\nSquare-root, not square.", "I'm glad you mentioned that. I didn't want to overload with too many newbish questions.\n\nMy understanding is that CBC is recommended? And ECB is highly discouraged? I don't have a whole lot of insight into CTR(?), CFB, and OFB.", "Fixed", "CBC isn't authenticated, and requires padding which can catastrophically leak information. CBC *can* be used safely (unlike ECB) but it's unnecessarily difficult. \n\nTypically if you have to use AES I'd recommend AES-GCM-SIV if available/usable in the application (with AES-256), if that's not available then AES-OCB, if that's not available then AES-GCM, if that's not then AES-CTR with HMAC-SHA256 (or HMAC-SHA512) of the ciphertext. \n\nIf you don't have to use AES, and can use libsodium, then use the [crypto_secretbox_easy](https://libsodium.gitbook.io/doc/secret-key_cryptography/secretbox) methods. \n\nThe disadvantage of all of those is that for each message encrypted you need to store the authentication tag. That's what prevents attackers from modifying the ciphertext without you noticing. That'll typically mean 16 bytes of extra data per encrypted message. Also, for all except AES-GCM-SIV if you re-use a nonce you catastrophically information.", "That\u2019s 20 year old advice at this point.  Look into authenticated encryption and AEAD.", "AES certainly isn't a requirement. I've also looked into `Kalyna-512/512` as an extreme-measure, but I'm not sure of the potential vulnerabilities of Kalyna, and whether or not it has been rigorously scrutinized.\n\nI'll definitely look into `libsodium`. I feel like I've heard of it before. As far as the `authentication tag`, I'm assuming it's cryptographically signed somehow? What prevents an attacker from modifying both the `ciphertext` and the `authentication tag`? Or is the `authentication tag` intended to be stored securely in another location?\n\nIn terms of the `nonce`, I'm assuming you're referring to the initialization vector? Given that the IV is a `nonce`, I could definitely see why using it more than once would be catastrophic! But I've also heard that it's safe to store the IV next to the ciphertext for use when decrypting without an issue. Is this true for all of them, or also just true for `AES-GCM-SIV`?", "Kalyna hasn't seen enough analysis for me to consider it safe. Indeed, given the way it was made (modifying AES and making the key schedule even more complicated) I suspect it's weaker than AES or backdoored. Since it won't have AES-NI constant-time hardware acceleration available it's almost certainly vulnerable to side-channel attacks to recover the key (just like many software implementations of AES are vulnerable). If I want a safe cipher to use with a software-only implementation, I'd use XChaCha20-poly1305, XChaCha12-poly1305, or XSalsa20-poly1305 (the last of which libsodium uses).\n\nLibsodium is one of the best (hardest to misuse, secure defaults) cryptographic libraries available. There are bindings to be able to use it from most programming languages.\n\nAuthentication tags are computed from the ciphertext, associated data (data that doesn't get encrypted but gets authenticated and stored with the ciphertext), nonce, and key. They're not cryptographically signed, they're closer to the symmetric-key equivalent of a signature. With an AEAD, if the authentication tag computed upon decryption doesn't match the one computed on encryption, the AEAD will not release any plaintext (return error). It's computationally infeasible to alter the authentication tag or the message (or the associated data or nonce) without knowing the key and still have it validate. \n\nThe authentication tag (and not knowing the key) is what prevents the attacker from modifying the ciphertext or the authentication tag. If the attacker *does* know the key they could compute a new authentication tag for a modified message, but they can also decrypt the message and encrypt whatever they want. If the attacker can choose the key they can create (key, message) pairs such that they can pick any authentication tag they want.\n\nThe authentication tag is stored along with the ciphertext and associated data. It doesn't need to be kept secret.\n\nThe term `nonce` means `number used once`. An initialization vector might be repeated, eg the SHA256 hash function has a fixed constant IV. So every nonce is an IV, but not every IV is a nonce. The nonce is a public parameter, you can store it with the ciphertext without issue. The only things you can't reveal to protect the confidentiality of the plaintext are the key and the plaintext. The nonce, ciphertext, authentication tag, and associated data (if any, you don't need to use this) can all be revealed freely."]}
{"id": "ot3hpp", "title": "Should I be concerned with in-band nonces?", "url": "https://www.reddit.com/r/crypto/comments/ot3hpp/should_i_be_concerned_with_inband_nonces/", "Created (UTC)": "2021-07-27 22:21:10", "body": "I'm using libsodium's `crypto_aead_xchacha20poly1305_ietf_encrypt/decrypt()` to securely communicate using a PSK over an unreliable transport, where packets can drop or arrive out of order.\n\nBest strategy I've been able to figure out in order to keep the nonces in sync is to simply prepend them, in full, along with the encrypted messages (of course they're randomly generated on startup and incremented on each transmission).\n\nI know nonces are expected to be public, but I wonder what are the odds of an attacker capturing enough messages over time to find two of them using the same nonce, and then be able to guess the key.\n\nAm I worrying too much?", "post URL info": [], "author": "cyberguijarro", "ups": "16", "downs": "0", "number of comments": "38", "comments": ["XChaCha20 nonces are 192 bits (if memory serves me right), which is long enough that you don\u2019t have to worry about nonce collisions as long as your RNG is good.", "Depends on if you have reason to think your RNG might fail. That type of fault has happened to others before, so you could look at MRAE constructions (misuse resistant authenticated encryption, for example SIV modes), and you can look at nonce hiding schemes to make such an error harder to detect.", "Given the nonce size, unless your random number generator is totally broken, nonces are never going to be repeat.", "Explore the nonce model as specified in this RFC [https://datatracker.ietf.org/doc/html/rfc5116#section-3](https://datatracker.ietf.org/doc/html/rfc5116#section-3). Under some assumptions:\n\n* Each sender can use a counter for the lower 64 bits, and combine it with a fixed per-sender 128-bit upper half to produce a 192-bit nonce. That should remove any need for you two have both sides in sync wrt nonces. The only part you need to care about is not to have collisions on the per-sender upper half. You effectively segmented the nonce space this way. \n* In a client/server bidirectional setup, the upper half can be agreed to be 0x0..0 for the client and 0xf...f for the server, or any other two distinct values. You can also make the counter 191 bits wide, and chose the most significant bit to be the upper half, and assign msb=0 to client and msb=1 to server. As it's clear who's connecting and who's accepting, you don't need to transmit any additional data in your handshake. 191-bit counters might not be a good idea though, as you rarely need the whole counter space -- I would even assert that it's impossible to need it. Better stick to something smaller.\n* You can chose to omitted the upper half from transmission (see 3.2.1 Partially Implicit Nonces), just sending the counter. That makes your payloads smaller, should that matter to you. Note that a collision on the explicitly sent counter is not a nonce collision as the counter is combined with two distinct upper halves to form two distinct nonces.\n* Remember to check for overflow on the 64 bit counter, and rekey on overflow. It's unlikely to happen but still do it for good measure.\n\nThat above assumed that the key has the same lifetime as the nonce counter, e.g. if they are held in memory of a process, both the nonce counter and the key die at the same time. If the key has an unclear lifetime (e.g. persisted to disk/shared between different processes), I would personally stick to random nonces generated fresh with each transmission, as this is the easiest to analyse and reason about.", "Doesn\u2019t the answer depend on the size of the nonce? If it\u2019s one bit then I would said, yes, be worried but if it\u2019s an UUID (not suggesting that you do that but used here to illustrate the other extreme), I would say no worries at all.", "[deleted]", "If your CSPRNG is good, odds of collisions during the lifetime of a key is darn near zero.", "I assumed the RNG is to be trusted in this scenario, although of course that would have to be separately verified in specific platforms.\n\nThanks for introducing me to SIV and nonce hiding schemes... will do a bit more research in those areas.", "192 bits on XChacha20poly1305.", "UK slang. Not used in USA."]}
{"id": "osp5xd", "title": "Aumasson's list of controversial cryptography papers", "url": "https://gist.github.com/veorq/f28d52e8b57971df03ea6f36ad5c400f", "Created (UTC)": "2021-07-27 08:33:21", "body": "", "post URL info": [], "author": "rgneainrnevo", "ups": "40", "downs": "0", "number of comments": "60", "comments": [">So here's a list of crypto papers and essays not purely technical, sometimes called \"controverial\",\n\nBy whom? Why?\n\nThis list, without aditional context, is next to useless, like a Wikipedia article based on hearsay.\n\nMore than suggesting more papers, one would add necessary comments explaining why they are/were considered controversial in the first place.", "[deleted]", "Looking over these papers, all of them are associated with well known contentious public debates, i.e. controversy in the cryptography community. Bring up Koblitz and related critiques of provable security at a crypto conference and watch what happens.\n\nAumasson's paper definitely deserves to be on the list. It probably the cause of the largest number of cryptography-twitter flamewars.", "Aumasson is sufficiently well respected that we can reasonably trust that papers he considers controversial are. Those which I recognize from reading, I'd agree with his assessment that they are contraversial. Some I agree with, some I don't. All are interesting.", "it is just a lame attempt to put himself in the same category as the other authors there", "Could you please elaborate on that?", "I know and work with JP on a regular basis and respect his work totally, and I still don't think the justification is there to call chacha8 \"safe enough\". haha\n\nIt's a tough sell to say that things are well understood enough that a breakthrough will never occur where chacha20 is still safe and chacha8 is not.\n\nI would also call Bernsteins recent paper about how biasing a quantum cryptography competition would look controversial. ( I can't find it at a glance, did he delete it? )", "> Aumasson's paper definitely deserves to be on the list.\n\nThere can't be too many applications where the extra rounds are a significant expense.", "The safe curves website is shitting on Weierstrass curves and promote edwards curves because supposedly because there is no constant-time formulas for Weierstrass curves which hasn't been true for over 5 years since the Renes paper.\n\nFurthermore, there has been way more reported production incidents due to people not clearing a cofactor and ending up vulnerable to a small subgroup attack than people attacked due to a side-channel. And you can't have cofactor = 1 on Edwards curves.", "[removed]", "I agree with JP: the common theme in attacks against ARX ciphers was insufficient diffusion. There really haven't been fundamentally interesting developments in that area since Claude Shannon, and past cases where diffusion was insufficient were ultimately flaws in the design of ARX ciphers which were discovered by researchers like JP. So far we don't have a reason to believe such flaws exist in ChaCha.\n\nSalsa is an interesting case study there: the best known attack reduces the security margin of Salsa20/8 by ~6 bits. JP helped develop it and several of its predecessors.\n\nI think there's a bit of potential we'll see similar future attacks against ChaCha8, but I'd expect such attacks to be similar in terms of shaving off a few bits of 256-bit security at best.\n\nIf you're betting on a complete breakage of ChaCha8, you're betting on some fundamentally new form of cryptanalysis against ARX ciphers. And of course, any cipher is potentially vulnerable to some hypothetical new form of cryptanalysis. The question is are we seeing the sort of metaphorical cracks in the facade which would lead us to believe such a cryptanalysis is on the horizon, and in the case of ARX, the answer so far is no.", "I'm still able to find here:\n\nhttps://cr.yp.to/papers/categories-20200918.pdf", "Oh, strong agree on disagreeing with Aumasson's paper. I think he is dead wrong, but you know teach the controversy or whatever.  \n\n\n\\>I would also call Bernsteins recent paper about how biasing a quantum cryptography competition would look controversial. ( I can't find it at a glance, did he delete it? )  \n\n\nWas that the Bernstein paper that he got all upset about because the eprint rejected it?", "It matters a lot on embedded platforms. ChaCha8 is over twice as fast as ChaCha20.", "The only thing I know of in production is chacha12 in Android for FDE, and only in low-end phones.", "Not just constant time, but unified (works for addition _and_ doubling), complete (no exceptional points that cause the addition to fail), and fast (which he knew would still technically rule out Weierstrass even if someone did the work like [Renes](https://eprint.iacr.org/2015/1060) / [Hamburg](https://eprint.iacr.org/2020/437)).\n\nIndistinguishability \"requiring\" Elligator was just dumb\n\nIgnoring the pain the cofactor causes was also dumb. Even if they considered that the cofactor was accounted for with Curve25519/EdDSA and they're not responsible if you fuck it up like with Monero, Ed25519 still wound up having issues with the cofactor and batch verification. There was also no clear path on what to do with Edwards + 3mod4 primes where you couldn't easily use a = -1, which means you'd have to use a = 1 which is slower and therefore bad. _Luckily_ Decaf/Ristretto solved the cofactor problem so Edwards curves now have prime order and the fastest math, but that is definitely something djb should've done before putting safecurves up", "This sub is about cryptography, not cryptocurrency", "elite tier imo is ARX with data-dependent rotations", "My very layman assumption that i'm making is that there should always be excessive margins of safety specifically to protect from the unknown, especially if they aren't computationally costly in the grand scheme of things. For this reason alone i'm more inclined to lean into something like Google using chacha12 for FDE in low-end android phones, vs reducing rounds to just above the best-known-at-present attacks.", "Ahh i had forgotten the title. Thanks!", "[deleted]", "> Edwards curves now have prime order and the fastest math\n\nAre they *also* fastest at X-only ladders? For instance, is there a way to speed up X25519 by doing the computation in Edwards space? I mean, there's an obvious speed up for generating ephemeral keys (using pre-computed tables), but what about the variable base single scalarmult in constant time?", "The big problem there is timing attacks. With the right hardware data-dependent rotations will still be constant time, but that's not always the case.", "I hope we can all agree ChaCha20 was a mistake.\n\nThe main security outcome of ChaCha over Salsa20 (setting aside it's a more elegant construction which performs better) was increased diffusion.\n\nAnd yet when it came time for standardization the number of rounds were left the same as Salsa20(/20), despite the increased diffusion rendering them unnecessary. I don't want to put words into anyone's mouths but I feel there was unnecessary fear in lowering the number of rounds commensurately with the increased diffusion.\n\nIn (Salsa)20/20 hindsight, I think it would've made more sense to standardize ChaCha at 12 rounds instead of 20. I would personally prefer and argue for 8, but I hope we can all agree 20 was too many.", "He argues that we can significantly reduce the margins of safety we have for cryptographic primitives without introducing weaknesses. Perhaps he is correct, no one really knows and for that reason I would argue that we should have very conservative margins of safety.", "The scalarmult itself for the Montgomery ladder and Twisted Edwards fixed window are roughly the same speed, but Montgomery is faster if you don't have to decompress the input point (costing a sqrt). And a bit faster still if you can do the final exponentiation with safegcd (i.e. a simple inversion). \n\nApparently all curves whose order is a multiple of 4 _can_ be laddered with the same formulas as the Montgomery ladder, but uh.. in terms of w where w = f(x,y). So the Montgomery ladder uses f(x,y) = x and a24 = (A - 2)/4, while Twisted Edwards uses f(x,y) = d*x^2*y^2 and a24 = a/d or f(x,y) = a*x^2 / y^2 and a24 = d/a. So.. doesn't seem very useful. [Differential Addition on Twisted Edwards Curves](https://link.springer.com/chapter/10.1007%2F978-3-319-59870-3_21) is on scihub", "why do you need hardware https://arxiv.org/abs/1509.02584 (my paper)\n\nthe enemy seems to be multiplication", "You need an ALU with a shifter that takes constant time regardless of shift amount. Not every architecture or implementation has that. Pretty much all CPUs do, but many microcontrollers don't have barrel shifters or similar constant-time-shifters.\n\nConstant-time multiplication is definitely even less common.", "Yup. It is not widely known, but barrel shifters are *big*. I don't know how they compare to a multiplier, but they are much bigger than what an intuitive understanding of rotations would suggest.", "Asymptotically speaking, a barrel shifter requires the same number of gates as a multiplier.\n\nOf course, most CPUs probably aren't using FFTs in their multipliers...", "I made a 64-bit barrel shifter in Minecraft years ago. They're huge. Gives a nice intuition to see it in Minecraft scale compared to entire 8-bit CPUs, it's about a quarter of the total size of most of them IIRC."]}
{"id": "ot10yb", "title": "Why are banking PIN's 4 numbers?", "url": "https://www.reddit.com/r/crypto/comments/ot10yb/why_are_banking_pins_4_numbers/", "Created (UTC)": "2021-07-27 19:37:18", "body": "I have bank accounts in a variety of different banks and all of them in order to get cash out off the ATM require a 4 number PIN. Isn't this insanity? I mean a modern GPU can probably crack this in seconds according to the computerphile video on cracking passwords. I don't get it.\n\nThen to log in, some sites require an alphanumberical password. For example, in one account I have, it asks for a 4 to 6 alphanumerical characters (max) which is also unsafe.\n\nAnother bank has a 4 PIN number again. It has that type of dynamic numpad sort of thing where the numbers change each time, however the correct PIN remains the same.\n\nWhat im missing here?  \n", "post URL info": [], "author": "cryptomann1", "ups": "6", "downs": "0", "number of comments": "46", "comments": ["Well... Not all banks are 4.   Bank of America is 6.\n\nBut also after, i think something like 10 false tried your card is what's is called \"hot carded\" or sometimes a \"soft hot card\" and you have to contact your bank to get a new card or get it turned back on (for the soft hot card).  So the likelihood of getting a 1/1000 shot in 10 tries or less is well... 1/100.\n\nBut also you talk about PINs in other ways so i think maybe you're talking about several different kinds all at once and it is a little confusing.", "> I mean a modern GPU can probably crack this in seconds according to the computerphile video on cracking passwords\n\nGPU hash cracking speed is irrelevant unless you can actually get your hands on the hash of the pin. If the banking service securely holds the hash then they can rate-limit attempts however they like.\n\nMy bank shreds my credit card or locks my web account after like 3-4 failed attempts.", "[deleted]", "You only get three tries. It's not about the Total solutionspace which is only 10000 numbers anyway. It's that the probability of you guessing it correctly within three tries is small enough. Also your pin is not the only security measure, ie transactions that look suspicious will be blocked by your credit card company.", "The card is typically locked after three failed attempts so there's no chance to crack anything. You just end up with a locked card after half a microsecond. Why do you think criminals go through the effort of putting false readers on ATMs to read PINs?", "Some banks you can set the number however long you want. Also people need to remember it and keep it simple, you don\u2019t want the person ahead of you putting in a 20 number and halfway getting a digit wrong", "[The historical reason](https://www.cnbc.com/2017/06/29/a-wifes-bad-memory-is-the-reason-your-atm-code-is-4-digits.html).", "It's 2FA: To withdraw cash, you need both the card (something you have) and the PIN (something you know). The PIN is usually ephemeral with the card expiration also.\n\nHowever, the PIN is handled through an online authentication handshake. The bank needs to verify the PIN is valid with the CCN, and every bank will limit the number of attempts on the PIN, usually at 3, after which the card is locked for a timeframe (24 hours). An online GPU attack is thwarted.\n\nTo do an offline GPU attack, the adversary would need a copy of the bank's authentication database, and that would assume the PIN is hashed, which it likely isn't.", "They're always authorized against a central service that can cut you off after a small number of incorrect attempts, so it doesn't really matter if it would be easy to try them all - you only get to try a few times.  And they have to be short so everybody can remember theirs, even people who aren't good at remembering things.", "Royal Bank, many years ago was variable length, minimum of 4...  I could set 12 digits..\n\nDidn't find anywhere I couldn't use my card for Interact purchases in stores or ATMs..\n\nThese days, no, too many (majority/all) have maximum entry lengths..\n\n4 digit PINs, thr security comes from the embedded smartcard..  3 PIN failures, card is NFG.", "Because they were invented in a time when someone couldn't do a billion guesses per second.", "They want it to be quick, but 3 is too compromised, therefore 4", "Also the PIN is something you know for authentication.  It isn't really for securing the transaction like the chip on your card.", "Except humans are terrible at selecting random pins.\n\nThe top three PINs alone ( 1234, 1111, and 0000 ) account for 18.6% of all pins used.\n\nIf you tried the 10 most common PINs your odds of correctly guessing is about 1 in 5.", "Beside ATM, to log in on the website im asked for ID number + 4 number PIN or 4-6 alphanumeric on other bank.", "Bad news, the pin is most probably not even hashed. Some of the banks I know of allows for the customer to access their pin through the online interface.", "Dunno I imagined some hacker with a laptop and some cables attached to the ATM cracking it like John Connor kid in Terminator 2.", "Imagine how much money would be saved if PIN numbers were slightly hard to put in while drunk. I\u2019ve seen people who can barely stand put their pin in and pull out a few hundred bucks more times than I can count.", "any human can roll dice. they just don't care to", "That wouldn't fly here in Sweden. 2 factor authentication involving either a hardware token or an app for authentication is the minimum here.\n\nEdit: also some banks here give you the choice of using a PIN been 4 and 8 digits. Not all cards readers support anything but 4 digits, so beware.", "If you can hack the ATM then you wouldn't bother mimicking anybody's card, you'd just hit the button to empty it on money.", "Yeah. I mean, it's just a computer running windows and all. If you can open up the cabinet, there's even keyboard right there for you."]}
{"id": "oryqj2", "title": "Why do folks care so much about using 256-bit symmetric keys, when key agreement (RSA/ECDH) is only 128-bit hard?", "url": "https://www.reddit.com/r/crypto/comments/oryqj2/why_do_folks_care_so_much_about_using_256bit/", "Created (UTC)": "2021-07-26 06:29:38", "body": "It seems strange to me.\nSo many pander to the \"256\"bit minimum, when alas, our RSA key encapsulation/ECC key agreement schemes are only 128-bit hard.\n\n\nThus there is no benefit to using 256-bit symmetric after a asymmetric KEX, right?\n\nHave you guys noticed the forced nature of \"must use 256-bit keys\" for TLS?", "post URL info": [], "author": "john_alan", "ups": "33", "downs": "0", "number of comments": "46", "comments": ["In addition to the other comments, asymmetric key exchange these days tends to be ephemeral. So it's not as likely to be attacked years later. Whereas symmetric encryption is often used for file storage, and files might be kept for long enough for quantum computing to become a real threat. So you want post-quantum security for symmetric crypto NOW, but can afford to wait for more analysis on the asymmetric side.", "why use 256: because it is cheap and because there are some attacks that might in some contrived situations sound sorta feasible below, say, 140 or 150 bits. going 256 bit is pretty straightforward. on the other hand, going 512 bit ecc is not so straightforward, and going 4096 bit rsa might also be expensive for some use cases, especially high traffic servers.\n\nwhy must? because some people like to brag about how secure they are, without understanding security.", "Multitarget attacks reduce the total cost with AES. They raise the cost (although logarithmically) with ECC", "One reason for using 256-bit AES keys is to protect you from attacks which leak some but not all of the key.  Many side channel attacks are like this (e.g. leaking the high bits of a byte by revealing which cache line a table lookup maps to).  If you start with 256 bits of secret, you have enough to spare if they end up not all being secret.\n\nThe other major reason is because (future) quantum computers cut the number of \"bits\" of a secret key in half.", "There was a [research paper](https://link.springer.com/content/pdf/10.1007%2F3-540-45682-1_5.pdf) making a similar point: Unbelievable Security: Matching AES Security Using Public Key Systems by Arjen K. Lenstra", "The primary reason is that [\"128-bits of security\" can mean very different things depending of the context](https://loup-vaillant.fr/tutorials/128-bits-of-security):\n\n* When you try to brute force a 128-bit cipher, you can attack N keys (for fairly large N) and hope to have at least one of them break after roughly 2^128/N attempts. Hash collisions and elliptic curves however don't have such multiple key attacks.\n\n* When you try to brute force a cipher, and make half the number of attempts required to break it, your chances of success are halved (linear drop-off). With hash collision and elliptic curves, this would divide your chances by *four* (quadratic drop-off).\n\nThis is why DJB can at the same time assert that Curve25519 (128-bits of security) has high security, while AES-128 (128-bits of security) [might be a bit too close for comfort](http://cr.yp.to/snuffle/bruteforce-20050425.pdf).\n\nNow I don' know RSA. But I do suspect that if we achieve 128 bits of security with it, that means something closer to hashes and curves than ciphers. (Given current attacks, that are *way* better than pure brute force.)", "well, thanks to the gchq, everything is kept for long enough :D", "> because some people like to brag about how secure they are, without understanding security\n\n\"military grade security\"...", "But a multi target attack isn\u2019t valid against a single agreed AES key is it?", "Err, I believe you're confusing things a tiny little bit here. From what I understand:\n\n* Multitarget attacks reduce the total cost of breaking the *first* key with AES.\n* Multitarget attacks raise the cost of breaking *all* keys with ECC. The cost of breaking the first key however is unchanged.", "Got ya on side channel. \n\nBut that same quantum threat will just break the ECDH anyway right?", "Wait a minute, do we have cryptanalysis on ciphers that study the effect of a partially leaked key? Like, how many rounds of AES-256 are needed to thwart all known attacks that would find the key in less than 2^246 operations, given that 10 bits of the key are leaked?", "Super interesting.\n\nIt's (2^128) / n right, not 2^(128/n)?\n\nCan you give me a little intuition as to why dlog/ecc doesn't suffer the same?\n\nCan't you (on the same curve), attack multiple points faster than you can attack one?\n\ni.e. have your list of attack points... (x1,y1)...(xN,yN)... and scalar multiply the generator by your potential private scalar and look up your attack points?", "Yep, but since the main reason for 256-bit key length (General-Purpose Error-Corrected Quantum Computers) also attacks asymmetric crypto *much* more efficiently to the point that increasing key lengths won't really help, there's not much point increasing asymmetric key lengths. Unless you want to take [Post-Quantum RSA](https://eprint.iacr.org/2017/351.pdf) seriously and have terrabyte RSA keys. That has some performance disadvantages and might tend to require a somewhat larger hardware budget.", "God I hate that term", "as long as it is an approved cypher, it is military grade already :)", "No, but they can be valid against many agreed upon AES keys, which is a threat worth considering in an online key exchange scenario", "There's a trivial bound of the form \"if you have a good attack on having k bits leaked, you can run the attack 2^k times with different 'leaked' bits\".\n\nFor asymmetric crypto there's lots of cryptanalysis.", "> It's (2^128 ) / n right, not 2^128/n?\n\nOops, you're correct, I meant the first one.\n\n> Can you give me a little intuition as to why dlog/ecc doesn't suffer the same?\n\nI know only what DJB and Tanja Lange say in his [ECC Hacks keynote](https://www.youtube.com/watch?v=vEt-D8xZmgE): _index calculus_. Long story short, discrete log over natural integers modulo some big prime can use shortcuts that aren't available to Elliptic curves. In fact, the absence of such shortcuts is our main reason to use ECC: with them, all we have is pure brute force ([Pollard's Rho](https://en.wikipedia.org/wiki/Pollard%27s_rho_algorithm), or [Kangaroo](https://en.wikipedia.org/wiki/Pollard%27s_kangaroo_algorithm) if the order of the curve is not prime), and the keys can be much smaller.\n\nHow exactly index calculus works, and how you can exploit those shortcuts, I have no idea.", "\ud83d\udc4d\ud83c\udffd", "<3 thanks!"]}
{"id": "ordldd", "title": "Is the Enigma Machine still considered safe?", "url": "https://www.reddit.com/r/crypto/comments/ordldd/is_the_enigma_machine_still_considered_safe/", "Created (UTC)": "2021-07-25 08:28:15", "body": "By today's standards is the encryption from the WWII Enigma Machine still safe enough for personal/recreational use?", "post URL info": [], "author": "Lowkey_force", "ups": "46", "downs": "0", "number of comments": "74", "comments": ["Modern ciphers cannot be be distinguished from random noise. Any attack that can distinguish a cipher-text from random bits is considered a valid attack on the cipher and the cipher is declared insecure.\n\nEngima has the property that when you press a letter it can never be encoded to itself. This fact alone is enough to consider the cipher broken.\n\nIf you imagine a game where I get to give you two plain-text messages and you choose one at random and encrypt it using Engima and send it back to me. I win the game if I can reliably tell you which message you encrypted and sent back to me. You win if even after some ludicrous number of attempts I can't come up with any way to reliably tell between them.\n\nEngima very obviously fails in this game. On the first trial, I send you the message of a thousand A's and the second message of a thousand Bs, I can clearly tell which is which because if I get a message back that contains no A's, it's the first message and if I get one that contains no B's, it's the second message.\n\nFor this reason the cipher is considered trivially broken.", "No, it is easily cracked by a modern computer. (This is a common exercise in many cryptography courses.)", "No. PCs even a few years old could decrypt Enigma messages within minutes. Distributed Networks within seconds.", "The Enigma machine wasn't even safe for its own day, (it contained a fatal flaw that was exploited by Turing)", "No, Enigma machines are heavy and coulh fall off the table causing injury. They also don't conform to modern electrical or fire safety standards.", "[removed]", "The effective key strength of a 4-rotor Enigma is 87.5 bits ([source](http://wiki.franklinheath.co.uk/index.php/Enigma/Key_Length)). And \u2026 here comes the pi\u00f1ata treatment \u2026 anything over 80 bits is *generally considered* sufficient for personal/recreational use. The 3-rotor Enigma is around 67 bits key strength, using the basic setup procedure.\n\nFor comparison, a case-sensitive 8-letter random password has about 40 bits of entropy.", "The fact that one letter cannot encrypt to self was one factor contributing to breaking Enigma (i.e. by modern definitions, failing the IND-CPA game).\nThe other contributing factor was the known plaintext, i e. German messages were always starting with the same text, which was a tremendous aid to breaking the code. \nToday's home computers are surely much more powerful than the bombas, however with no known plaintext aid the resulting \"broken\" messages can sometimes be quite  ambiguous in plain language.", "What recreational use would require a cipher that is secure by modern standards?", "By today's standards, no it is not considered cryptographically secure.\n\nThat said, if you refrain from misuse of the cipher (e.g signing off every plaintext with \"Heil Hitler\" like the Germans did) it would be practically secure against non-nation-state attackers.", "I doubt anything will happen if you are just using it for fun but it would be an awful idea to encrypt anything you care about with it.", "I think we can safely say that all cryptography systems prior to the 1970's are no longer safe today.\n\nThere are numerous reasons, but one primary one is that the concept of a public key cryptosystem didn't exist before the 1970's and the Diffie-Hillman paper. Prior to the 1970's no matter how computationally intractable your encryption was, it always required to exchange of some \"secret\" information about the encoding scheme *prior* to the ability to encode messages.\n\nOnly once the idea of Public Key Cryptosystems came around in the 1970's was it possible for two people to exchange information, over an insecure line the entire time, and be sure that their encryption was computationally intractable given computing power available at the time.\n\nInterestingly the original authors who proposed the idea had difficulty coming up with a mathematical scheme that satisfied such public key system criteria; they simply published a paper on the idea itself. It didn't take long for several mathematicians to offer potential implementations of public key systems. And while RSA was one of the first, having been around since the 70's, it's still considered quite secure today.\n\nAnother thing that's interesting to note is that for most public key systems - it is not just that they are computationally intractable *given the most efficient mathematical methods available*. Rather, it is widely believed that algorithms which break things like RSA using the computing power available today cannot exist. Some mathematicians are no longer working on looking for such efficient algorithms, instead working on a proof of the upper limit on efficiency of such an algorithm which renders the problem computationally intractable.", ">Engima has the property that when you press a letter it can never be encoded to itself. This fact alone is enough to consider the cipher broken.\n\nI believe the early models of the Engima did not have this property. Not encoding to same letter occur in the later models that used a reflector.", "[deleted]", "Sorry  - I will have to (somewhat) disagree on that one,  it depends, if some things are known(some, plaintext for example), then yes, it \\*becomes\\* pretty, doable.  \n\n\nbut, to be clear:  a enigma machine today, is (surprisingly) still \\*\\*Quite hard\\*\\*,  if nothing is known about the ciphertext, and the settings is in no real,  \"order\" (so, think totally random positions in ring settings, and plug board) (add the extra rotors, and the different Kind of machines as well..)  \n\n\nThis guy explains is much better than I do, but one thing is for certain - just because we have many times faster computers than before, it does not mean a supercomputer can crack (every) enigma machine-encrypted message,   \n(I would like to see that case - if there is!)   \n\n\nPlease! Do NOT take this as offense! I just couldn't resist to clear up a (possible?) misconception! \n\n&#x200B;\n\nhttps://www.youtube.com/watch?v=RzWB5jL5RX0", "This is not entirely true. Modern computers can only decrypt some Enigma messages, those of which were improperly encrypted, or there are known (or guessed) plaintexts. Properly encrypted Enigma messages with no or little context remain unbroken, and probably will until better AI's are created to help solve them.\n\nThere are still many unbroken Enigma messages:\n\nhttps://enigma.hoerenberg.com/index.php?cat=Unbroken\n\nhttp://www.enigmaathome.net/forum_thread.php?id=320\n\nhttps://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma#Since_World_War_II\n\nWithout a weakness or crib, there are no halting conditions for cracking software. A common misconception with encryption is that the algorithm somehow \"signals\" a correct key or \"signals\" incorrect key. But this is not the case. When an incorrect key is used, no such signal is generated, a machine has no way to tell if a key was successful. Thus, a machine has no way to tell if it has found the correct key or not. So how do they program machines to crack keys?\n\nAlan Turning and his team leveraged a mis-use of the machine in order to generate a simple halting condition. The Germans would \"randomly\" (not so randomly) generate a 3-symbol key (really it was a pseudo-IV), and then duplicate it at the start of all messages. For example, if I randomly generated the key A-B-C then the first 6 letters of that message would be A-B-C-A-B-C. The Allies knew this, so a simple halting condition could be that if the first 3 symbols were equal to the next 3 symbols, this key was potentially correct. A potentially correct key would be used by a human to then decrypt the entire message, and they would have to manually read the message to see if it made sense (the machines only worked on the first 6 letters usually, the smaller the crib, the simpler the crib, the simpler the machine, the faster it could work, the more machines they could build). Other halting conditions were the fact that weather updates (and other standard messages) always started off with the same letters in the same positions (such as \"good morning\" but in German of course), giving Turning and his team more halting conditions.\n\nEnigma's only weakness was misuse. Had they used it properly, and some in the German navy did, it would not have been cracked. Just because a modern GPU can execute a very simple hash many times per second does not mean that same GPU can decrypt and check a full message without any sensible context or crib at the same speed. 2^80 hashes per second does not mean 2^80 Enigma decrypts per second. If it did, why are there still unbroken messages? The problem is a lack of halting condition, or a lack of a simple halting condition. Even if a machine could run an infinite amount of decrypts per second, there are not enough human beings on Earth to read all of those decrypts. Machines cannot read German and they cannot tell if a decrypt is successful or not. So machines have to statistically analyse each decrypt. Then millions of those messages that pass statistical analyses have to be sent to either a human or an AI to \"read\" the message to see if it makes any sense in any context. Then those messages have to be passed on to even more humans to check some more. That entire process cannot happen at 2^80 per second.\n\nThe best AI to date that has been attempted is below:\n\nhttps://github.com/DigicaSolutions/EnigmaCode\n\nThey only trained it to read 10 letters of German versus 10 letters of random. It was able to decrypt test messages, but not real Enigma messages.\n\nThe problem was never decryption, it's the halting condition. If you do not have a reasonable halting condition, then all a distributed computer is going to give you are 2^80 messages that you need to read through one by one to find the correct message! You need a halting condition (crib) or an AI that can read German really quickly and really accurately. The bottleneck will always be the AI.", "Enigma was quite safe for its day. Reliably breaking it in time for the attack to be useful was a years-long international effort. Turing's team not only had expert codebreakers and engineers but also the work of the Poles from before the war, a captured Engima machine as reference, American manufacturing capacity to build over 100 code breaking machines, and plaintexts provided by resistance operatives throughout Europe. Many Nazis radio operators also failed to be operationally secure in their use of the Enigma.", "It's been a few years so apologize if I say something wrong, but wasn't the \"flaw\" the messages being coded using the same initial combination of rotors, effectively making the cryptography much less secure? That would be analogous to saying some website being hacked because people were reusing passwords from another website that *actually* got hacked.", "Yep, it's utterly insecure but a good replica is a *really cool device*. Sort of like how typewriters are cool machines but totally obsolete, and with a lot of the same mechanical wizardry.", "That only applies to ciphers with no known attacks faster than brute force. (or equivalent security notions for things like hashes). Enigma has attacks much better than brute force.", "Dude, secure symmetric crypto is a thing.  There are legit use cases where symmetric (and not asymmetric) keys are needed.\n\n3DES (+ an appropriate mode of operation) is still considered secure, though not recommended for new systems for other reasons.  DES came out in 1975, before the existence of asymmetric crypto was public knowledge.  I doubt the designers of DES were aware that public key encryption was a real possibility.", "Identical repeating letters can absolutely encrypt to the same letter in the Enigma.", "thanks for this!  easy to understand and fun to read post.   modern message encryption systems often have authenticated metadata or MAC's or other easy/explicit halting conditions, so it's interesting to see one that doesn't\n\nthis means (to me) that the longer a message is, the more the statistics can be leveraged as an accurate halting condition.   a 300 character message or so should be sufficient that simple stats on word lengths and character frequencies should get you down to a handful of messages.\n\nwhen i look at the links you posted it's clear that the longest unbroken messages are all 110 characters or less.  \n\n\ni imagine a 4 letter english encryption:  \n\n\nit could be \n\n\"STOP\"  \n\"OK#4\"  \n\"FIRE\"  \n\n\netc.   ... nothing you can do to decrypt it.", "i.e. it\u2019s much slower to test \u201cdoes this look like plaintext\u201d than to iterate inputs to the system?  i guess i assumed that at least as a first pass character frequency would be a start but i admit i haven\u2019t thought about it enough.", "> You need a halting condition (crib) or\n\nSorry, but this is exactly the reason why it is not secure today: it is vulnerable to a known-plaintext attack.  All modern ciphers are designed to be resistant to such attacks: if the cipher is not vulnerable in such a scenario, then it is considered broken by modern standards.  Enigma is insecure for exactly this reason, modern ciphers are not.\n\n> Enigma's only weakness was misuse. \n\nNo no no.\n\n> Alan Turning and his team leveraged a mis-use of the machine in order to generate a simple halting condition. \n\nThe scenario you describe was originally discovered by Polish cryptographers (led Marian Rejewski).  Turing built on their work, but let's make sure we get the right attributions for the attack described.  In fact, Rejewski and his team discovered how group theory can be used to \"fingerprint\" a key based upon known repeated patterns.  This was in my mind the greatest cryptanalysis achievement up until this time.\n\n**Here's what you need to read**\n\n * [Marian Rejewski and the First Break into Enigma](https://www.ams.org/publicoutreach/feature-column/fcarc-enigma)\n\n * [An Application of the Theory of Permutations in Breaking the Enigma Cipher](https://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=D523AF5CBA26324C12FCA42745570A7C?doi=10.1.1.2.9118&rep=rep1&type=pdf)\n\nThe first is a publication in the American Mathematical Society that explains Rejewski's work in modern language.  The second is right from the horse's mouth, Marian Rejewski.\n\nIn short, encrypting the same key twice at the beginning of the message allowed the allies to fingerprint the rotor position given enough ciphertexts.  This is not a flaw in the operating procedure, instead it is an insecure design.  \n\nIf you want to know about what Turing did, watch [this video](https://www.youtube.com/watch?v=V4V2bpZlqx8).  He exploited the fact that given a known plaintext, you can rule out rotor positions because a letter never maps to itself.  This allowed finding rotor positions much faster than brute force.\n\nBoth the Polish (Rejewski's team) and the British (Turing's team) demonstrated that Enigma is not secure by modern standards.", "I mean, no one's saying it was *easy*, but they broke it, which means that it failed the basic test of a cipher.    \n\nIt was able to be broken by the nation states of the time, which means it wasn't suitable for use in a war in that era.", "Got a link to its cryptanalysis? I only know of the one weakness (the \"always substitute\" one).", "Do you have any examples? Both of your examples are from the 1970\u2019s onward; 3DES encryption was invented in the 90\u2019s. \n\nAnother reason for my claim is the amount of computing power available before the 1970\u2019s and the method of efficient algorithm brute force attacks. \n\nWe didn\u2019t have the computing power before the 1970\u2019s to use numbers which were large enough to be computationally intractable by today\u2019s standards. Even for something like RSA which is still considered secure, if large enough primes are used - if you took something encrypted in the 70\u2019s using RSA could be broken today, since we are putting the computational power of the 70\u2019s to produce large primes against the computational power of today\u2019s ability to run efficient algorithms. \n\nAnd any encryption which doesn\u2019t use computational intractability by today\u2019s computing power standards as a foundation for its security seems vulnerable by today\u2019s standards.\n\nIn 50 years, I expect most things which are encrypted today, and considered secure today, to no longer be secure. That doesn\u2019t necessarily mean that the method itself which was used will be insecure, as the computing power for encryption using that method increases. \n\nSo I suppose it\u2019s possible that a method which existed before the 70\u2019s could be considered secure if implemented appropriately today. But I\u2019m just skeptical due to the computing power available before the 70\u2019s for encryption methods, and I\u2019m not aware of any such methods. Do you have any examples?", "Double-checked and I probably misremembered something.", "Yes, the statistical checks are a bit like a car transmission, layered to maximize efficiency. The first pass is extremely quick and produces many false-positives but no false-negatives. For example [this project](https://www.bytereef.org/m4_project.html) uses [Sinkov statistics](https://en.wikipedia.org/wiki/Sinkov_statistic). Plaintexts that pass the first test get passed on to a slightly more complicated test, perhaps looking for specific German words, phrases, or grammar. Texts that pass that then passed on to AI, or in the past, actual humans. The process is ever more complicated because code words and typos/mistakes in coding were frequent. So a decipher with many mistakes, typos, and grammatically incorrect German could still be valid, where as the very next one is equally as bad, but is just a (un)lucky key randomly generating German words that happen to have some context with war/military/weather/resources/inventory.", "> Many Nazis radio operators also failed to be operationally secure in their use of the Enigma.\n\nThis is a big point that doesn't mean the cipher was flawed. You can have all the algorithms and complex passwords in the world, but if you stick the password in a sticknote in your desk no cipher would be secure.", "Because of that it's not IND-CPA secure. That is what allowed attacks faster than brute-force. Once you've got attacks faster than brute-force the key strength doesn't matter, the effective strength (given that attack) is what matters.", "3DES is just 3 invocations of DES.", "> This is a big point that doesn't mean the cipher was flawed. \n\n(1) If a cipher is vulnerable to a known plaintext attack, then it is flawed.  \n\n(2) Enigma is vulnerable to a known plaintext attack.\n\n(3) Therefore, Enigma was flawed.\n\nWhich part do you disagree with?", "Sure, but those weren't the flaws that broke it, it just got them info we needed to break it.    \n\nReusing keys a few times, having some known plaintexts, and access to the machine itself should compromise *messages*, not the entire cipher.", "Yep, makes sense. Someone must've published at some point about the effective key strength, any idea?", "My original post claimed that cryptography systems prior to the 1970\u2019s are not secure today for a variety of reasons. I gave the PKC invented in 70\u2019s reason in my initial post, which doesn\u2019t apply to DES, but I gave another reason in my follow up post which does. \n\nDES was still invented in 1975. Do you have any examples of cryptographic systems invented prior to the 1970\u2019s which are considered secure today?\n\nI\u2019m not saying one doesn\u2019t exist, I\u2019m curious; I\u2019ve just taken some mathematical cryptography and I\u2019m not aware of any.", "This is in the context of how safe it was \"for the day\". Every cipher of WWII was vulnerable to known plaintext attacks.", "Dude, my point was that your basic argument is flawed and inane.  You claim that all crypto before 1970 is flawed because public key crypto.  I'm pointing out that none of this was publicly known until 1976.  So if knowledge of public key crypto is so essential to any kind of secure crypto, how did the designers of DES do it?\n\nNot to mention, that anybody with any real knowledge of cryptography knows about the existence of secure symmetric crypto and a bit of it's history.  (Turns out symmetric crypto and hash functions are also pretty darn important to practical public key systems too.)\n\nThere are like, deep structural flaws in your argument that quibbling over the minutiae isn't going to be able to fix.", "Original question from the author (at the top):\n\n> By today's standards is the encryption from the WWII Enigma Machine still safe enough for personal/recreational use?\n\n\"By today's standards\"", ">Dude, my point was that your basic argument is flawed and inane. You claim that all crypto before 1970 is flawed because public key crypto.\n\nThat's not what I said - I said that was *one of numerous reasons.* If I'm so plainly wrong, could you kindly point me to an example of an encryption scheme developed prior to the 1970's which is still considered secure by todays standards?\n\nThe reason that I gave the public key system reason is that it was relevant to this guys question. Part of the reason we were able to break enigma is the fact that they had to share the enigma equivalent of the private keys over \"insecure networks.\" Thus France's spy Hans-Thilo Schmidt was able to discover and send back daily keys.\n\n>So if knowledge of public key crypto is so essential to any kind of secure crypto, how did the designers of DES do it?\n\nI won't comment here because I have no knowledge of DES encryption.", "You're responding to a thread not to the original post.", "By the standards of 8-year-olds passing notes in class, Enigma is safe (ignoring the obvious weight of the machine, which could fall off of a desk and injure such a small child). Happy?", "How about by the standards of WWII encryption? You know, the subject of this thread?", "Got broken, like PURPLE, so still pretty crap. Took a bunch of money and a few years, so better than no encryption or some older systems.\n\nThat's in contrast to SIGABA (unbroken during its lifetime)."]}
{"id": "oqrg1e", "title": "Are passwords with words really safer than passwords with complex characters?", "url": "https://www.reddit.com/r/crypto/comments/oqrg1e/are_passwords_with_words_really_safer_than/", "Created (UTC)": "2021-07-24 07:47:45", "body": "When you search \"safe passwords\" in Google blogs show up talking about how you should use normal words instead of complex passwords. Among these blogs its also the NIST.\n\nFor example:\n\n\"window car plate keyboard mouse awesome\"\n\nThis would be safer than \"screwing up\" the password a little bit? like adding some special characters removing i for 1, s for $, adding some number to it..\n\nWhy is that? I just feel a bit paranoid at simply having some words as a password so I like to add in some numbers and special chars and so on.\n\nAre they conspiring to decrease password strength on people? (tinfoil hat on)\n\n&#x200B;\n\nAlso, is there any site that you can use to measure your password strength against a government bruteforce attack? the ones that I find it just says for instance, I tested a password (not the same but similar format):\n\n\"It would take a computer about 1 undecillion years to crack your password\"\n\nThis sounds cool. However it's just one computer. What happens if someone with resources has a bunch of computers to bruteforce at once? How do I check my password strength then?", "post URL info": [], "author": "cryptomann1", "ups": "31", "downs": "0", "number of comments": "123", "comments": ["[deleted]", "With generated passwords, you can *calculate* how many chances it will take in order to brute force a password. It's the number of unique symbols, to the power of how many of them there are.\n\nSo with a 4 digit PIN, there's 10^4 == 10,000 possible pins.\n\nWith a lowercase password of 15 characters, it's 26^15, or around 2^70, so 70 bits of entropy.\n\nFor a password with 6 words, from a wordlist of 8000, that's 8000^6, or 2^77. 6 words is *stronger* than the 15 character random lowercase letter password, by a decent amount.\n\nAnd how long it will take someone to brute force a given password depends a lot on how that password is stored. If it's stored using strong password hashing algorithms, an average computer might only be able to check a few of them per second. If they're using something weaker, it can be a few *million* per second, or more.", "Passwords and passphrases are about combinatorics. Your password is 1 of many, where \"many\" can be rigorously defined in a quantifiable manner.\n\nIf you are generating a [passphrase using some dice](https://diceware.com), then you are letting the dice pick a word from your word list. If that word list has 7,776 words, then each d6 toss will uniformly pick 1 of 7,776.\n\nGranted, 1 random word isn't very secure. My laptop can process a million guesses per second, so we should probably generate more. Generating a second random word with my d6 means that I now have to guess 1 in 7,776 for the first word, and 1 in 7,776 for the second, or 1 in 7,776^2 = 60,466,176. 60 million possible passphrases is certainly better, but that's a minute on my laptop.\n\nHow far out should you go? [According to some verifiable brute force rates](https://gist.github.com/atoponce/a7715930ae6eb7d6b487f2f76b57a68d), you probably want to target about 6 words with your d6, or 1 in 221,073,919,720,733,357,899,776 ~= 2^(77.5).\n\nThe key here however is that your d6 is choosing your passphrase, not *you*. If you decide to build it yourself, the security margins drop significantly.", "Word based passwords have a higher entropy per unit of human memory. 10 bits of random words are easier for you to remember than 10 bits of random characters. So if you choose between a word based password and a character based password that are each as easy to remember as each other, then the word based password will probably be stronger.\n\nObviously, this is a simplification without scientific or mathematical rigor. For example I don\u2019t know if \u201cunit of human memory\u201d is a real thing.", "Relevant https://xkcd.com/936/", "Snowden said. Use 4 random rarely used words from a dictionary.", "An vulnerability in the 'word' approach, that might just be me, is that I've had to stop myself reading the password aloud when I type it.", "Fact is, real people can't remember crazy passwords with weird characters. So they go with the minimal effort that satisfy the requirement. Which means, given the \"standard\" requirement of \"one uppercase, one lowercase, one number, one special\" in the end everyone's password looks like this:\n\n**Johnny.1**\n\nNow add the requirement to change password periodically, and here's the new password:\n\n**Johnny.2**\n\nBoom! You just trained people to use easily guessable passwords in predictable patterns, for the joy of all attackers.", "It really depends on the total entropy (randomness) in the password. If you choose random words from a 13 bit per word dictionary (2^8 == 8192 words) then 4-6 words is 52-78 bits, which is going to be quite difficult to crack. \n\nBy comparison, randomly generated password with 20 characters, made up of upper, lower, numeric gives log2(62^20) == approx 119 bits which is essentially impossible to brute force. Diceware would require 9 words to have the same strength.", "The problem with special characters is that people choose them in predictable ways.  See: http://www.cs.umd.edu/~jkatz/security/downloads/passwords_revealed-weir.pdf\n\nAlso see this Microsoft blog: https://techcommunity.microsoft.com/t5/azure-active-directory-identity/your-pa-word-doesn-t-matter/ba-p/731984\n\nWhen you question these things, I summarised all the answers in my blog: https://littlemaninmyhead.wordpress.com/2019/07/28/collection-of-references-on-why-password-policies-need-to-change/", "requiring a number and special character is security theater. since it's a requirement and the set in each is smaller than the alphabet (\\~10 vs 26) it makes it easier to crack. also: they are much easier to guess where their position is since it's often first or last. it's a complete joke.", "https://xkcd.com/936/", ">\"It would take a computer about 1 undecillion years to crack your password\"\n\nIf somebody had 1 undecillion computers, they could crack your password in one year. As long as you change your password every 364 days you're golden.", "Put upper and lower case and mix with numbers and symbols", "I think mine is pretty safe. *******************\n\n**********************\n\nEdit: pretty cool that reddit censors password. How does it know ?", ">Also, is there any site that you can use to measure your password strength against a government bruteforce attack? \n\nFor passphrases, this is what I like to use. [https://passwordbits.com/passphrase-cracking-calculator/](https://passwordbits.com/passphrase-cracking-calculator/) It uses more real-world cracking power to give you a better idea. \n\nI only use passphrases on things that I may have to manually enter because entering \"**remission stimulus refund runaround**\" is a lot easier than \"**wfevQe>?R2UMgn45Ty?y**\" especially on mobile.", "I use a password manager for all passwords. When I use contiguous characters, I chose 32 characters: uppercase/lowercase letters, numbers and symbols. I also enjoy using pass phrases (multiple words separated by spaces) based on First Nations languages (Canada & sometimes US). I pick m\u00e9morable expressions and just translate word for word. It\u2019s kind of fun and I learn a bit about First Nation culture.", "It's just a matter of characters. Which would you prefer A-Z or everykey on your keyboard?\n\nWhen it comes to brute forcing they normally use dictionary attacks. So if you take the following\n\n\"mouse home comb\"\n\nthat's going to not take too long to break into if the attacker knows it consists of 3 words and so on and so on.  Computer processing power is a lot better than it was 20 years ago so passwords need to adapt. Hackers don't just use 1 computer too they could use a bot net to guess passwords. In most cases they don't need to.\n\nThere are two types of common password attacks guessing and stealing.\n\nStealing is why you don't use the same password over all websites in case one gets compromised. It is then added to a list with the email and they will just let a bot test the emails. Once it finds accounts that work they will send this information on to gain access.\n\nGuessing is when someone targets you and enters stuff like p@$$w0rd1945 - your d.o.b etc until they can gain access. There is a database of default passwords out there and some people even use them thinking they are safe...\n\nNow NGL if you want to create a password simply enter a load of rubbish like the following\n\nakXs32944!\"04aL1d - sure it is hard to remember but safer adding caps and no caps makes it much harder to crack too.\n\nThe longer your password the longer it would take to crack. The randomness of how much scope each character to be helps in it's protection. Chrome does this automatically for you these days when creating a new password on a website.\n\nBut just remember you are only as weak as your weakest link most people are hacked due to a crappy site they joined up to being hacked so that password you thought wa safe for 10+ years most likley is on a database. This is why when it comes to banking you have passwords, passkeys, security numbers and phone verifications to procted the user.\n\n&#x200B;\n\nOh and always remember if someone wants to get in they will, just make it more difficult for them ;)\n\nThere is a program that tells you how long it would take to crack but I aint sharing that one here....", "I rather have a long password with one or two numbers. I mean anything other than that I am likely to forget", "[deleted]", "Length means more than \u201ccrazy\u201d so they teach the word \u201csentence\u201d method so people will make long passwords. \n\nIf you make a easily typable sentence that is 64 characters, its just as strong as a 64 crazy character password because each are 64 characters and thats the thing that matters.  The only difference is that one, you will be able to remember and type easily and the other you would never be able to remember. \n\nMore than that, is that the word sentence method makes it easy to use all crazy characters.  Nouns or beginning of sentence would be capital, then lower case. Its easy to add numbers too and symbols if you use contractions in your words - \u201cMy dog\u2019s 4th paw is white and his name is Rover\u201d contains all character classes for instance and is long.", "The other comments all have really good explanations for evaluating passwords based on words vs complex characters. But I think one thing that might help is to get a bit more basic.\n\nLet's say you create a 5-character password containing only the first 10 letters of the alphabet (lowercase). That makes for 100,000 possibilities. If you add one more character to your set of characters, you have 11^5 possible words for an attacker to guess, which is 161,051. But if you add an extra character to your password (to make it a 6-character password), you have 1,000,000 possibilities. So adding a character to your password is MUCH stronger than adding more possible characters to your password (with the same length).\n\nSo, bottom line, longer passwords is better than more complex passwords. Now, the question you're asking is about the trade-off: is it better to have a longer, less complex (read: easier to memorize) password, or a shorter, more complex (read: harder to memorize) password? Of course, the best solution is randomly generate a long-ass password and you're good on both fronts. That's why a password manager is a good choice. But if you have to choose from one of the two above options, the other commenters have good insight into that.", "I don't think passwords should be rememberable, except for OS logins as you usually can't paste and your password manager. My password manager password is a base91 encoded hash of a rememberable, salted passphrase, and all other passwords are generated by my password manager and as long as the app/service will allow. This makes for really high entropy and I know as few passwords as possible (plausible deniability).", "[deleted]", "In future I\u2019m going to use your reply as all of my passwords because I have no fucking idea what any of it means and I\u2019m pretty sure any one I know who will ever try to get into my accounts to find out if I\u2019ve been buying more warhammer or some other useless shit I spend far to much money on will also not have a clue what this means", "[removed]", "[deleted]", "is there any software where you can enter your password and it tells if its decent or not?\n\n[https://www.security.org/how-secure-is-my-password/](https://www.security.org/how-secure-is-my-password/)\n\nHow do you rate this? I want something like this, but with settings where you can select how powerful the resources of the bruteforcer are.\n\nFor instance can you tell me how long would it take to crack a 28 char password with some special characters encrypted with vera's AES-Twofish-Serpent cascaded algo?\n\nCan your gov crack it?", ">For example I don\u2019t know if \u201cunit of human memory\u201d is a real thing.\n\n\nMaybe there is such a thing. For example the ability to compress using your lived experiences could give you an edge against state of the art password crackers. For instance, you can build a story around \"Broaden Attire Even Rumble Treble Grain\". Less vivid story can be built around characters in \"rvA2EBawTP6y\". \n\nPasswords such as \"rvA2EBawTP6y\" are maybe easier to train into muscle memory, though...", ">\\>So if you choose between a word based password and a character basedpassword that are each as easy to remember as each other, then the wordbased password will probably be stronger.\n\nI don't get this.\n\nGiven 2 passwords of say 28 characters\n\none is\n\nasphalt epic cake car bounce\n\nother is\n\na$phalt\\_ep1c\\*cake;C4r=b0unce\n\nwith enough practice you can remember the special stuff you added\n\nso are you saying the first one is safer and easier for a computer to bruteforce?\n\ncould your gov press a button and have it bruteforced in a X years? because these cases of people put in jail that wouldn't decrypt I doubt they used some mega complex passwords because reading the stories they seem like they aren't very bright people", "There it is.\n\nWhenever this gets brought up, there's always someone who mentions the XKCD, and then someone who shits on it, saying \"but then I can just guess passwords by putting words together. Checkmate!\"\n\nThere are something like 20,000 words in your average English dictionary. If you use four random words, that puts you at 20,000^4 potential passwords.\n\nUsing random characters, you need roughly 9 random characters to match that number of potential passwords, so, in theory, four words is \"less secure\" than random characters.\n\nWhat people who argue that tend to forget is that *you can't just assume everyone is always using four words, if they're using words at all*. As such, a password consisting of four words is usually going to be 20+ characters long, making it orders of magnitude more secure than 9 random digits.\n\nIf I use five words, it's even more secure, and if I use three words, it's immune from a four-word password cracker.\n\nAll of that is a long way to say \"Praise Randall, God of Geeks.\"\n\nObligatory: yes, I'm using handwavium terms when I say \"more or less secure\", essentially equating bits of entropy to security, which isn't exactly accurate. Doesn't matter. All Praise Randall.", "Came here to check if this is already there. While it is'just a comic' it does some proper math an explaining what makes a good password.", "Really, that's it? source???", "That's the xkcd method. Bump it up to 8-9 words and you're good. See diceware", "First link not working.\n\nDo you have a list of successfully bruteforced password? this would be interesting to see what kind of passwords are actually getting bruteforced (ideally by governments or someone with a lot of money but I guess such databases are harder to find)", "Well the problem is you cannot change a password of someone gets ahold of your encrypted file.\n\nHow many computers does the NSA has?", "Hunter2", "But you would not know that there are discrete \u201cunits\u201d in correct horse battery staple example.  Hell, you wouldn\u2019t even know its 28 characters.  Dont forget youre walking in blind to crack either password.\n\nEdit: i didnt read tour whole post - i saw this mistake and commented too soon.", ">\u201cMy dog\u2019s 4th paw is white and his name is Rover\u201d\n\nBut aren't passwords that \"sort of make sense\" easier to crack because of dictionary attack or some other guessing stuff?", "As a followup, security is always a trade-off. It also doesnt matter what your password strategy is if the website stores passwords in plaintext and has a data breach, but there's nothing you can do about that (although a random password would be more helpful here so that an attacker wouldnt be able to use this password as a hint for other passwords you may have).\n\nIf the NSA put quintillions of dollars of CPU power towards hacking one of your passwords, they would probably succeed. You're hopefully not going to be in that situation, but my point is that any password is \"hackable\". Just like anyone can break into your house with unlimited time and resources. The only thing better security does is make it harder for a low-effort attacker to hack you successfully. Don't leave your house doors open when you're on vacation, and don't choose hunter2 as your password. But is the off-chance an attacker might hack your password worth you needing to remember, correctly type out (without typos), and possibly resetting your password every time you need to login (assuming you're not using a password manager)? If I werent using a password manager, id rather quickly type out four english words every time i login than needing to slowly type out my elaborate password.", "[deleted]", ">I don't think passwords should be rememberable\n\nWhen you get to that point it's not a \"password\" anymore but a login token. I.e., something the user shouldn't even be aware of. \n\nAnd yes, it's basically good advice to treat the password manager password as the only thing to remember (although personally I don't put all my eggs in one basket and do remember several passwords for critical services) and the rest as tokens that you don't even need to see.\n\nBut when you're at that point, \"password strength\" stops being interesting. On the one hand you can always generate a 32-character ASCII string that's effectively impossible to brute-force ...... and on the other, if you only use different 8-digit numeric sequences, it doesn't make you \"more vulnerable to brute force\" in any practical sense: (1) it's still untouchable by dictionary attacks, (2) nobody is going to run actual brute force against a database full of stolen credentials, and (3) even if they did they can't use the result to pivot to another service.", "that's cool, but what password are you using *for the password manager*?", "Even with a pw manager, it's convenient to have passwords that you can type without much difficulty. I'd rather have a longer password than one with uppercase or special symbols.", "It\u2019s a game. It\u2019s a hobby. It\u2019s a strong ass password.", "But if you have the 30 character length without using uppercase/lowercase/symbols/numbers, it's the exact same number of possibilities a program would have to search through to crack your code - because it doesn't know you excluded those. That's why words aren't less secure. It's still the exact same number of variables that had to be cycled through.", "Where do you get 49 from? log2 of 26^15 is ~70.5", ">I used keepassxc to generate a passphrase for me to use as a master password. I did however regenerate it a couple of times until I found one that I felt I could remember well. I bet I'm not the only one doing this either.\n>\n>I bet there are (or will be) attacks that exploit that sort of behavior like trying to match a <adjective> <noun> word order and such. Wonder if there has been any research into that sort of attack yet.\n\nTheoretically, yes. Practically, no.\n\nKeepassXC generates a six-word passphrase from the [EFF \"long\" word list](https://www.eff.org/deeplinks/2016/07/new-wordlists-random-passphrases). Like Diceware, it also has 7,776 unique words in the list. So on generation, it's 1 of 7,776^(6), which is about 1 in 2^77 as already mentioned.\n\nIf you discard a passphrase, because you didn't like what was given, then you reduced the keyspace to 2^77 - 1. To reduce it to 2^(76), you would have to discard 2^76 passphrases (2^76 + 2^76 = 2^(77)). I would argue that your security isn't in practical jeopardy until you've dropped beneath 2^(60) for an offline hash cracking attack. That means discarding 2^76 + 2^75 + 2^74 + ... + 2^62 + 2^61 + 2^60 total outputs before finding one you like. That's 149 sextillion discarded passphrases.\n\nDiscard away. You're not doing any meaningful damage to your security.", "1. Never enter your password into a testing meter.\n2. All security testing meters are arbitrary.\n3. Security testing meters encourage lay users to give their passwords to untrusted websites.\n4. Developing password testing meters is bad, and developers who design them should feel bad.\n5. Never enter your password into a testing meter.", "You can download John the ripper or hashcat, hash your password in a variety of different formats, and see how long it estimates it would take.    \n\nIf you're concerned about password strength, it probably won't be your password strength that causes it to get leaked, it'll probably be a site not hashing them at all, and then loosing their database.      \nIt's typically only feasible to break wordlists with common substitutions, lists of previously exposed passwords, and very short random passwords.   \nAfter that the search space just gets way too big, even for massive clusters running faster than typical.   \n[A one million computer cluster, each doing a billion hashes per second, would take eight years to break a passphrase as described in other comments.  ](https://www.wolframalpha.com/input/?i=%28%288000%29%5E6%2F%281000000000*1000000%29%29%2F31536000) \nBoth of those numbers are unreasonably large. \n\nYour best bet is to use a passphrase generator and a password manager, and to use two factor when possible.", "> So are you saying the first one is safer and easier for a for a computer to brute force?\n\nNo. Here we should consider \u201csafer\u201d as the opposite as \u201ceasier for a computer to brute force.\u201d But I wasn\u2019t trying to say either anyway.\n\nIn retrospect I didn\u2019t read your post well enough which is the cause of the confusion. I wasn\u2019t exactly answering the question you asked. Here is an answer:\n\n\u201cScrewing up\u201d your password could help, but not by a lot. Humans are a lot more predictable than they think they are when it comes to doing that. Password crackers exploit this and try those variations automatically and efficiently.\n\nYour a$phalt\u2026b0unce password is more secure than the asphalt\u2026bounce password. However if you added a word or two to the asphalt\u2026bounce, that would be by far the most secure. On the other hand, it would take longer to type.", "\"with enough practice you can remember the extra stuff you added\" - that proves the point, it's harder to remember and thus cost more \"unit of human memory\". Plus, since those substitutions are pretty common, it won't add much complexity to the password. Maybe 5-10x\n\nHowever, spending that unit of human memory to add one extra word instead will make a massive difference in how hard it is to crack. \n\nYou can think of the diceware list as an alphabet consisting of 7700 characters, while the single char choices on the keyboard are around 100 characters. Adding one character multipliers the complexity by 100, while adding a word multiplies it by 7700. This is if the attacker knows how you constructed the password. If the attacker doesn't, it will multiply it by a lot more than 7700.\n\nFurther, the computer doesn't care if the \"alphabet\" or token list it's working with is characters, numbers, or words. It will follow the same rules to generate and test new candidates. But the human brain is bad at remembering random data, but it's really good at words. So for a human it's much easier and more convenient to remember a set of words than a (larger) set of (semi-)random gibberish. As a bonus it's also way easier to type in on a mobile keyboard :)", "> special stuff\n\nEvery 10 year old knows that $ looks like s, 1 looks like i, 4 looks like a, and 0 looks like o. This will not meaningfully prevent an attacker from guessing your passwords. But assuming those five words were picked using a random generator, it's still a strong password and stronger than if you hadn't made the changes (but not by much).", "> What people who argue that tend to forget is that *you can't just assume everyone is always using four words, if they're using words at all*. As such, a password consisting of four words is usually going to be 20+ characters long, making it orders of magnitude more secure than 9 random digits.\n\nI'm always annoyed by people making that assumption, but you're going too far the other way. We should assume an attacker doesn't know the structure of your password (outside of requirements from the service), but it doesn't prevent them from trying a word-based attack as well, especially if they think a word-based password is more likely.", "Nah, if you make the empty word part of your dictionary, you can handle 4 or less words with barely any extra overhead.\n\nThe part about 20000 words in the dictionary scaling fast is accurate though.", "Just doubling it, like diceware with 8-9 words (7776 words in the dictionary), puts it out of reach of pretty much every hacking group.", "I don't have a source. I read it somewhere a long time ago.", "Well how can we remember 9 rarely used words?", "> First link not working.\n> \n\nIt works for me.  Depending upon your browser, it might download automatically for you.  Check your downloads folder.  You can also look at the slides, [here](https://slide-finder.com/view/Testing-Metrics-for-Password.254007.html?__cf_chl_jschl_tk__=pmd_f5d443e602a34f13a858b882e223b21015719275-1627184653-0-gqNtZGzNAg2jcnBszQY6).\n\n> \n> Do you have a list of successfully bruteforced password? this would be interesting to see what kind of passwords are actually getting bruteforced (ideally by governments or someone with a lot of money but I guess such databases are harder to find)\n\nIf you read the Microsoft link, they talk about how passwords are brute forced.  You need to distinguish between online attacks and offline attacks.  For online attacks of user passwords, it's largely credential stuffing and password spraying with the most popular passwords.  For offline attacks where they have the database of hashed passwords, a combination of methods is used, including dictionary and brute force (in addition to credential stuffing and other methods).\n\nThere used to be a website with lots of database dumps called hashes.org, but that has been down for quite some time.  You can see the web archives of it [here](https://web.archive.org/web/20201101134515/https://hashes.org/leaks.php) .  You can also look at common passwords and a number of cracked databases [here](https://github.com/danielmiessler/SecLists/tree/master/Passwords).", "[deleted]", "Not when they are very long. There are no dictionary attacks on passwords over 30 characters.  Maybe even 20. \n\nThe longer the passpharase, the harder it is to even begin to guess what words make it up. \n\nHow would you program your cracker to find all the possible word combinations in :\n\n\nXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXXX\n\nMind you, you also have to consider numbers and symbols on top of regular upper case and lower case letters.\n\nWhere to begin? Lets start by find all the sentences that begin with the word \u201cThe\u201d  - ok, just about every possible sentence in the world could begin with the word \u201cThe\u201d. So you cracker would have to try all of them - and you wouldnt be close to cracking my password the begins with \u201cMy\u201d. \n\nIts \u201ceasier\u201d if people only used say, 3 words - coming up with every combination of 3 words might - only might be doable because its a limited set of words, but more importantly characters. If we assume that my dictionary is standard, I might attack this as \u201ctry every combination of 5 letter words, but limited to three words\u201d\n\nSo: \u201cwords, three, month\u201d\nmonth, words, three\u201d\nthree, words, month\nWords,Month, Three\nWords, three, Month\n\n\nBut you would have to try every single 5 letter word, in all possible combinations, in both upper and lower case forms, and there is absolutely no guarantee that we are even dealing with 5 letter words. It might 1 four letter word 2 two letter words and one final 7 letter word. So you have to try every single combination of every single word length, account for uppercase versions and lower case versions etc.  see how hard a problem this is? \n\nThere are no crackers that can crack full words like three cherries on a slot machine. Its not like that start cracking and go Boom! I got the first word! Now I just need to find the other two words!\n\n\u201cMonth XXXXX XXXXX\u201d\n\nThey don\u2019t work like that. Its all other nothing because you are matching a hash of the whole thing, not a partial thing.", "Mind sharing what you use for a manager?", "[deleted]", "Netflix", "Then there\u2019s this guy, going for distance.", "probably used log base e\n\nwhich is wrong here", "Why do we need log in the first place?", "[deleted]", "Yeah that's why I said a software so you can enter it into an air gapped offline computer.\n\nI don't get why a meter is inherently bad. You are calculating how strong your password is one way or another so why not automate it with a nice GUI.", "Please read some research on this subject before commenting in so opionated fashion. Some password strength estimators are grounded on good theory. Good example is https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/wheeler \n\nThere is no risk from using an offline library like zxcvbn to test your password locally.   \n\nThere are of course limits to the accuracy of these estimates. The accuracy of the estimators is good only for low entropy passwords. So, you are able to find out with good certainty if your password is weak enough to brute force online. Estimates beyond that are not that accurate. This is shown in one of the graphs of the usenix presentation pretty well. For higher entropy one would need to have impractically large model, and the results are less interesting anyway.", "Hashcat and JtR won't give you an estimate of how long it will take to crack. They'll give you an estimate of how long it will take to exhaust the current keyspace. Those are two entirely different things. Hashcat might tell you it will take a million years to exhaust the keyspace and will recover the password in a few minutes. In that case, you just got lucky.", "\\>as described in other comments.\n\n&#x200B;\n\nSorry but which comments? just to get an idea I would like to know what password you used for that calculation.\n\n&#x200B;\n\nWhich is better ripper or hashcat? I will try that assuming \"remaining time\" is accurate.", "Two factor's is just the best really", "I wish I could test the strength of my password for real and get an idea of the end result. Is there really no way to know how safe it is at least in paper?\n\nI want to make a backup of my files and put it online somewhere in case my computer become broken or fire in the house, however im paranoid at the thought of having my stuff online. With cryptocurrency being a thing there is a big incentive for people to store your encrypted stuff indefinitely on the servers and try to bruteforce it since its like looking for treasures.", "A dictionary attack just checks for words, it doesn't necessarily check for words in different orders. (\"kn0wl3g3!\", not \"knowledge gunboat suzanne small\" ) \n\nIn the end, they still have to brute force trillions of permutations (20,000^4 from before), in addition to the septillions upon septillions of other potential permutations.", "Attackers often DOES know the structure of your passwords, if you have ever registered on a website which didn't protect their account database properly.", "The alternative to 9 words with diceware (116 bits) is 19 to 20 fully random alphanumeric characters (113 or 119 bits, respectively). Even with 5 special characters added to the mix, 19 characters has less entropy (115 bits) than the 9 words.\n\n8 words (103 bits) correspond to 17 characters (101 bits) or 18 (107).", "I just wrote another comment elsewhere in the thread that explains what i mean more without getting into math of course. Its a super hard problem to attack which is why we have never seen a case of super long passphrases of \u201cwords\u201d actually being cracked.", "Then I think it's very doable to memorise 64 characters of some dumb sentence or thing that you construct in your mind, with some screwing around on it.\n\nAnd as far as using KeePass, for full disk encryption you can't use it. You can always use an USB with a randomly generated key, however, now you have the problem of having to hide the USB (and not losing it) because it's literally your key, which also contains KeePass with the rest of the passwords.\n\n&#x200B;\n\nAbout crackers, i thought that they would be able to search for spaces or other stuff typically used to separate words like commas, and then find out the length of the words and go from there.", "Not OP but Bitwarden is what I switched to and it has been amazing. Has a lot of great features that other password managers make you pay for and even if one of the features you want on Bitwarden, the cost is very minimal.", "Still makes for a good enough password with srspass.com :p", "log base 2 of the number of combinations, is how many bits you need in order to enumerate* all possible combinations\n\n*ie, assign a unique base-2 number to each combination.", "It's accurate enough. The margins are large enough that you can tolerate discarding 99% of candidate values because even with knowledge of the discarding rule the adversary doesn't have enough computing power to crack the remainder. 2^77 is a lot.", "They're all based on the developers ideas of security, which makes the password security strength meter ecosystem arbitrary. Just use the password generator in your password manager, then you don't need to worry about it.", "zxcvbn is abandonware. [Last commit was almost 4 years ago, in October 2017](https://github.com/dropbox/zxcvbn/commit/67c4ece9efc40c9d0a1d7d995b2b22a91be500c2) updating the readme. It's certainly better than most of the competition, but it's also not designed for end users to test their password against. The library is built for organizations/services that provide authentication to give an idea to end users what the they think the strength of their password might be.\n\nEnd users should not be testing their passwords against password strength testing meters. They're too arbitrary and give a false sense of security. Instead, end users should be educated in using password managers, and using the generators that ship with them. Not designing their own, then finding libraries to test them against.", "These algorithms can only tell you that obviously bad passwords are bad, but can never tell you if a password is good.", "From a practical standpoint, that's really the most accurate answer you can give.    \n\nYeah, you can guess anything on the first try, but there's nothing you can *do* to raise that number.    \nSo barring miracles, the typical time to crack a password is on the order of the time it takes to search the keyspace.", "There were some other comments discussing a word based passphrase consisting of 6 words drawn at random from a list of 8000.  \nI used that as the baseline for the calculation.     \n\nIt really depends on what you're looking for, but for your purposes they should be the same.  Hashcat is faster, but I recall John has a better interface.", "No.\n\nRandomness is a property of the source of a number, not a property of numbers. Same applies to passwords. You can not put a password into an estimator and get a correct estimate. The only way to evaluate it is by evaluating the process for creating it.", "Tl;dr: just get a password generator with a high possibility space >2^128, and sleep well knowing it will never be cracked.\n\nYou don\u2019t need to (and can\u2019t really) test the security and entropy of a password at face value out of context. The security of a password depends on the method it was generated.\n\nYou may remember I\u2019m high school physics class they briefly taught entropy. Usually there is the example of a room with a barrier. All of the particles are on one side until you remove the barrier. It is practically, but not purely, impossible, for all the particles to be chance go back to the same side. My teacher incorrectly said that was a low entropy state, but if it were to happen by chance then 2nd law of thermodynamics would be broken but that is nearly impossible. However, the true mathematical measure of entropy is how likely something was to happen. So if by an incredible chance the particles did go back to the other side of the room, and the barrier was put back, then the entropy would not decrease because it was unlikely.\n\nMy point: the states before and after the barrier is removed are the (partly) the same. However, the entropy is greater after the barrier. As you cannot tell the entropy of the room simply by looking at the particles, you cannot tell the entropy of the password just by looking at the password. You need to know how it was generated.\n\nHow does that apply to the real world? There is a mantra in cyber security that a system is only secure as that system would be if the attackers knew the system. In other words, assume the attackers know what password generator you used. Of course, if you see that, by a freak of nature, you generator spit out a password that an attacker would likely use, then you can use common sense and re-roll. However, if you use a sufficiently powerful generator, the chance of it generating a likely guessed password is analogous to the chance of you suddenly exploding, because your half of the room is a vacuum.", "Fine, a \"word-based password cracker\". In any case, if they're trying a brute force attack, the word-based password is not inherently more difficult to crack based on character count. It would be based on word count.", "Mhhh with a password manager this could be possible", "Nope, they cant. They are cracking a hash of the passphrase,  not the actual words. \n\nLets say you password is \u201cThree month words\u201d - lets pretend the hash of that is fhruthcb\n\nYou program you cracker to look for 5, three letter words - the cracker than comes up with its first pass \u201cchild doors oreos\u201d and outputs the hash of thise three words - that has equals \u201claksdjfh\u201d. It then compares this hash with the one from our real password. It doesnt match, so it tries for a new set of three, 5 letter words. \u201cTypos swims laser\u201d and compares that hash with the hash from our password. Rinse, repeat, ad infinium. \n\nThis is why length is more important than the content of your password. All the cracker k knows is the hash - it has no idea if the contents inside are words or random crazy characters.  It has to try every permutation to match hash to hash. \n\nThere are shortcuts we take on short passwords.  Its mich easy to crack 10 character passwords no matter what their content - a computer can whip through every single permutations of 10 crazy characters easily.  Wecan even program the cracker to test for the most likely permutations first - like we know most people start their password with a capital letter a d always add the number or symbols at the end, so I can program my cracker to look for UlllllllNNS <\u2014 Upper Lower lower lower lower lower lower lower number number symbol.  This reduces the time to crack because is a super common pattern.  We still are going through all permutations, get the hash and then see if the hash matches the real passwords hash, but I am trying the most likely candidates first a d there are only so many permutations of 10 chars.  But 32 or 64 characters? Impossible in this day and age.  (Who kows what the future will bring - 10 char was once thought to be impossible. \n\nI am a big fan of password managers - they enable you to store hundreds of 64 character passwords without ha ing to memorize them, but there are accounts you want to use passwords on and for those, I think the super long complex sentence/passphrase method works well", "Ah yes thx", "I don't use a password generator or a manager. What if your computer become hacked? all of your passwords stored in the same spot.", "I am learning about Keepass. How dumb it would be to have a copy of the database in dropbox or as an attachment in protonmail or something?\n\nAlso: how do you create 64 character random passwords? can Keepass create the random passwords too? I like the method of Truecrypt for instance where you move the mouse around to create the extra entropy. Keepass integrates a safe way to create such passwords as you add them on the database?", ">I don't use a password generator or a manager.\n\nLooks like we now know how you can improve your password security.\n\n>What if your computer become hacked?\n\nYou have a serious problem on your hands.\n\n>all of your passwords stored in the same spot.\n\nThis is indeed a risk for password managers. But as security professionals, we're concluded that the risk is worth it when the passwords are unique per account and randomly generated. As a result, when password breaches happen, and your account is part of the breach, then only that account is affected, and you're not vulnerable to credential stuffing.\n\nBest practice is to use a password manager.", "You really, really should start using one. For example, Bitwarden is a good one and open source. It has tons of features on the free version and the paid is even better. Using unique long random passwords for each service/app greatly increases security as long as you use the manager wisely. Really, start using one!", "You can always [pepper](https://passwordbits.com/salting-passwords/) your important passwords in your password manager if it makes you feel better. There is no real excuse to not use a password manager these days.", "I don't use the same password for everything, I just have a text file inside an encrypted file to store the passwords.\n\nAnd mega important passwords I have repeated so many times that I have remembered it like my name in case you lose the physical carrying device for such passwords (fire, flood, government becoming like china and so on)", "How do you protect your computer so it doesnt become hacked with all the passwords stored in there?\n\nIn Windows I have Tinywall and default antivirus of Windows 10\n\nIn Linux I use Elementary OS I didn't install any firewalls or antivirus.\n\nI will look into it. But generally, I register on many dumb websites and stuff that I don't really bother much even if it gets hacked. I put passwords on some encrypted text file.\n\nAt the end of the day I only need strong passwords for the email I use for banking, taxes, crypto. Around 4 or 5 passwords that you must remember in your head beside storing it somewhere.", "But then you do have a password manager, except it's more manual and more prone to you making mistakes.", "If you really don't like cloud storage, KeePass or KeePassXC store the database encrypted locally, just like yours. Only difference is KeePass can generate strong (psuedo)random passwords for you, while your brain cannot.", "PW manager does everything for you. It creates strong passwords for all sites, it stores them always with a strong encryption, it syncs the passwords so you can access them using different devices or browsers etc. It is a lot more secure than anything else. As long as your master passphrase is strong enough. And you can further increase the security by using 2FA. \n\nRemember than your passwords are always stored and synced encrypted so nobody can access them besides you. They will be unencrypted only when you actually need to use them.\n\nAnd because all passwords are unique, you don't need to be too worried if one of your passwords is compromised as no other site uses the same. The manager also generates password breach/strength reports for you. You can use as many \"dumb websites\" as you want. The manager will keep up.\n\nAt least check this out:  https://bitwarden.com/\n\nFor computer security I use Windows Defender (the stock antivir). On my work laptop running macOS I think I have F-Secure.", "I'm having trouble understanding.\n\nYou're worried about a password manager's local DB getting hacked, but you're storing you home rolled encrypted file locally? \n\nWhat is it you think password managers do with your data? That DB is encrypted to hell and back.\n\nI have one passphrase that I need to memorize, everything else is generated at random and stored in an encrypted password manager on an encrypted volume.\n\nThe general rule of thumb for cryptography applies here: don't roll your own system. Use what works and had been vetted independently. It doesn't just mean \"pick the right file encryption command line tool,\" it refers to the whole system."]}
{"id": "oqxtzd", "title": "Trending topics in Crypto", "url": "https://www.reddit.com/r/crypto/comments/oqxtzd/trending_topics_in_crypto/", "Created (UTC)": "2021-07-24 13:44:13", "body": "[This is sort of a crosspost - some changes were made]\n\nI am still missing delivering my Thesis in order to finish my MSc in InfoSec and I am striving to find the right topic.\n\nI would like opinions on trending (or future trending) topics regarding crypto, in particular crypto vulnerabilities related-stuff.\n\nFWIW working full-time in InfoSec (mainly vulnerability management of all sorts, specially websites) and have a Maths background.\n\nThanks in advance.", "post URL info": [], "author": "thefrenchunderground", "ups": "9", "downs": "0", "number of comments": "30", "comments": ["You might have a look at [this thread](https://www.reddit.com/r/math/comments/lvtdm5/whats_new_since_the_code_book/) where I comment on major advancements of the last 20 years.", "Zero-knowledge proofs, homomorphic encryption, multiparty computation, AEAD and MRAE encryption modes (TLDR robustness), formal verification, constant time implementations, sidechannel resistance, etc...", "This NIST project on Privacy-Enhancing cryptography might be interesting for you: https://csrc.nist.gov/projects/pec", "[removed]", "Thanks for your reply, aren't all of these theoretical? I haven't yet eliminated theoretical topics but is there any practical stuff worth investigating?", "Stop spamming", "Zero-knowledge proofs and multiparty computation both went from infeasible for most usecases to deployed IRL in the last 5 years, although both still have high overhead.\n\nZerocoin deploys Zero-knowledge proofs for privacy of transactions, as an example. \n\nFormal programming is also getting more common, and constant time implementations and AEAD modes are becoming the default in cryptography libraries.\n\nHomomorphic encryption is still very niche, but has a few uses too."]}
{"id": "oqt9eh", "title": "What is currently the most secure Verifiable Delay Function for randomness beacons?", "url": "https://www.reddit.com/r/crypto/comments/oqt9eh/what_is_currently_the_most_secure_verifiable/", "Created (UTC)": "2021-07-24 09:27:05", "body": "Say an election for US Senator ends in a tie. I want to break the tie, by allowing many parties to contribute randomness to a seed that is run through a VDF to get a winner.\n\nThe Senate election requires an extremely high degree of public trust, all while being a high value target for attackers. However, the VDF is a somewhat new technology, and not necessarily deserving of that trust.\n\nWhat\u2014if any\u2014VDF algorithm can be trusted to hold against both side channel* and mathematical attacks.\n\n*I see an algorithm as resistant to side channel attacks if I don\u2019t have to code it from scratch. If the VDF is based on already implemented primitives, or has been used in production itself, then it would be relatively easy to make an implementation resistant to side channel attacks. I don\u2019t trust myself to role my own crypto.", "post URL info": [], "author": "NCGThompson", "ups": "11", "downs": "0", "number of comments": "32", "comments": ["I can try for curiosity sake, but I really haven't explored this at all and this is just based on first intuition, so smarter people are welcome to shoot it down. \n\nSeed data is received from all parties, concatenated in a prestablished manner and hashed using a known trusted cryptographic hash algorithm. Concatenate the resulting digest with a counter and hash again until that digest's N lowest bits are 0 where N establishes some reasonable amount of work time. The counter value modulo the number of candidates gives you the winner.\n\nIt would seem important that the initial hash input not be predictable to any party such that they could, given enough time, precalculate their own seed contribution for a favourable result.", "I would look into what the Supranational team is doing for VDF competitions and the Stanford VDF Day 2020:\n\n- https://github.com/supranational/vdf-fpga\n- https://github.com/supranational/vdf-fpga-round3-results\n- https://m.youtube.com/playlist?list=PLVpqsHnTzV3cKWkbHAU-bKBLpjGA6ANT-\n\nThey got sponsored by the Ethereum Foundation to come up with a VDF design and then implement it in hardware so that we can estimate the max hardware acceleration that is achievable and take that into account when choosing parameters to ensure protocol fairness.\n\nApplication is the randomness beacon in Ethereum 2 ;).\n\nBe sure to also check the Verifiable Random Function IETF draft:\n\n- https://github.com/google/draft-irtf-cfrg-vrf\n- https://datatracker.ietf.org/doc/html/draft-irtf-cfrg-vrf-01", "[removed]", "[removed]", "This is a variant of secure coin flip protocols. You need to commit the values before publishing them to avoid tampering.", "Stop trying to spam", "This subreddit is about cryptography, not cryptocurrency. We can't help.", "If that\u2019s the case that wouldn\u2019t work. I need to commit the values *by* publishing them.", "Not necessarily - hash based commitment. You don't publish the raw value itself. Once everybody has made and shared a commitment to the random values they prepared in secret, they can publish their random values and combine them.", "I agree that would work. In fact, I\u2019ll probably use that as another layer of security. However that is not what I\u2019m looking for. I want to report a number to the press that I derived from multiple entropy sources, and use that number as an input for a VDF, where the output seeds a virtual coin flip.", ">I want to report a number to the press that I derived from multiple entropy sources\n\nThat sounds risky, because the public can't independently verify or trust the entropy sources, and there is no way for you to prove that the values provided are actually random. When people complain about the results, what do you do?\n\nI think the best method would be to have the source of entropy be limited to the candidates themselves -- since they each want to win, they have an obvious motivation not to collude. \n\nEach candidate chooses a long, arbitrary value, and publishes the hash of that value. Then the candidates all reveal their secret values, which are compared against the published hashes to make sure they were chosen before the other values were revealed. Hash these values together and find the modulus as above to determine the winner.\n\nNone of the candidates can claim the system wasn't fair, because it has already been proven that their chosen value was used.", "Combining additional entropy sources with the candidates can only help. If one entropy source is truly random, but a thousand collude, the result will be truly random.", "Yes, but that also means as long as one candidate doesn't collude, the result is random. If all candidates collude to get a specific person elected, why wouldn't they all just drop out and let that one win by default?\n\nIf there is a situation where it would be possible for all candidates to collude (maybe they are forced into the election and don't actually want to participate?) then you are right, the game theory model can no longer assume selfish actors and you would need external entropy.\n\nEdit: Just to reiterate, the reason I suggested only using candidates is because you want the public to trust the result. If the public believes at least one candidate wants to win and therefore won't collude with others, then they can accept the end result. If you can find a different entropy source that the public will trust just as much as the candidates themselves, that would work fine!", "The candidates\u2019s computers can be hacked. Even if you know a candidate won\u2019t voluntarily collude, you still can\u2019t trust her."]}
{"id": "oq53q1", "title": "Why the ubiquity of Paillier over Okamoto-Uchiyama for additively homomorphic encryption?", "url": "https://www.reddit.com/r/crypto/comments/oq53q1/why_the_ubiquity_of_paillier_over_okamotouchiyama/", "Created (UTC)": "2021-07-23 08:45:48", "body": "In my (very very limited) experience with cryptographic voting schemes, I've *only* seen Paillier's encryption scheme used for tally-able votes. This seems a bit odd as Okamoto and Uchiyama actually introduced the trapdoor function used by Paillier. Is there a reason for this?", "post URL info": [], "author": "natatatonreddit", "ups": "17", "downs": "0", "number of comments": "27", "comments": ["I honestly don't know, but I can give two plausible answers. 1) Politics and just that Paillier became more popular, 2) improvements to Paillier such as Damgard-Jurik makes it attractive if you want better packing.", "Looks nice. Might result in shorter messages, too?", "[removed]", "Why don't you just delete your spambot account(s)? You're not getting through."]}
{"id": "oq54jy", "title": "PASERK: Platform-Agnostic Serialized Keys (PASETO extension)", "url": "https://github.com/paseto-standard/paserk", "Created (UTC)": "2021-07-23 08:46:56", "body": "", "post URL info": [], "author": "paragon_init", "ups": "6", "downs": "0", "number of comments": "15", "comments": ["[removed]", "Stop spamming. A reminder, this is illegal under US and EU law."]}
{"id": "opyclw", "title": "Status Report on the Second Round of the NIST Lightweight Cryptography Standardization Process", "url": "https://nvlpubs.nist.gov/nistpubs/ir/2021/NIST.IR.8369.pdf", "Created (UTC)": "2021-07-23 01:47:41", "body": "", "post URL info": [], "author": "espadrine", "ups": "27", "downs": "0", "number of comments": "17", "comments": []}
{"id": "opykm2", "title": "Secret password that requires multiple keys to decrypt", "url": "https://www.reddit.com/r/crypto/comments/opykm2/secret_password_that_requires_multiple_keys_to/", "Created (UTC)": "2021-07-23 02:05:26", "body": "This is the best place I could think of to ask this, and unfortunately my search terms are so vague that it'll never pop up when I search for it.\n\nI seem to remember a program/\"encryption\" method that you could choose how many passwords were generated, and how many were needed to decrypt the text.\n\nFor a general example, you could enter the text string \"the password is password\" and then generate 3 codes, which would end up being \"fj73abbn4nkdao\" \"jfbn38a9vxvci\" and \"vbn4397anb.\" You could then select how many of them were needed to actually unlock the original text, and you would plug those codes into the program for it to \"decrypt\" them.\n\nI seem to remember it being named after an Indian guy but I don't quite remember if that's the case. I recall seeing it on a YouTube video about some sort of ARG, but I don't remember which one. It was years ago.", "post URL info": [], "author": "TSLPrescott", "ups": "5", "downs": "0", "number of comments": "19", "comments": ["The keyword you are likely looking for is [Shamir's Secret Sharing](https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing) (though Adi Shamir is from Israel, not India).", "Shamir's secret sharing scheme. Or in general terms, threshold encryption schemes.", "There are javascript-based password splitting utilities at http://passguardian.com/ and https://old.reddit.com/r/PasswordSplit/comments/7qhye0/how_to_split_your_passphrase/", "Thank you, that's what it was!", "Thanks, that's it!"]}
{"id": "opm10n", "title": "Do I need a key committing AEAD to be random key robust?", "url": "https://www.reddit.com/r/crypto/comments/opm10n/do_i_need_a_key_committing_aead_to_be_random_key/", "Created (UTC)": "2021-07-22 13:11:48", "body": "So I've learned some time ago that AEAD schemes have the following guarantee:\n\n* Let Alice and Bob agree on some key K.\n* Bob knows for sure it's K, and not some other key.\n* Alice performs (nonce, ad, ciphertext, tag) = AEAD(nonce, ad, plaintext, tag), and sends the whole thing to Bob.\n* If bob successfully authenticates (nonce, ad, ciphertext, tag) under key K, then he knows for sure it was encrypted with key K.\n\nOn the other hand, it is *not* guaranteed that the tuple (nonce, ad, ciphertext, tag) only authenticates under key K. Which means that if there's a way to trick Bob into using a different decryption key, they might get a different message, or simply accept as valid a tuple (Evil_Key, nonce, ad, ciphertext, tag) that is anything but.\n\nOne solution is to use a _key committing AEAD_, that on top of the above guarantee, can only decrypt under key K. There are two obvious ways to do this:\n\n* Replace the polynomial MAC (GHASH, Poly1305\u2026) by a hash based MAC (HMAC-SHA256, BLAKE2\u2026). Note that the MAC must be collision resistant, so it needs to be at least 256 bits ([128 bits of security](https://loup-vaillant.fr/tutorials/128-bits-of-security), similar to Curve25519). The main problem here is that it's generally slower. Polynomial hashes are very hard to beat. Especially GHASH if there's hardware support.\n\n* Encrypt 32 bytes worth of zeroes in addition to the plaintext, and append the encrypted zeroes to the ciphertext. Bob can then encrypt zeroes himself, and compare. The main problems here are the size and computational overhead incurred by those additional 32 bytes, and the potential for timing leaks (we now must perform *two* checks instead of just one, that requires some care).\n\nThose problems tend to compound for file encryption, which would typically be encrypted chunk by chunk: the use of committing AEAD will repeat the overhead for. each. chunk. Not to mention the complications: as a designer and an implementer, it would be so much easier to just pick some standard (and thus non-committing) AEAD scheme and encrypt the chunks with that.\n\n---\n\nSo I thought: how about committing the key separately from the AEAD? I'm thinking of this in the context of file encryption, where it would go like this:\n\n1. Parse the header.\n2. Deduce the encryption key (that's where committment may happen).\n3. Decrypt each chunk (using **non** committing AEAD).\n4. Authenticate padding, if any.\n\nNote that this is not constant time at all. Each step is validated one after the other. If the file is corrupted at a later stage, the recipient will just take longer to notice something is amiss. This breaks IND-CCA2 under timing attacks, (or at all, if the software tells you exactly what went wrong), but I *think* it is generally a good tradeoff, because it enables lightweight streaming encryption and decryption. (Arguments to the contrary are very welcome.)\n\nFirst question: __can we commit the key once and for all on step (2)?__ Here's how I think we could go about it:\n\n1. Use the header do perform any key exchange or password key derivation, get session key KS.\n2. K, H = KDF(KS) (We could use a stream cipher to do that derivation.)\n3. If we are encrypting, write H to the file. If we are decrypting, compare with what is written, and abort if it's different.\n4. Use K to encrypt/decrypt the actual data, using an ordinary AEAD.\n\nWould the use of H successfully commit the key K?\n\n---\n\nI have another related question: __Do interactive protocols like those found in the Noise protocol framework naturally commit the session key?__ And perhaps even more importantly, does that even matter in this context?", "post URL info": ["https://loup-vaillant.fr/tutorials/128-bits-of-security),"], "author": "loup-vaillant", "ups": "22", "downs": "0", "number of comments": "27", "comments": ["Not an answer, but I suspect you'd find [this](https://github.com/BLAKE3-team/BLAKE3/issues/138) proposal for a committing deterministic AEAD mode in BLAKE3 interesting.\n\nAnother way I think would work is\n\n1. Use the header to perform any key exchange or password-based key derivation, get session key KS and initial nonce IV a la libsodium's secretstream.\n2. EncryptionKey = keyed_hash(key=IV, input=(KS || \"EncryptionKey\")) (use a keyed hash or KDF, with the IV as the key and the session key + a context string as the input)\n3. KeyCommitment = keyed_hash(key=IV, input=(KS || \"KeyCommitment\")) (use a keyed hash or KDF, with the IV as the key and the session key + a context string as the input)\n4. If encrypting, write the KeyCommitment to the AD or plaintext of the file. If decrypting, compare with what is written, and abort if different.\n5. Use K to encrypt/decrypt the data, using an ordinary AEAD.\n\nThe disadvantage of your method is that I think it leaks the identity of the key. As long as the commitment value gets incorporated into the tag of the AEAD there are no additional checks needed. There's still the size and computational overhead issue, but in a chunked file situation I think this is still fine \"detached\" and put in a header with the other AD (if any). Steps 2 & 3 could be combined without the context strings, assuming a long enough output from the keyed hash or KDF. EG Blake3's `Hasher` has `new_keyed` for keyed hash mode, and `finalize_xof` to provide arbitrary-length output.", "From [the PASETO v3 draft specification](https://github.com/paragonie/paseto/pull/127):\n\n> ### Why Not AES-GCM in `v3.local`?\n> \n> While it's true that AES-GCM is more broadly supported in environments that use\n> NIST and FIPS-approved cryptography, GMAC is neither\n> [message-committing nor key-committing](https://eprint.iacr.org/2019/016).\n> \n> The techniques for turning an AEAD scheme into an AEAD scheme [is well known](https://eprint.iacr.org/2020/1153),\n> but it requires publishing an additional SHA2 hash (or KDF output) of the\n> key being used.\n> \n> Using GCM would require us to also publish an additional hash _anyway_. At\n> that point, it doesn't offer any clear advantage over CTR+HMAC.\n> \n> CTR+HMAC (with separate keys and PAE) is a secure construction and provides\n> the cryptographic properties we need to use PASETO in threat models where\n> multiple keys are used or [partitioning oracles](https://eprint.iacr.org/2020/1491)\n> are possible.\n\nI think the argument here is:\n\nFor transport-layer cryptography, revealing the HMAC of the key during the handshake phase is sufficient to fix it for all subsequent packets. https://eprint.iacr.org/2020/1153\n\nFor application-layer cryptography, just using a different MAC is probably the best move, since this is a per-message check.\n\nEncrypting zeroes *works* but there was a hardware side-channel published last year where some processors handle sequences of `0x00` bytes detectably faster than sequences of `0xFF` bytes. It might be better to prefix the message with a 256-bit domain separation constant and compare that in constant-time if you go this route.", "> The disadvantage of your method is that I think it leaks the identity of the key.\n\nOops, my bad, I forgot to use a nonce to guarantee that KeyCommitment would be unique. An alternative would be to use a fresh random session key every time. If I can achieve that, we don't care about leaking its identity. So:\n\n* For public key encryption, the sender would presumably use an ephemeral key, which naturally randomises the session key.\n* For password based encryption, the password derivation can use a random nonce to randomise the key.\n\nI may be forced to use those tricks anyway, because of two things:\n\n* Ultimately, I want a PURB: the whole thing must look absolutely random to adversaries who don't know the password, or don't have the recipient's keys.\n* I also want to support multiple recipients. That means coming up with a random session key KS, and writing down K1\u00a0XOR\u00a0KS, K2\u00a0XOR\u00a0KS etc. where K1, K2 etc. may be password derived keys. If two recipients happen to use the same password, I would end up with a repetition in the file, destroying the random property (and leaking the fact that a password is being reused). Also, if K1 and K2 are related in any way, I'm afraid it could leak information about KS.", "> Encrypting zeroes works but there was a hardware side-channel published last year where some processors handle sequences of 0x00 bytes detectably faster than sequences of 0xFF bytes.\n\nNot doubting you, but I've been having trouble to find this and I want to read the original paper. Do you perchance recall what it was called?", "> For transport-layer cryptography, revealing the HMAC of the key during the handshake phase is sufficient to fix it for all subsequent packets.\n\nI believe that answers it then, thanks. (If I view file encryption as a non interactive handshake followed by a stream of encrypted packets).\n\n> While it's true that AES-GCM is more broadly supported in environments that use NIST and FIPS-approved cryptography, GMAC is neither message-committing nor key-committing.\n\nWait a minute, is message commitment a thing? I mean, key commitment is the inability for an attacker to find a new key under which the message (and tag) would authenticate.\n\nMessage commitment on the other hand would be\u2026 the inability to change the message and still authenticate it? But AEAD already guarantees that, as long as the key stays secret. And if the key *isn't* secret, the attacker can just compute the right tag.\n\nWas this sentence you quoted ill formed, or did I miss something?\n\n> Encrypting zeroes works but there was a hardware side-channel published last year where some processors handle sequences of 0x00 bytes detectably faster than sequences of 0xFF bytes.\n\nWTF?? I learned something today. Keeping that in mind, thanks.", "> Encrypting zeroes _works_ but there was a hardware side-channel published last year where some processors handle sequences of `0x00` bytes detectably faster than sequences of `0xFF` bytes. \n\nI just realised that we can get around this problem in our case: the fact that we're encrypting zeroes, and not anything else is public knowledge. So while encrypting zeroes might be faster than encrypting some other text, that's not a problem, because timings are only leaking public information here.\n\nAnd the encrypted zeroes are anything *but* zeroes, so we should be more able to compare them in constant time. So, while *decrypting* this text and compare with zeroes might be a bad idea, encrypting zeroes and verifying that we get the same ciphertext should be okay. Plus, it's easier with counter modes like AES-CTR and ChaCha20.", "https://twitter.com/BRIAN_____/status/1260913021116993536\n\nThat's because it wasn't a paper.", "If I understand what you\u2019re describing around message commitment, I think \u201cmessage franking\u201c may be aligned with it too. When I first heard about the compact committing key schemes in ECDH-1PU draft to prevent the KCI attacks, the underlying academic paper made a lot of comparisons between message franking and compact committing schemes. If I understood the paper correctly message franking was supposed to be for message commitments and compact committing AEAD schemes were for key commitments.\n\nEdit: Here\u2019s a link to the paper I was referring to https://eprint.iacr.org/2017/664.pdf", ">> While it's true that AES-GCM is more broadly supported in environments that use NIST and FIPS-approved cryptography, GMAC is neither message-committing nor key-committing.\n\n#\n> Wait a minute, is message commitment a thing? I mean, key commitment is the inability for an attacker to find a new key under which the message (and tag) would authenticate.\n\nA third party attacker who doesn't have the key can't do it.\n\nSomebody who sends a message to 2 parties with the same key can trick them both to believe they got the same message when they in fact have received different messages.", "Thanks!", "I wrote the ECDH-1PU draft. I also wrote this blog which goes into a bit more detail about why you want \u201cmessage commitment\u201d: https://neilmadden.blog/2021/02/16/when-a-kem-is-not-enough/ (scroll down to \u201cAuthenticated mKEMs\u201d).", "Oh, I see, using the tag as a message identifier\u2026 Got it: so, if the recipient knows that they're using the right key, and the message successfully decrypts:\n\n- It means the sender knew the key as well.\n- It does *not* mean this is the only message they sent with that particular tag.\n\nMakes sense."]}
{"id": "oph365", "title": "Hidden volumes: what's the consensus nowadays?", "url": "https://www.reddit.com/r/crypto/comments/oph365/hidden_volumes_whats_the_consensus_nowadays/", "Created (UTC)": "2021-07-22 09:13:54", "body": "I remember being told to not use hidden OS volumes on Veracrypt because it was just dumb unless you are dealing with an computer illiterate. But say some government goes full on communist/nazi and wants your coins. Kicks your door and starts checking for stuff where you could store coins. What do we know?\n\n\\-Full disk encryption: They can 5$ wrench your ass or they will be more polite and just put you in jail and throw the key until you decrypt.\n\n\\-Full disk encryption with hidden OS: They can easily know there is a hidden volume\n\n\\-Hidden volume in a Veracrypt container: Will this do the trick? can do they know you are hiding something?\n\n\\-You could always upload to some online service but this opens many additional risks: like they knowing you bought such a service, accessed it, or they going bankrupt/getting bought by your favorite 3 letter agency and exposing your data/any other data loss/hack that's not your fault because you don't control the servers. Also the bad feeling of permanently leaving a copy of your data somewhere else even if encrypted, you never know. Now with digital coins being a thing the incentive to bruteforce on everything is insanely higher compared to in the past. It's like seeking for treasures.\n\nWhat can be done in terms of plausible deniability these days? people are getting stopped on airports and stuff forced to decrypt and they make dumps of your drives. That's not fun. We need to be 3 steps ahead with these guys.\n\nMy conclusion is that full disk encryption is a liability because you either decrypt or you don't.\n\nWith volumes, you can hide them. However, forensics have tools which as far as I know can detect a vera hidden volume even if very well hidden inside other files, but at least that's better than a plain \"enter password\" situation by just turning on the computer.\n\nAnd then if they found the file we have hidden volumes, this could save you assuming it really works and they cannot claim you are hiding something.\n\nSo having said that and considering any other possible scenarios, what's the best way to go about this?", "post URL info": [], "author": "cryptomann1", "ups": "12", "downs": "0", "number of comments": "26", "comments": ["I've written about plausible deniability and some problems with hidden volumes before: https://spacetime.dev/plausibly-deniable-encryption", ">What can be done in terms of plausible deniability these days? people are getting stopped on airports and stuff forced to decrypt and they make dumps of your drives. That's not fun. We need to be 3 steps ahead with these guys.\n\nDon't carry encrypted data with you. What do you expect them to do if you say that you do not know the password? Let you go? Try that with China and see how that goes.\n\nDon't spend your time wargamming when a rubber hose is cheap and available. If a superpower wants you data, they'll get your data. Minimize the number of occasions where you and the data are in the same place.\n\nIf you want to go down the privacy fever dreams of wargamming how you, the special one, can beat a superpower at their game, /r/privacy <- is that way.", "Problem with plausible deniability and rubber hoses is that if you don't caught up what they want they just keep hitting you with a wrench.\n\nBetter to just not have the ability to give it up.", "if anyone suspects you have information they want and are willing to break the law to get it from you, the only \"plausible deniability\" going on will be whether you're in their custody or not. no government cares about \"your coins\". if your password can be brute forced it and/or your kdf is too weak.", "What is not hidden cannot be found.", "But can you spot a Veracrypt hidden container that is hidden inside a Veracrypt hidden container?", "In other words RAID 0 Striped Data with full encrypted drives. Carry one and mail the other", ">Don't carry encrypted data with you. What do you expect them to do ifyou say that you do not know the password? Let you go? Try that withChina and see how that goes\n\nThis is why im talking about hidden volumes and in any case how to solve the \"do not carry anything with you problem\" which involves either putting the files online temporarily (Where and how?) or hiding the files well enough that it passes border control.\n\n&#x200B;\n\n>Don't spend your time wargamming when a rubber hose is cheap andavailable. If a superpower wants you data, they'll get your data.Minimize the number of occasions where you and the data are in the sameplace.\n\nThis is not being about some dangerous most wanted global list terrorist or something, this is about basic privacy, about random stops in border control, or a situation where governments go insane and knock in everyone that has withdrawn coins from exchanges into local wallets in a massive scale operation etc. What I mean is non targeted personally.\n\nThere are things we can do. There's people permanently in jail because they defused to decrypt, so im not buying the US has superpowers to decrypt passwords. So it's a matter of having a strong enough password, knowing it is strong enough (how) and then hiding the files (hidden volumes, or cloud storage, again this needs further research).\n\nYou are too pessimistic IMO, we can do some things.", "How do you check if your password is strong enough to not be bruteforced by govs?  \nThere's people permanently in jail because they refused to decrypt so im not buying this magic super power of governments being able to bruteforce passwords. It's just a matter of \n\n1) Having a strong enough password\n\n2) Hiddin the containers", "Why bother, just mail them both", "[removed]", "Huh?", "Somebody who doesn't know what this sub is about"]}
{"id": "oon0co", "title": "Is it even possible to securely wipe an SSD - 2 months journey.", "url": "https://www.reddit.com/r/crypto/comments/oon0co/is_it_even_possible_to_securely_wipe_an_ssd_2/", "Created (UTC)": "2021-07-21 03:17:59", "body": "After about a few months of constantly trying to sell my computer protecting myself from data theft and constantly hearing different voices - believe it or not - I am really clueless. There are two options - either buy a totally new SSD, or still try to wipe the actual one.\n\nThe biggest problem: Upon starting using my SSD I had no idea about encryption techniques. And I think it was really, really a big mistake.\n\n**So far what I understood:**\n\n\\- DBAN does not work - have a notice on the first page [https://dban.org](https://dban.org)\n\n\\- Personal manafacuter-made SSD sanitization tool COULD work - in my case did not find anything released for that occasion\n\n\\- found today this [https://support.lenovo.com/us/en/downloads/ds019026-thinkpad-drive-erase-utility-for-resetting-the-cryptographic-key-and-erasing-the-solid-state-drive-thinkpad](https://support.lenovo.com/us/en/downloads/ds019026-thinkpad-drive-erase-utility-for-resetting-the-cryptographic-key-and-erasing-the-solid-state-drive-thinkpad) which even matches my laptop model.\n\n\\- I also read the following\n\n>With SSDs, you may need to clear the registers before writing data for  performance reasons, but that's about it. If you're paranoid, you can  overwrite the container headers to remove the possibility of decrypting  the data. But really, I would just reformat, and move on.\n\n\\- and this\n\n>1: Simply send the SATA (or NVME) Secure Erase Command. This tells the  firmware to do a wipe and is only the serious option for a SSD as you  can't access the raw flash directly.  \n>  \n>2: Beware that not all SSD:s implement it correctly. Might look up an old article on this later.\n\n**Conclusion:** \n\nforget about DBAN, my SSD does not have any custom software, lenovo link states to offer \"This Drive Erase Utility for the Resetting the Cryptographic Key and the  Erasing the Solid State Drive resets the Cryptographic Key of Full Disk  Encryption(FDE) supported hard drives(HDD) and erases the Solid State  Drive(SSD)\", SATA secure erase command could work, but not always\n\n**My re-organized questions then - in the form of potential steps - step 1 = question 1, step 2 = question 2 etc.**\n\n1. Should I then use the custom lenovo software ?\n2. How do I know if SATA secure erase command will work for my SSD?\n3. &#x200B;\n\n>you may need to clear the registers before writing data for  performance reasons, but that's about it. If you're paranoid, you can  overwrite the container headers to remove the possibility of decrypting  the data\n\n3.1 Cleaning the registers - how to perform that and should I?\n\n3.2. Overwriting the container headers -  how to perform that and should I?\n\nALTERNATIVE FOR ALL MY QUESTIONS 4. IDIOT FRIENDLY - if you could provide me with easy to digest steps that you would to, I think I would have appreciate it even more. I am.. desperate.", "post URL info": ["https://dban.org](https://dban.org)", "https://support.lenovo.com/us/en/downloads/ds019026-thinkpad-drive-erase-utility-for-resetting-the-cryptographic-key-and-erasing-the-solid-state-drive-thinkpad](https://support.lenovo.com/us/en/downloads/ds019026-thinkpad-drive-erase-utility-for-resetting-the-cryptographic-key-and-erasing-the-solid-state-drive-thinkpad)"], "author": "MicroBoy4441", "ups": "3", "downs": "0", "number of comments": "59", "comments": ["FYI, this is double posting, which is cluttering our low volume subreddit.\n\nI'm letting this one remain, but I want to point out that unlike on Stack Exchange, new questions on the exact same topic as in an open thread does NOT need to be posted in a new thread, it should instead be asked in the same thread as the original question. Especially so when it's the same user who has multiple questions, follow-ups should be done in the same thread.", "If you're that concerned about someone buying your PC and immediately trying to recover something from it, sell it without the SSD or just buy a new one (they are pretty damn cheap).\n\nThere is no point in all this hand-wringing. A regular buyer will just install his stuff and get on with it.\n\nIf you want to deep dive down to the privacy fever dream territory where everyone is a constant target, /r/privacy <- is that way.", "You seem to have dived deeper into this subject than I ever did. I just issued the secure erase command which to my understanding resets the NOR flash state. I just confirmed that by opening the device with hexdump and see only zero.\n\nI admire that you take this seriously. I try to restore as much as I can if a buy a used harddrive/ssd/SD-cards. Mostly for the challenge but I have found some serious stuff...", "Why not sell it without the ssd?", "Physically destroy it. It's you're only bullet proof guarantee the data cannot be recovered. Sell the laptop without the drive.", "Contrary to what most everyone in this thread is saying, there's only one way to be sure of getting it all, and it's only available on quality SSDs - if you bought an SSD from a fly-by-night manufacturer, results vary wildly.\n\nIt's incredibly analogous to the `memzero()` problem - we've engineered systems for read, write, and lifetime performance to the extreme, and so the controllers have gotten very sophisticated at handling block garbage collection. They easily find blocks to churn rather than modifying stateful blocks. `dd` simply will not work in a timely fashion (nor is it guaranteed to work at all depending on the actual implementation of the drive's firmware) - the firmware will happily cycle through 'hot blocks' rather than assign 'cold blocks' to be overwritten, in an attempt to preserve the drive's functional life. And thus, most existing tools designed to work on hard disks simply will not.\n\nThat doesn't mean it's not possible. The commandset that SSDs make available via their interfaces contains a \"secure delete\" function - on SATA interfaces it's called \"secure erase\", on NVMe interfaces of a modern make it's called \"sanitize\". It's the *only* reliable function to remove the data on a block, and unfortunately it's always optional - cheaper manufacturers simply don't implement it, as it's expensive and verification of the functionality after every firmware change across all of their models is inconvenient. Buying from quality manufacturers makes it more likely the function is implemented, albeit they will sometimes charge more to make it available - it's sometimes used as an \"enterprise\" feature.\n\nCheck that your tool understands how to issue the \"secure delete\" command to whatever kind of SSD you have, and that your SSD supports it. If it doesn't, destroy it - there's honestly no other way to be sure. And in the future, all SSDs should be encrypted from out of the package, with a key under your control which you can destroy at leisure.", "If you're really worried about SSD data remanence and didn't initially encrypt the drive, [one option is a hard drive shredder](https://www.youtube.com/watch?v=wb3Xa1h_RqM&t=9s).", "- Install a Linux distro e.g. Ubuntu (nice and easy), selecting the option which removes any old partitions and will use the whole drive.\n- Install TrueCrypt 7.1a from a reputable source (audit site).\n- Create a maximum size TC volume allowed (using up the remaining free space) then wait a few hours while it fills the disk with a huge file full of cryptographically secure pseudo random bytes.\n- Format and install whatever OS then sell.", "Reinstall windows and download Glary Utilities and then click Wipe Free Space. This is not like an old hard drive where there's some magnetic \"ghost image\" that a forensic analyst with a microscope can view. Once an SSD chip is overwritten, the data is gone. You can also use Bleachbit and overwrite several times if you're super paranoid. If Hilary Clinton used Bleachbit, then you can use it with confidence. To recover anything left you would need million dollar forensic equipment, you can't just use Undelete, and no consumer will ever be able to recover anything.", "SSD doesn't leave residual data like a magnetic platter drive does. You format an SSD, and the data is dead. Regular hard drives have a map of where your data is, and when you erase it, it just labels that plot of land as ready for use, but it doesn't actually knock the house down until something else gets written there. When you format an SSD, you tell it to flatten the whole countryside.", "There was a thread recently on that, but i can't seem to find it, perhaps someone else can? or was it on r/cryptography .... not sure.", "I bought a desktop from a defense contractor years ago and recovered a ton of stuff.   I did not expect that.", "Note that because of wear leveling, a drive showing up as all-zero in software does not necessarily mean all data is gone.", "unnecessarily complicated. there are tools that override the entire disk. however, modern ssds have wear levelling and spare sectors, thus this is not reliable. the only reliable method is to change the internal encryption key, if possible. if not, just burn the thing.", "No need to use anything but the built in LUKS encryption. But even that isn't doing much over just booting SystemRescueCD and doing a full reformat.\n\nBeware of untouched sectors due to wear leveling.\n\nAlso, info to OP: the encryption key clearing feature is used after you have enabled the disk's integrated disk encryption function. If you never enabled the integrated disk encryption, this feature doesn't help. However if the function is available you could try enabling it, but I don't know if this will cause it to encrypt the full disk on its own, clearing every sector (you may need to attempt to fill the disk once).", "As noted in other comments, this assumes fully trustworthy firmware and no issues with wear leveling", "Beware of wear leveling using overprovisioning of storage along with sectors flagged as disabled after wear. SSD:s do not expose raw storage sectors, it exposes logical storage sectors which it maps internally to physical sectors.\n\nIf you control the firmware or have a reliable erase function available via the firmware then it is easy, but you can't bet on that.", "Twice\n\nhttps://www.reddit.com/r/crypto/comments/oobmpc\n\nhttps://www.reddit.com/r/crypto/comments/oo80fq", "> the only reliable method is to change the internal encryption key, if possible.\n\nJust for the record, that's what ATA Secure Erase is supposed to do on SSDs and modern HDDs. Ought to be pretty foolproof for vendors to implement, though I won't be surprised if some *still* managed to fuck it up.", "Due to your reputation I will allow myself to ask you something. \n\nLet me get it straight:\n\n1. formatting an entire SSD with SystemRescueCD/other tool\n2. encrypting it with LUKS along installing Linux\n\n\\- NO DBAN/NO Bruce Scheiener wiping afterwards/before?\n\nWould that give me some sort of additional safety from my actually deployed .txt and .docs?", "How much and what is left after:\n\nsudo dd if=/dev/zero of=/dev/sda \n\nsudo dd if=/dev/zero of=/dev/boot\n\nsudo dd if=/dev/zero of=/dev/swap\n\n\nrun from a live USB?", "1 and 2 are effectively equivalent in terms of function - you write to all sectors once.\n\nEncrypting is a bit more likely to fill the available sectors due to integrated compression capabilities in the SSD controller, however, so 2 alone is more reliable - when you run a full format, the computer may simply write blank sectors to disk, which the SSD may compress and thus leave some sectors untouched. \n\nNote that option 2 would be done by using a Linux distro where the installer has a built in function for enabling LUKS, and simply enabling it during installation - then fill the disk once, ensuring all sectors are filled. LUKS is a Linux feature, not a separate program.\n\nDBAN and equivalent literally just does the same thing - write something to the disk which looks random. It just does it slightly differently.\n\nBut a dedicated eraser tool which simply writes random bits in one pass is the simplest to use. No need to install Linux and all that. I think SystemRescueCD may even have such tools available, so you can make it bootable from a USB drive and run that with minimal fuss. Just create a LiveUSB with SystemRescueCD, boot the computer with it, run the eraser tool. Done.\n\n~~Edit: also since when do I have a reputation, lol~~", "Depends entirely on how the drive implements wear leveling. If some of the sectors you have written sensitive data to are inactive, this won't touch them.", "As always easy to digest answer. Really appreciate it Natanael_L!\n\nMy summary;\n\n1. Dedicated eraser tool from SystemRescueCD (USB!) first or last step?\n\n2. Delete all partitions\n\n3. encrypting one giant partition with LUKS along installing Linux\n\n4. Dedicated eraser tool from SystemRescueCD (USB!) first or last step?", "Thanks for pointing out wear leveling. I will look into it.", "1: only step! You only need one overwrite pass - assuming the disk exposes all sectors for writes.\n\n2 & 3: not necessary if you've done 1. But this is a second alternative to 1. Again, note that LUKS is a part of the Linux OS, so it's rather the other order of events - install Linux, and make sure LUKS is enabled during installation. Or enable it afterwards. Then fill the disk, if LUKS didn't perform a full overwrite pass (if it did, you don't need to do anything extra). \n\n4: see 1-3", "My last queston would have to be: What is\"Dedicated eraser tool\", called on SystemRescueCD?", "Here's docs:\n\nhttps://www.system-rescue.org/manual/Secure_Deletion_of_Data/\n\nKeep in mind that they are overly cautious in this text. A single pseudorandom overwrite pass is good enough - assuming wear leveling won't screw you over. \n\nThey give a suitable example command here;\n\n> shred -v -n 1 /dev/fd0 \n\n> Shred will overwrite the floppy with one random pass.\n\nReplace /dev/fd0 with the disk mount label that your SSD will have been given.\n\nAll such full disk overwrites will overwrite any volume headers or equivalent filesystem data. \n\nAlso, since SystemRescueCD has most of these tools installed, you can use it to run the SSD secure delete command too, see instructions here (this requires that the SSD has a correct implementation of secure delete, not all has it);\n\nhttps://techgage.com/article/securely-erasing-your-ssd-with-linux-a-how-to/\n\nLook at the hdparm command line options. The instructions show how to find out if the command is available on your SSD. However, availability of the command doesn't guarantee it will work. \n\n> hdparm \u2013security-erase PASS /dev/sdX\n\nWhere sdX is replaced by the drive label that your SSD gets.\n\nEdit: the best approach is IMHO using both a standard overwrite and also the SSD secure delete command, since each command individually has some risk of leaving sensitive data behind, but because they use different mechanisms then the total risk of failure is lower when you use both.\n\nBut multiple overwrites is not going to help versus a single overwrite, that's just using the same mechanism twice.\n\nIf you additionally want to use the Lenovo tool then you might try it, as it may potentially be using yet another mechanism for erasure (most likely is that it just runs the secure delete command, however).", "I dont know how to thank you.\n\nAbout the reputation of yours you doubted in the previous post: my assumption was based on Karma, but you confirmed that its not just numbers my friend.\n\nReally appreciate it!", "All those karma points aren't from this sub, heh (but I am a mod here, and people haven't fled yet) \n\nYou're welcome"]}
{"id": "onyjmw", "title": "Cryptanalysis of Meow Hash", "url": "https://peter.website/meow-hash-cryptanalysis", "Created (UTC)": "2021-07-20 02:17:31", "body": "", "post URL info": [], "author": "Soatok", "ups": "67", "downs": "0", "number of comments": "40", "comments": ["Reason number 146729 not to roll your own crypto. Even really smart people mess up when writing this stuff.", "I'd wager Peter knows more about meow hash internals than the developers did.\n\nThat is quite the write up with graphics and interactive puzzle!", "The [\u201chash levels\u201d page](http://nohatcoder.dk/2019-05-19-1.html) has done harm. Through its lack of formalism, it made hash dabblers believe that all they needed, to have some cryptographic properties, is to claim a level and wait for someone to disprove it. So they claim too high a level with too little evidence, and someone bites the bait in production.\n\nTake [the Meow README](https://github.com/cmuratori/meow_hash/blob/master/README.md):\n\n> Due to recent discoveries by Peter Schmidt-Nielsen, we have decided to reclassify Meow hash 0.5/calico from level 3 to level 1.\n\nLevel 1 indicates:\n\n> A level 1 hash should, given two different inputs, produce a collision with a probability of 1 in 2^n.\n\nHow the inputs are selected is unspecified, but in the charitable interpretation of \u201cselected uniformly at random across all possible inputs,\u201d it cannot be achieved for MeowHash. The finalization is a surjection; if each 128-bit hash output has 2^(1024-128) states (of 128-byte size) that yield that hash, once the first input has been selected uniformly at random, the second input is one of 2^1024 - 1 possibilities, thus the best achievable probability of a collision is (2^896 - 1) \u00f7 (2^1024 - 1), which is objectively distinct from 2^-128.\n\nI think we can all agree this is a very silly reason for a hash to fail to achieve level 1 in a hash categorization, and so it is more the fault of the categorization than a fault of the hash design.\n\n(And there\u2019s an argument to be had that under that definition, Meow also doesn\u2019t match level 1 because of the weak keys described in the article.)\n\nThere is a blog post brewing in my hands, because there is so much that can be said on this topic.", "[removed]", "> The creators make a few security claims; we will break them all.\n\nThe perfect way to start a cryptanalysis paper and make sure you have everyone's attention.", ">The [\u201chash levels\u201d page](http://nohatcoder.dk/2019-05-19-1.html) has done harm. Through its lack of formalism, it made hash dabblers believe that all they needed, to have some cryptographic properties, is to claim a level and wait for someone to disprove it. So they claim too high a level with too little evidence, and someone bites the bait in production.\n\nCareful with your verbiage. I don't believe it's \"done harm\". You would need to prove that people have actually had data compromise or identity theft. I don't know that's the case here. I certainly agree the hash levels definition is dangerous, but I'm not sure anyone nor their personal data has been harmed by it.", "I really don't know what harm you are referring to. Hash dabblers have been there long before that definition, publishing functions with seeds that do squat, up to and including having no effect on whether two inputs collide.\n\nWith no hash level definition you can't even call these functions broken, the author typically won't understand what a seed is supposed to do. See for instance https://github.com/Cyan4973/xxHash/issues/180\n\nAs for the collision probability you mention, you forget that two different inputs may produce the same internal state, that accounts for the difference you observe.", "[No](https://cryptoisnotcryptocurrency.com).", "I am thinking of [the denials of service](https://static.usenix.org/event/sec03/tech/full_papers/crosby/crosby_html/) that [plagued](https://www.aumasson.jp/siphash/siphashdos_29c3_slides.pdf) various [online systems](https://www.youtube.com/watch?v=R2Cq3CLI6H8) over [the years](https://twitter.com/mik235/status/1135335887334547456).\n\nI understand your sentiment, and indeed there has been no loss of life. It is a costly weigh on our industry however, similar to the effects of [Algol\u2019s null reference](https://www.infoq.com/presentations/Null-References-The-Billion-Dollar-Mistake-Tony-Hoare/).\n\nIMO it is much easier to correct than null pointers, but it does require raising awareness about the actual differential analyses etc. that are required as evidence that a MAC has the expected security we want from it. Otherwise, designers will make and promote new insecure MACs, and programmers will want to use the faster not-actually-a-MAC rather than actual MACs.", "Hi! Would you consider making the following changes?\n\n1. Could you describe the properties using the precise formalism of the advantage of all adversarial algorithms against a given game, for each of them? Ideally, naming them in a way that matches their common name, like \u201cdiffuse hash\u201d, \u201ccollision-resistant hash\u201d, \u201cMAC\u201d? It would both make those properties something they can mathematically study for their design, and put them in the point of view of an attacker. It would also avoid the hand-waviness that seems to cause an \u201cI bet it's good-enough for this\u201d approach to picking a level.\n2. Could you add to each, what evidence designers would be expected to provide? (Best differential and linear trails, proof of the construction under the assumption of an idealized primitive, etc.)\n3. Could you separate the classification between keyed and unkeyed? They fundamentally target different use-cases in my eyes, so level 5 is not supposed to be stronger than level 3 in a way that makes sense. Also, could you drop level 2? Beyond being unachievable, since the attacker\u2019s allotted computational power is not bounded, it permits the attacker guessing the key, which wouldn't prevent a DoS as claimed at the bottom.", "1. I'm not sure exactly what you are asking, seems to describe pretty much what I have already done. If you think anything is unclear you'll have to be a bit more specific. Maybe you could give an example of how you would like the text changed.\n2. I think that is outside of scope, and a somewhat subjective question.\n3. I see the principal objection to ranking 4 and 5 above 3. In practice though you can always trivially turn a level 4 or 5 hash into a level 3 hash, whereas the reverse is not usually possible, and we generally expect that more computation is needed to satisfy the higher levels, so I think the ordering makes reasonable sense. The idea of level 2 is that it works where an attacker gets no feedback. If you can cause something to be inserted into a hash table, but can't time it, it doesn't matter how much computation you have, because you have no data to feed into your super computer. Level 2 may be a bit fringe, but it is a distinct class, so I think it deserves mention.", "For 1, let\u2019s take the example of a MAC, where you play the [\"unforgeable against chosen message attack\" (UF-CMA) game](https://cseweb.ucsd.edu/~mihir/cse207/slides/s-mac.pdf). You then ask, for all possible inputs of the following algorithm, that the number of instructions it takes to execute, divided by the probability that it outputs \"true\", be below 2^s, where `s` is the security level.\n\n```\nprocedure UFCMA(adversary):\n  key \u2190 random_sample({0, 1}^k)\n  queries \u2190 {}\n  procedure query_mac(message):\n    queries \u2190 queries \u222a {message}\n    return mac(message, key)\n  adversary.request_queries(query_mac)\n  forgery \u2190 adversary.forgery_attempt()\n  return forgery.message \u2209 queries \u2227 forgery.mac = mac(forgery.message, key)\n```\n\nIt is an [unambiguous and consistent style of formulation](https://cseweb.ucsd.edu/~mihir/cse207/slides/s-mac.pdf) [that you will find](https://crypto.stanford.edu/~dabo/courses/OnlineCrypto/slides/05-integrity-v2-annotated.pdf) [in cryptographic textbooks](https://web.engr.oregonstate.edu/~rosulekm/crypto/chap10.pdf).\n\nNot sure 2 is all that subjective. Designers without prior experience need guidance on what evidence to provide for their claims; them making claims without evidence may indeed be what we are used to, but it is not how things ought to be, and indeed cryptographers expect that evidence in the initial publication.", "[Fixed formatting.](https://np.reddit.com/r/backtickbot/comments/osavpm/httpsnpredditcomrcryptocommentsonyjmwcryptanalysis/)\n\nHello, espadrine: code blocks using triple backticks (\\`\\`\\`) don't work on all versions of Reddit!\n\nSome users see [this](https://stalas.alm.lt/backformat/h6n8thf.png) / [this](https://stalas.alm.lt/backformat/h6n8thf.html) instead.\n\nTo fix this, **indent every line with 4 spaces** instead.\n\n[FAQ](https://www.reddit.com/r/backtickbot/wiki/index)\n\n^(You can opt out by replying with backtickopt6 to this comment.)", "1. I don't see how that would be an improvement, even fewer people would be able to understand it.\n2. It is subjective enough that someone will disagree no matter what I write, but really, it is not part of the definition, so it doesn't belong in this text.", "We can have it look more like C if it helps understandability. I don\u2019t think there is any significant barrier to comprehension otherwise. You understood it: why do you think others would not? And it is unambiguous (which is why cryptographers use it), unlike the current definitions.\n\nOn 2, it is objective enough that all cryptographic hashes presented in the past decade provide differential cryptanalysis in their paper. It does not need to be part of the definition of a cryptographic hash, since failing that analysis yields a break according to the definition."]}
{"id": "ooh274", "title": "Using a new key with every character of text", "url": "https://www.reddit.com/r/crypto/comments/ooh274/using_a_new_key_with_every_character_of_text/", "Created (UTC)": "2021-07-20 19:40:02", "body": "Schemes like AES perform frequent key exchanges to make cracking one message/key not compromise the other messages. What if you applied this concept to every single character or byte of text? I imagine this would take a very long time, but would it end up being x times as difficult to crack, where x is the number of characters or bytes (depending on which you used)? At a certain point you could just guess the remaining characters, so maybe it would only be 1/4x as difficult or something like that. \n\nFor practical uses, I could imagine an encrypted messaging tool that let you choose \"how secure\" to make your message. There could be some sort of slider that says, \"This will take 100 years to crack, and take 1 second to encrypt. This higher setting will take 10,000 years to crack and take 100 seconds\".", "post URL info": [], "author": "TrainSudden", "ups": "2", "downs": "0", "number of comments": "27", "comments": ["Technically, some schemes already do that. Not with a fully new key, but with randomization per block. Stream ciphers generate key pads with a pseudorandom key stream bit for each data bit, while chaining mode ciphers uses each previous block as an input for the next to randomize the encryption.\n\nThere's also ratchet constructions where new keys are continously derived for each new message, like with Signal's double hash ratchet.\n\nMost systems do not perform a full key exchange for every message, in particular since it would typically be very inefficient, and also since the key exchange itself relies on mathematical security assumptions which hypothetically could be broken, meaning that instead of trusting AES you will be trusting a Diffie-Hellman key exchange.\n\nIf the goal is to make extra hard to break the encryption, use 256 bit key ciphers, slow KDF:s, and key exchanges with higher security margins (like curve448 and/or post-quantum algorithms)", "A few problems with this approach:\n\n-  you'd be limited to sending x characters, x being the number of keys you communicated.\n- a huge increase in the communication cost\n- it only increases the computation cost of a brute force approach. The method is still vulnerable to the same attack vectors AES has.", "A quibble... AES only specifies how a single 16 byte block is encrypted.", "Is it generally thought, then, that an attack on AES will likely come from an attack on the protocol itself (breaking SHA-512 or something, somehow) and not by a brute force method? \nThanks for sharing these. I hadn\u2019t thought of the character limit", "Either that or a \"clever\" brute force done with quantum computing, for example", "No better attack by quantum computers against AES is known but Grover's algorithm. It \"only\" squares the keyspace, leaving AES256 still secure.", "So far that's true. I just pointed as an example of what could happen in the future"]}
{"id": "oobmpc", "title": "Prepare an SSD-equipped laptop for sale (data safety)", "url": "https://www.reddit.com/r/crypto/comments/oobmpc/prepare_an_ssdequipped_laptop_for_sale_data_safety/", "Created (UTC)": "2021-07-20 14:32:06", "body": "Greetings!\n\nLaptop owner, about to sell it.\n\nData currently on the disk: passwords - KeepassXC, minor files - one of a little bigger value, I really mean it, some private photos (!!) and videos. Since keepassXC already encrypts, Im only worried about the .docs, jpgs, .avis.\n\nI have no knowledge when it comes to data erasing. Please, do not laugh.\n\nI was suggested:\n\n1. Prepare important files copies\n2. GParted -> remove all the partitions\n3. Prepare giant partition covering the entire SSD (except GRUB menu), install random Linux distro checking the \"Encrypt\" option before installation -> see if it boots up properly and asks for passphrase\n4. (NO CLUE WHICH IS BETTER)  DBAN wipe/Bruce Schneier wipe/German Vsitr wipe/US DoD wipe\n5. Install the \"final\" OS  -> sell\n\nWould that provide me with some nice data safety?\n\nThanks in advance dear /crypto users! :)", "post URL info": [], "author": "MicroBoy4441", "ups": "2", "downs": "0", "number of comments": "25", "comments": ["Simply send the SATA (or NVME) Secure Erase Command. This tells the firmware to do a wipe and is only the serious option for a SSD as you can't access the raw flash directly.", "Never ever resell used storage, it's the safest rule it the book. Storage is cheap anyway. Physical destruction at end of use/life (after secure wiping).\n\nEncrypt always on first use and every use, wipe at end of use, then physical destruction.\n\nHaving looked at SSD's and their data storage/wiping method (FTL, amplification, compression, relocation, HPA's), I pick physical destruction *every* time, even after using LUKS and *dd*.\n\nNot all SSD's are equal, the problem is what happens after your data passes through the FTL. That is vendor (and model or firmware) specific.\n\nLUKS -> *dd* and */dev/urandom* -> Blentec \"Will it Blend?\" blender -> Thermite\n\nThat is, if you truely value your privacy.\n\nNever *ever* write unencrypted data to these things either. Not even once. Some do encrypt as wiping just wipes their \"secret\" key area (that's why their secure wipe is fast lol, it's not the whole drive wipe), which you don't control, it's in a HPA (you can check for HPA's on the command line).\n\nSecure wiping is so bad (neigh impossible, due to compression, don't use zeros or it compresses to save page writes and wear, that's why we use *urandom* and not *zeros*), some vendors just encrypt and wipe their own key area (again you don't control this).\n\nTreat these things like you would a facehugger egg from Alien or a brainchip from a Terminator.\n\nResell value on storage is low anyway due to wear on usage, if they're eager and willing to pay for your used storage, that means they're possibly after an attempt at data recovery. Yes, people do buy storage from ebay or liquidation auctions for this purpose.\n\nProbably best to swap out the factory shipped storage on new purchases with your own better brand, then replace it back on reselling with the original one (as it would be unused). It's like a clean factory reset then.", "SSD disk sanitization is very different from HDD sanitization. With HDDS, you can just overwrite every sector on the disk with zeros and be done with it. SSDs however require a bit more care due to their wear leveling algorithms.\n\nMost SSD manufacturers ship a sanitization tool specific to that model that you should use for clearing the registers. You should verify that it resets every register however. You *could* overwrite the registers with zeros, but there no guarantee you'll get them all due to wear leveling, which is why you should search for the manufacturer's sanitization tool.", "If you had enabled full device encryption it will be enough to just format the drive as the encryption keys will be lost. Anything read will be gibberish\n\nEdit: Spelling", "Definitely do not use DBAN on an SSD. It was never intended for use on SSD and has such notice right on the [home page](https://dban.org/).", "See;\n\nhttps://www.reddit.com/r/crypto/comments/oo80fq/_/h5wwv03", "Beware that not all SSD:s implement it correctly. Might look up an old article on this later."]}
{"id": "oo6jq8", "title": "Research Topics - Ideas!", "url": "https://www.reddit.com/r/crypto/comments/oo6jq8/research_topics_ideas/", "Created (UTC)": "2021-07-20 10:18:34", "body": "Hi all,\nI\u2019m pursuing a Masters in Cybersecurity and exploring a couple of different options regarding a research topic for my thesis. I\u2019ve a few topics (haphazardly written on a sticky note!) but just reaching out to the wider community to see if anyone has any topics they have noted in the last year or so that has piqued their interest, or any topics that seem interesting?\n\nThanks a lot in advance!", "post URL info": [], "author": "thrualongway", "ups": "6", "downs": "0", "number of comments": "21", "comments": ["Ask your thesis advisor. This is always the way.\n\nThere is no point in me suggesting that you do a thesis on FHE when you have no one at your university that can guide you through it.", "You could try to [break this hash function](https://www.reddit.com/r/crypto/comments/frgeat/hash_anyone_looked_at_highwayhash/).", "If you are interested in people, and not technical stuff I advice you look at social engineering. Looks really interesting and includes people rather than the normal stuff.", "I\u2019ve 100% asked them too! Wouldn\u2019t make their jobs that easy. :) \nWas just reaching out to another community to see if there were new/interesting topics that I might have missed. \n\nThanks for the response!", "I have looked into this actually, it\u2019s one of my favourite topics. I do fear that it\u2019s such a broad scope I\u2019d have a bit of trouble narrowing it down (and potentially getting permission if needed from work/school), but it\u2019s definitely one of the more interesting aspects. Thanks for the suggestion!"]}
{"id": "oo80fq", "title": "Encrypted volumes backed up and no longer needed - can I simply erase my SSD?", "url": "https://www.reddit.com/r/crypto/comments/oo80fq/encrypted_volumes_backed_up_and_no_longer_needed/", "Created (UTC)": "2021-07-20 11:30:33", "body": "As the title states.\n\nI was \"playing\" with VeraCrypt and Luks encrypted volumes to see it in practice while I still knew that this computer should be formatted in the future anyway. The \"encrypted\" files were backed up. Can I then remove all the partitions, format  the entire disk and install new systems or is there something special that I have to do?\n\nNo special settings set, just regular encrypted volumes accessed by a passphrase.", "post URL info": [], "author": "aRKsonaR", "ups": "2", "downs": "0", "number of comments": "20", "comments": ["With SSDs, you may need to clear the registers before writing data for performance reasons, but that's about it. If you're paranoid, you can overwrite the container headers to remove the possibility of decrypting the data. But really, I would just reformat, and move on.", "Why would you think you have to do anything special?  Are you trying to protect data that was on the drive in encrypted format from a nation state?\n\nThe question \"is there something special that I HAVE to do?\" cannot be answered without more information about what you are trying to achieve.", "Just check what is DoD 5220.22-M and do it...", "No, its not top secret, the reason I asked is because I thought that encryption leaves some sort of future problems for writing new data onto the SSD and it should be dealt with carefully , I guess I was .. wrong?", "Nope. It's just random looking bits written to disk. If you want to use the disk for something else later, just reformat. The computer just won't know how to write to the disk before you either unlock the drive (using the current password) or you reformat in order to tell it to ignore what's currently on the disk and overwrite it with a new filesystem.\n\nThere's typically no write locks involved on the harddrive itself. Especially not in something \"ordinary\" like Veracrypt or Truecrypt."]}
{"id": "oo7kaz", "title": "Could I have a keccak256 example?", "url": "https://www.reddit.com/r/crypto/comments/oo7kaz/could_i_have_a_keccak256_example/", "Created (UTC)": "2021-07-20 11:08:39", "body": "I know this is not about cryptocurrency, so please forgive me for asking about keccak256, I cannot find a code sample for the keccak256, other than \u201cimport keccak256 module thing\u201d or something like that, could you help me find an actual code sample showing the algorithm?", "post URL info": [], "author": "663994", "ups": "2", "downs": "0", "number of comments": "19", "comments": ["how did that happen? they even have a homepage: https://keccak.team/keccak.html", "Keccak has nothing to do with cryptocurrency its just used by crypto currencies. It wasn't developed for use in crypto currencies, and is used in many other areas", "Keccak is the underlying hash function family behind SHA3, have you looked at the author's website?", "[deleted]", "https://github.com/esaulpaugh/headlong/blob/master/src/main/java/com/joemelsha/crypto/hash/Keccak.java\n\n(modifications to the original by me)\n\nnote the theta step, rho step, pi step, chi step (and a fifth step not to be named). it can be converted to proper SHA-3 with a one-line change to the pad function.\n\nit's probably not the best impl to learn from though because it's been hand-optimized by two different people", "I'd he asking about the non final variant used in ETH though?\n\n(I don't know)", "Comment approved now, automod is trigger happy", "If so, their source code repo would have it"]}
{"id": "onkuye", "title": "Ehat to do with AES-128 key of length 15 ASCII characters?", "url": "https://www.reddit.com/r/crypto/comments/onkuye/ehat_to_do_with_aes128_key_of_length_15_ascii/", "Created (UTC)": "2021-07-19 12:07:34", "body": "&#x200B;\n\nI'm trying to decrypt an encrypted h264 I-frame, and I was given the a of length 15 ASCII charchters, is this even valid?\n\nShould not it be of length 16, so the binary representation would be 128 bits?\n\nIf it is valid, what is the common practice in such cases? what can I do?", "post URL info": [], "author": "zulumvar", "ups": "10", "downs": "0", "number of comments": "19", "comments": ["It's very unlikely to use such thing as key. Normally you would apply some PBDKF function to derive key from passphrase", "Maybe the last byte of the key is a 0x00 string null terminator", "> what can I do?\n\nAsk whoever gave you the key what the specific encryption/key-derivation algorithm was?", "The 16th byte may be a 0x00 ([null terminator](https://en.wikipedia.org/wiki/Null-terminated_string)), otherwise it may need [padding](https://en.wikipedia.org/wiki/Padding_(cryptography).", "The most or the least significant bits?", "A key is an array of 16 bytes, so it's the last byte of that array."]}
{"id": "onctvo", "title": "Peer Review, Lectures for Highschool Students", "url": "https://www.reddit.com/r/crypto/comments/onctvo/peer_review_lectures_for_highschool_students/", "Created (UTC)": "2021-07-19 05:13:00", "body": "Hi everyone,\n\nI'm a penetration tester that runs a non-profit in San Diego, CA and teaches cybersecurity at a middle school and high school in the area (Cyberpatriot and some CTFs). Looking to get some feedback on this video I just put together as I'm starting to get lectures together for this year. Hopefully this is allowed, please lmk if it's not--sounds like advertising is banned but I'm hoping this is different enough, I'm not monetized on YT fwiw.\n\nI just want to make sure I'm not passing on some blatantly incorrect information.\n\n[Everything You Need to Know About Password Security - YouTube](https://www.youtube.com/watch?v=suCs7btj1pw)\n\nThanks guys!", "post URL info": ["https://www.youtube.com/watch?v=suCs7btj1pw)"], "author": "iamtherealmod", "ups": "8", "downs": "0", "number of comments": "16", "comments": ["Sorry, there are other mistakes here.\n\nCollision resistance is an important property of cryptographic hash functions, but it is not an essential property for password hashing.  When you talk about two inputs hashing to the same password, that scenario is 2nd preimage resistance.  That\u2019s what we need.  Collision resistance implies 2nd preimage resistance, but the opposite is not true.\n\nWhen we talk about preimage resistance, what we really mean is faster than brute force searches. \n\nThe best way to attack passwords is credential stuffing, which is highly successful because many people reuse passwords on multiple sites.\n\nWhat is completely missing is why password hashing functions need to be slow, which implies that the SHA2 family of functions are not good for password hashing despite being good for cryptography.\n\nRainbow tables are a time-memory trade off.  Here it is described as only a table lookup, and that is not accurate.\n\nNo, the advice from NIST is NOT to change your password every90 days, instead the advice is only change it when there is indication of compromise.  See question B05 in their FAQ: https://pages.nist.gov/800-63-FAQ/#q-b5\n\nWhy is 2FA not recommended in best practices?", "Problem 1: Your math around the 5 minute mark is wrong.  You computed the number of ways to choose a password with the first character being upper case, the second being lower case, the third being a number, the fourth being a special character, and the remaining being anything.  There are many other possible combinations where they do things in different orders.", "CP is a legit program.  Incredible kids come out of it", "Scott, thanks for the replies and critique. I\u2019m going to do the video again with everyone\u2019s recommendations so yours will definitely be incorporated. Really appreciate it."]}
{"id": "onmz4w", "title": "A consortium led by global satellite company SES will create a roadmap and infrastructure to mitigate cyber threats by using satellite Quantum Key Distrubution. It's called LuxQCI: The Luxembourg\u2019s Quantum Communications Infrastructure project (LuxQCI) | Business Wire (13th July 2021)", "url": "https://www.businesswire.com/news/home/20210712005866/en/SES-led-Consortium-to-Define-Luxembourg%E2%80%99s-Quantum-Communication-Infrastructure-for-Europe", "Created (UTC)": "2021-07-19 13:52:32", "body": "", "post URL info": [], "author": "Aerothermal", "ups": "0", "downs": "0", "number of comments": "12", "comments": ["Which STILL is secure only if you can securely distribute a secret authentication key in advance. In which case you can also use symmetric encryption.\n\nJust because you can do something it doesn't mean you should."]}
{"id": "ommjr7", "title": "Initial Draft Specification for PASETO v3/v4", "url": "https://github.com/paragonie/paseto/pull/127", "Created (UTC)": "2021-07-18 01:20:57", "body": "", "post URL info": [], "author": "paragon_init", "ups": "17", "downs": "0", "number of comments": "26", "comments": ["I still don't understand why they don't take this to ietf to get real adoption", "You mean like [this](https://mailarchive.ietf.org/arch/msg/jose/Bzz8Y2oZR2rwkapfhErvKZh_A_U/)?", "FWIW that's not an RFC. It's an expired individual internet draft that hasn't been updated or pushed in 3+ years. Hardly an active effort.", "If the IETF doesn't want to play ball, things don't become RFCs, no matter how much effort you put into it.\n\nThus, your conduct here is oddly reminiscent of harmful gatekeeping.", "I personally am actively involved with ietf and a bunch of the people associated with oauth2, jwt and oidc. If you are experiencing any gatekeeping in those areas I will be more than happy to make a personal introduction as this would help move the industry forward as a whole. They are some of the smartest people around in this industry and having followed your website for over a year now I think it would be a great collaboration.", "My experience doesn't match yours.\n\nXChaCha died in the draft stage even when it was a working document under CFRG, when I was *actively* pushing for it.\n\nWithout XChaCha, there can be no PASETO RFC.\n\nIf you're interested in resurrecting the XChaCha RFC and getting that standardized, then I'll be free to pick up PASETO again. But I'm kinda burned out by the IETF.", "Hijacking this thread, could I trouble you to tell me a bit more about the lifetime of an I-D and where the common mistakes are? Thank you for your time.\n\nI have a (non-cryptographic) I-D that I've been working on but quite honestly I'm daunted by the process and I want to avoid failure, especially as an outsider.", "I've not experienced anything bad from the IETF, personally, though my only noteworthy participation is chiming in on the \"Real Name\" discussion a few months ago.", "Do you have a working group that you tried to raise XChaCha and it's benefits with and a reason they shut you down? If you can link to that I'd be more than happy to resurrect with the appropriate parties. It's not an easy process that something get's proposed and it's just approved, but it's the right one to work through to get adoption.", "All communications were on the CFRG mailing list. I never got a reason, they just ghosted me."]}
